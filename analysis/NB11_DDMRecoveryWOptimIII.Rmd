---
title: "Experience vs. description based decision-making project: DDM parameter recovery multiple round optimization"
output: 
  html_document:
    toc: true
    toc_float: true
    code_folding: 'hide'
---

# Setup

Set up environment and load in data

```{r include=FALSE, message=FALSE}
library(tidyverse)
library(here)
library(gridExtra)
cbbPalette <- c("#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
theme_set(theme_classic())
sem <- function(x) {sd(x, na.rm=T) / sqrt(length(x))}
helpers_path = here('analysis/helpers/')

set.seed(385736)
```

```{r message=FALSE}
source(paste0(helpers_path, 'ddModels/fit_task.R'))
sim_trial_list = list()
fit_trial_list = list()

source(paste0(helpers_path, 'ddModels/r_ddm_models/ddm_model1a.R'))
sim_trial_list[['model1a']] = sim_trial
fit_trial_list[['model1a']] = fit_trial

model = "model1a"

source(paste0(helpers_path, 'ddModels/get_true_pars.R'))
true_pars_path = paste0(helpers_path, 'ddModels/cluster_scripts/test_data/')

library(visualMLE)
```

# Sim3: Single round 3 parameter model

Using data from the last simulation where data was generated with a 4 parameter model checking how recovery works for a single iteration when gamma is fixed to 1, effectively optimizing over 3 parameters instead.

**Example 1**
For a dataset with gamma = 1, delta < 1:

```{r}
data_suffix = "sim_single_sub_data23"
data = read.csv(paste0(helpers_path, 'ddModels/cluster_scripts/test_data/', data_suffix, '.csv'))
```

```{r}
get_true_pars(data_ = data_suffix, true_pars_path_ = true_pars_path)$true_pars_str
```

```{r}
start_vals = c(0.142,0.184,0.673)
par_names = c("d", "sigma", "delta")
fix_pars = list(gamma = 1)

optim_out = optim_save(par = start_vals, get_task_nll, data_= data, par_names_ = par_names, model_name_ = model, fix_pars_ = fix_pars)
```

```{r}
round(optim_out$par, 3)
```

**Example 2**
For a dataset with gamma != 1, delta < 1.

```{r}
data_suffix = "sim_single_sub_data24"
data = read.csv(paste0(helpers_path, 'ddModels/cluster_scripts/test_data/', data_suffix, '.csv'))
```

```{r}
get_true_pars(data_ = data_suffix, true_pars_path_ = true_pars_path)$true_pars_str
```

```{r}
start_vals = c(0.887,0.305,1)
par_names = c("d", "sigma", "delta")
fix_pars = list(gamma = 1)

optim_out = optim_save(par = start_vals, get_task_nll, data_= data, par_names_ = par_names, model_name_ = model, fix_pars_ = fix_pars)
```

Delta moved in the right direction from the starting value but not sufficiently.

```{r}
round(optim_out$par, 3)
```

**Example 3**
For a dataset with gamma = 1, delta > 1.

```{r}
data_suffix = "sim_single_sub_data38"
data = read.csv(paste0(helpers_path, 'ddModels/cluster_scripts/test_data/', data_suffix, '.csv'))
```

```{r}
get_true_pars(data_ = data_suffix, true_pars_path_ = true_pars_path)$true_pars_str
```

```{r}
start_vals = c(0.887,0.305,1)
par_names = c("d", "sigma", "delta")
fix_pars = list(gamma = 1)

optim_out = optim_save(par = start_vals, get_task_nll, data_= data, par_names_ = par_names, model_name_ = model, fix_pars_ = fix_pars)
```

Delta moved in the right direction from the starting value but not sufficiently.

```{r}
round(optim_out$par, 3)
```

**Example 4**
For a dataset with gamma != 1, delta > 1.

```{r}
data_suffix = "sim_single_sub_data39"
data = read.csv(paste0(helpers_path, 'ddModels/cluster_scripts/test_data/', data_suffix, '.csv'))
```

```{r}
get_true_pars(data_ = data_suffix, true_pars_path_ = true_pars_path)$true_pars_str
```

```{r}
start_vals = c(0.148,0.454,7.620)
par_names = c("d", "sigma", "delta")
fix_pars = list(gamma = 1)

optim_out = optim_save(par = start_vals, get_task_nll, data_= data, par_names_ = par_names, model_name_ = model, fix_pars_ = fix_pars)
```

Delta moved in the right direction but too much.

```{r}
round(optim_out$par, 3)
```

Clean up workspace

```{r}
rm(start_vals, par_names, fix_pars, optim_out)
```

**Conclusion**
Tentatively, it seems like delta moves more from the starting value when gamma is fixed to 1 (i.e. when the fit optimizes over only 3 parameters), regardless of whether that is the true gamma value of not.  

Still, for the 5 dataset in sim2 where gamma = 1 delta recovery was pretty bad. It was not noticeably better than other combinations.  

To understand how well recovery works (especially for delta) using a three parameter model (d, sigma, delta) I systematically varied each parameter and generated 36 datasets to optimize over. The datasets were generated using the combination of the true values `true_ds = c(.001, .06 , .5)`, `true_sigmas = c(.001, .08, .3)`, `true_deltas = c(.1, .5 , 1, 3)`.

In addition to identifiability this was also motivated by the logit analyses for the whole sample, which showed that while the weight of EVs decreased monotonically, weight of QVs followed more a step function/was possibly consistently underweighted.

## Results

```{r}

```

# Sim4: Two round optimization 

For the same 36 datasets
Fix delta to 1. Optimize over d and sigma. Then fix d and sigma and optimize over delta.

```{r}
first_start_vals = c(0.832,0.924)
first_par_names = c("d", "sigma")
first_fix_pars = list(delta = 1, gamma = 1)

first_optim_out = optim_save(par = first_start_vals, get_task_nll, data_= data, par_names_ = first_par_names, model_name_ = model, fix_pars_ = first_fix_pars)

second_start_vals = c(2.624,1.194)
second_par_names = c("delta", "gamma")
second_fix_pars = setNames(as.list(first_optim_out$par), first_par_names)

second_optim_out = optim_save(par = second_start_vals, get_task_nll, data_= data, par_names_ = second_par_names, model_name_ = model, fix_pars_ = second_fix_pars)
```

True parameters are:

```{r}
get_true_pars(data_ = data_suffix, true_pars_path_ = true_pars_path)
```

Two rounds converged on:  

d and sigma
```{r}
first_optim_out$par
```

delta and gamma
```{r}
second_optim_out$par
```

# Multiple rounds until improvement is below a specified threshold

```{r}

```

Next:
- Joint choice and RT modeling
- Hierarchical estimation

Meeting note: 
- Make likelihood surface for one of the recovered delta-gamma correlation scatter plots

------------------------------------------------------------------------------------------------
More data per optimization? (currently for single subject)

Would you compute posterior among these different optimized values? Is there any point in doing that even when there is no iteration that has converged on the true values?