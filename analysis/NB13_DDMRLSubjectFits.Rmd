---
title: "Experience vs. description based decision-making project: DDM parameter recovery multiple round optimization"
output: 
  html_document:
    toc: true
    toc_float: true
    code_folding: 'hide'
---

# Setup

Set up environment and load in data

```{r include=FALSE, message=FALSE}
library(tidyverse)
theme_set(theme_classic())
library(here)
helpers_path = here('analysis/helpers/')
cpueaters_path = '/Users/zeynepenkavi/CpuEaters/DescribedVsLearned_beh/analysis/helpers/'
fig_out_path = paste0(here(),'/outputs/fig/')
source(paste0(helpers_path, 'optimPostProcess/get_optim_out.R'))
```

# Fit to subject data: First RL then DDM

## Parameter distributions

Distribution of converged values for each subject (25 histograms per parameter for each of the three parameters)

```{r}
optim_out_path = paste0(cpueaters_path, 'ddModels/cluster_scripts/optim_out/fit1/')
subnums = c("01", "02", "03", "04", "05", "06", "07", "08", "09", "10", "11", "12", "13", "14", "15", "16", "17", "18", "19", "20", "22", "23", "24", "25", "27")
data_prefix ="sub_data"
model = "model1c"  

ddm_fit_iters = data.frame()

for(i in 1:length(subnums)){
  cur_subnum = subnums[i]
  tmp = get_optim_out(model_=model, data_=paste0(data_prefix, cur_subnum), optim_out_path_=optim_out_path, iters_ = TRUE)
  tmp$subnum = cur_subnum
  ddm_fit_iters = rbind.all.columns(tmp, ddm_fit_iters)
}

ddm_fit_iters = ddm_fit_iters %>%
  rename(d = Param1, sigma = Param2, delta = Param3)
```

```{r}
ddm_best_sub_ests = ddm_fit_iters %>% 
  filter(Iteration != 1) %>%
  group_by(subnum) %>%
  mutate(best_sub_est = ifelse(Result == min(Result), 1, 0)) %>%
  filter(best_sub_est == 1) %>%
  select(-Result,-Iteration,-kernel,-best_sub_est) %>%
  gather(key, value, -subnum)
```

```{r eval=FALSE}
p = ddm_fit_iters %>%
  filter(Iteration != 1) %>%
  select(-Result,-Iteration,-kernel) %>%
  gather(key, value, -subnum) %>%
  ggplot(aes(value))+
  geom_histogram(bins=50)+
  geom_vline(data=ddm_best_sub_ests, aes(xintercept=value), color="red")+
  facet_grid(subnum~key, scales="free")

fig_fn = 'ddm_model1c_fit1'
ggsave(file=paste0(fig_out_path, fig_fn, '_par_hists.jpg'), p, height = 11, width=8, units="in")
```

```{r echo=FALSE, out.width='100%'}
fig_name = 'ddm_model1c_fit1_par_hists.jpg'
knitr::include_graphics(paste0(fig_out_path, fig_name))
```

Distribution of best fitting parameter across subjects (one histogram per parameter with 25 values)

```{r}
ddm_best_sub_ests %>%
  ggplot(aes(value))+
  geom_histogram(bins=30) +
  facet_wrap(~key, scales="free")
```

# Fit to subject data: RL+DDM

## Parameter distributions

```{r}
optim_out_path = paste0(cpueaters_path, 'ddrlModels/cluster_scripts/optim_out/fit1/')
subnums = c("01", "02", "03", "04", "05", "06", "07", "08", "09", "10", "11", "12", "13", "14", "15", "16", "17", "18", "19", "20", "22", "23", "24", "25", "27")
data_prefix ="sub_data"
model = "model1c"  

ddrl_fit_iters = data.frame()

for(i in 1:length(subnums)){
  cur_subnum = subnums[i]
  tmp = get_optim_out(model_=model, data_=paste0(data_prefix, cur_subnum), optim_out_path_=optim_out_path, iters_ = TRUE)
  tmp$subnum = cur_subnum
  ddrl_fit_iters = rbind.all.columns(tmp, ddrl_fit_iters)
}

ddrl_fit_iters = ddrl_fit_iters %>%
  rename(d = Param1, sigma = Param2, alpha = Param3, delta = Param4)
```

```{r}
ddrl_best_sub_ests = ddrl_fit_iters %>% 
  filter(Iteration != 1) %>%
  group_by(subnum) %>%
  mutate(best_sub_est = ifelse(Result == min(Result), 1, 0)) %>%
  filter(best_sub_est == 1) %>%
  select(-Result,-Iteration,-kernel,-best_sub_est) %>%
  gather(key, value, -subnum)
```

```{r eval=FALSE}
p = ddrl_fit_iters %>%
  filter(Iteration != 1) %>%
  select(-Result,-Iteration,-kernel) %>%
  gather(key, value, -subnum) %>%
  ggplot(aes(value))+
  geom_histogram(bins=50)+
  geom_vline(data=ddrl_best_sub_ests, aes(xintercept=value), color="red")+
  facet_grid(subnum~key, scales="free")

fig_fn = 'ddrl_model1c_fit1'
ggsave(file=paste0(fig_out_path, fig_fn, '_par_hists.jpg'), p, height = 11, width=8, units="in")
```

```{r echo=FALSE, out.width='100%'}
fig_name = 'ddrl_model1c_fit1_par_hists.jpg'
knitr::include_graphics(paste0(fig_out_path, fig_name))
```

Distribution of best fitting parameter across subjects (one histogram per parameter with 25 values)

```{r}
ddrl_best_sub_ests %>%
  ggplot(aes(value))+
  geom_histogram(bins=30) +
  facet_wrap(~key, scales="free")
```

# Comparison of the two fits

## Likelihoods

Negative log likelihoods lower (better) for ddm compared to ddrl for almost all subjects.

```{r}
ddrl_fit_iters %>%
  filter(Iteration != 1) %>%
  select(Result, subnum) %>%
  mutate(model = "ddrl") %>%
  rbind(ddm_fit_iters %>%
          filter(Iteration != 1) %>%
          select(Result, subnum) %>%
          mutate(model = "ddm")) %>%
  ggplot(aes(Result, fill=model)) +
  geom_histogram(bins=30, alpha=.5, position="identity") +
  facet_wrap(~subnum, scales="free")+
  theme(legend.position = "bottom")+
  scale_fill_manual(values=cbbPalette[1:2])+
  labs(fill="")
```
## Parameter estimates

### MLE scatter plots

Drift rate and sigmas are similar across the two models but when fitting learning rates at the same time the probability distortion parameter delta is consistently higher and >1 (overestimation of fractal relevance).

```{r}
ddm_best_sub_ests %>%
  mutate(model = "ddm") %>%
  rbind(ddrl_best_sub_ests %>%
          mutate(model = "ddrl")) %>%
  group_by(subnum) %>%
  spread(model, value) %>%
  drop_na() %>%
  ggplot(aes(ddm, ddrl))+
  geom_point()+
  geom_abline(aes(slope=1, intercept=0))+
  facet_wrap(~key, scales="free")
```

### Distributions of all converged values

```{r eval=FALSE}
p = ddrl_fit_iters %>%
  filter(Iteration != 1) %>%
  select(d, sigma, delta, subnum) %>%
  mutate(model = "ddrl") %>%
  rbind(ddm_fit_iters %>%
          filter(Iteration != 1) %>%
          select(d, sigma, delta, subnum) %>%
          mutate(model = "ddm")) %>%
  gather(key, value, -subnum, -model) %>%
  ggplot(aes(value, fill=model)) +
  geom_histogram(bins=30, alpha=.5, position="identity") +
  facet_grid(subnum~key, scales="free")+
  theme(legend.position = "bottom")+
  scale_fill_manual(values=cbbPalette[1:2])+
  labs(fill="")

fig_fn = 'ddm_ddrl_model1c'
ggsave(file=paste0(fig_out_path, fig_fn, '_par_hist_comparison.jpg'), p, height = 11, width=8, units="in")
```

```{r echo=FALSE, out.width='100%'}
fig_name = 'ddrl_model1c_fit1_par_hists.jpg'
knitr::include_graphics(paste0(fig_out_path, fig_name))
```

# Comparison of ddrl alpha's to hierarchical rl alpha's

```{r}
all_trials_data = read.csv('/Users/zeynepenkavi/Downloads/GTavares_2017_arbitration/behavioral_data/all_trials.csv')
all_trials_data %>%
  drop_na() %>%
  select(subnum, alpha) %>%
  distinct() %>%
  rename(rl = alpha) %>% 
  left_join(ddrl_best_sub_ests %>%
              filter(key == "alpha") %>%
              mutate(subnum = as.numeric(subnum)) %>%
              select(-key) %>%
              rename(ddrl = value), by="subnum") %>%
  ggplot(aes(rl, ddrl))+
  geom_point()+
  geom_abline(aes(slope=1, intercept=0))+
  labs("Comparison of learning rates from hierarchical vs. ddrl fit")
```

# Posterior predictive checks

## RL -> DDM

```{r}

```

## RL + DDM

```{r}

```