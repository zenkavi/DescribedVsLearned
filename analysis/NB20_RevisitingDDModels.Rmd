---
title: 'Experience vs. description based decision-making project: Revisiting DD models'
output:
  html_document:
    toc: yes
    toc_float: yes
    code_folding: 'hide'
  pdf_document:
    toc: yes
---

```{r include=FALSE}
library(tidyverse)
theme_set(theme_bw())
library(here)
cbbPalette <- c("#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
helpers_path = here('analysis/helpers/')

source(paste0(helpers_path,'ddModels/sim_task.R'))
source(paste0(helpers_path,'ddModels/fit_task.R'))
source(paste0(helpers_path,'01_clean_behavioral_data.R'))
source(paste0(helpers_path, 'get_qvals.R'))
source(paste0(helpers_path,'optimPostProcess/sim_sanity_checks.R'))


set.seed(38573)
```

Add distorted value estimates using the hierarchical RL fit.

```{r message=FALSE, warning=FALSE}

source(paste0(helpers_path, 'rlModels/fit_rl_hierarchical_oneParamDoubleSymmLinearProbDistortion_rpeBoth.R'))

clean_beh_data = par_ests %>%
  group_by(subnum, par) %>%
  summarise(est = mean(value), .groups='keep') %>%
  spread(par, est) %>%
  left_join(clean_beh_data, by='subnum')

## Add Q values of fractals to each trial
clean_beh_data = clean_beh_data %>%
  group_by(subnum) %>%
  do(get_qvals(., model_name="rpeBoth")) %>%
  ungroup()

clean_beh_data = clean_beh_data %>%
  mutate(rightLotteryEV = referenceProb * referenceValue,
         leftLotteryEV = lotteryValue * lotteryProb,
         lottery_ev_diff = leftLotteryEV - rightLotteryEV,
         fractal_qv_diff = leftQValue - rightQValue,
         distorted_ev_diff = (1-theta)*(1-probFractalDraw)*lottery_ev_diff,
         distorted_qv_diff = theta*probFractalDraw*fractal_qv_diff)

rm(fit, g_par_ests, par_ests)
```


```{r}
# Extract set of stimuli that will be used for simulations
sub_data = clean_beh_data %>%
  filter(subnum  %in% c("01", "03", "05","07", "09", "11", "13", "15", "17", "19")) %>%
  select(leftLotteryEV, rightLotteryEV, leftQValue, rightQValue, probFractalDraw, reactionTime, choiceLeft, subnum, distorted_ev_diff, distorted_qv_diff) %>%
  rename(EVLeft = leftLotteryEV, EVRight = rightLotteryEV, QVLeft = leftQValue, QVRight = rightQValue, distortedEVDiff = distorted_ev_diff, distortedQVDiff = distorted_qv_diff)
```

# RT effects to explain

Source trial simulating and fitting function three integrator model. The model only had the ddm parameters as variables; choice parameters (learning rate and probability distortion) are fitted elsewhere and used to compute the distorted value differences fed into this model.


```{r}
sim_sanity_checks(sub_data, checks=c(1,3,4,5,6,7,8), compare_logits = F, compare_rts = F)
```

## Slow errors check

```{r}

```

# Recovery checks

## States-space method

Using Gabi's discrete time and state-space method

**Why might this not have been used previously? Some ideas:**  
**The boundary in traditional DDM is not fixed at 1 and -1. Instead it is a parameter. It's not immediately apparent to me how to use the sum of random variables approach without assuming the boundaries at 1 and -1.**
**The traditional DDM often models the whole of a response time distribution for correct vs incorrect.**

## One integrator

```{r}
source(paste0(helpers_path, 'ddModels/r_ddm_models/ddm_oneIntegrator_sepProbDistortion.R'))
```

### Same trial

```{r}
d = 0.03
distortedEVDiff = .3
distortedQVDiff = .1
sigma = .05
n_particles = 250
sim_data = data.frame()

for(i in 1:n_particles){
  tmp = sim_trial(d = d, sigma = sigma, distortedEVDiff =distortedEVDiff, distortedQVDiff =distortedQVDiff, EVLeft = NA, EVRight = NA, QVLeft = NA, QVRight = NA, probFractalDraw = NA)
  tmp$iter = i
  sim_data = rbind(sim_data, tmp)
}
```

```{r}
fit_trial_list = list(model1 = fit_trial)

d_range = seq(.01, .1, .01)
sigma_range = seq(.01, .1, .01)

recovery_df = data.frame(test_d = NA, test_sigma = NA, nll = NA)

for(i in 1:length(d_range)){
  for(j in 1:length(sigma_range)){
    test_d = d_range[i]
    test_sigma = sigma_range[j]
    test_nll = get_task_nll(data_ = sim_data, par = c(test_d, test_sigma), par_names_ = c("d", "sigma"), model_name = "model1", fix_pars_ = list())
    recovery_df = rbind(recovery_df,
                        data.frame(test_d = test_d, test_sigma = test_sigma, nll = test_nll))
    
  }
}
recovery_df = recovery_df %>% drop_na()
```


```{r}
recovery_df %>%
  mutate(test_d = as.factor(test_d),
         test_sigma = as.factor(test_sigma)) %>%
  ggplot(aes(test_d, test_sigma, fill=nll))+
  geom_tile()

#Zoom in
recovery_df %>%
  filter(test_sigma>.04 & test_d < .06)%>%
  mutate(test_d = as.factor(test_d),
         test_sigma = as.factor(test_sigma)) %>%
  ggplot(aes(test_d, test_sigma, fill=nll))+
  geom_tile()
```

### Different trials (~single subject)

```{r}
sim_trial_list = list()
sim_trial_list[['model1']] = sim_trial
```

```{r}
n_trials = 300
stimuli = clean_beh_data[1:n_trials,] %>%
  select(leftLotteryEV, rightLotteryEV, leftQValue, rightQValue, probFractalDraw, reactionTime, choiceLeft, subnum, distorted_ev_diff, distorted_qv_diff) %>%
  rename(EVLeft = leftLotteryEV, EVRight = rightLotteryEV, QVLeft = leftQValue, QVRight = rightQValue, distortedEVDiff = distorted_ev_diff, distortedQVDiff = distorted_qv_diff)
sim_subj = sim_task(stimuli, model_name = "model1", d=d, sigma=sigma)
# sim_subj
```

```{r}
d_range = seq(.01, .1, .02)
sigma_range = seq(.01, .1, .02)

recovery_df = data.frame(test_d = NA, test_sigma = NA, nll = NA)

for(i in 1:length(d_range)){
  for(j in 1:length(sigma_range)){
    test_d = d_range[i]
    test_sigma = sigma_range[j]
    test_nll = get_task_nll(data_ = sim_subj, par = c(test_d, test_sigma), par_names_ = c("d", "sigma"), model_name = "model1", fix_pars_ = list())
    recovery_df = rbind(recovery_df,
                        data.frame(test_d = test_d, test_sigma = test_sigma, nll = test_nll))
    
  }
}
recovery_df = recovery_df %>% drop_na()

```

```{r}
recovery_df %>%
  mutate(test_d = as.factor(test_d),
         test_sigma = as.factor(test_sigma)) %>%
  ggplot(aes(test_d, test_sigma, fill=nll))+
  geom_tile()

recovery_df %>%
  filter(test_sigma > .03) %>%
  mutate(test_d = as.factor(test_d),
         test_sigma = as.factor(test_sigma)) %>%
  ggplot(aes(test_d, test_sigma, fill=nll))+
  geom_tile()
```

## Three integrators

```{r}
source(paste0(helpers_path, 'ddModels/r_ddm_models/ddm_threeIntegrators_sepProbDistortion.R'))
fit_trial_list = list(model3 = fit_trial)
sim_trial_list = list(model3 = sim_trial)
```

### Schematic representation

Extending the state space approach

1. Likelihood computations depends on all three integrators' position

2. Time-dependent change of arbitrator slope

```{r}

```

Test if trial simulating function works.

```{r}
i=300
tmp = sim_trial(dLott=0.03, dFrac=0.06, dArb=0.07, sigmaLott = 0.03, sigmaFrac = 0.03, distortedEVDiff = sub_data$distortedEVDiff[i], distortedQVDiff = sub_data$distortedQVDiff[i], probFractalDraw = sub_data$probFractalDraw[i], barrierDecay = 0, EVLeft = sub_data$EVLeft[i], EVRight = sub_data$EVRight[i], QVLeft = sub_data$QVLeft[i], QVRight = sub_data$QVRight[i], debug=TRUE)

annot_top = paste0("distorted EV difference = ", round(tmp$out$distortedEVDiff, 3), 
                    "\ndistorted QV difference = ", round(tmp$out$distortedQVDiff, 3),
                   "\nprobFractalDraw = ", tmp$out$probFractalDraw,
                    "\nchoice (based on) = ", tmp$out$choice, " (", tmp$out$arbitrator, ")")

annot_bot = paste0("dLottery = ", tmp$out$dLott, 
                    "\ndFractal = ", tmp$out$dFrac,
                    "\ndArbitrator = ", tmp$out$dArb,
                    "\nsigma = ", tmp$out$sigmaLott)

tmp$debug_df %>%
  select(arbitratorRDV, lotteryRDV, fractalRDV, time) %>%
  gather(key, value, -time) %>%
  ggplot(aes(time, value, color=key))+
  geom_line()+
  geom_hline(aes(yintercept=1))+
  geom_hline(aes(yintercept=-1))+
  geom_hline(aes(yintercept=0), linetype="dashed")+
  theme(legend.position = "bottom",
        panel.grid = element_blank())+
  labs(color="", x = "Timestep (in 10 ms)", y="RDV")+
  annotate(geom="text", x=20, y = .6, label = annot_top, hjust=0)+
  annotate(geom="text", x=20, y = -.6, label = annot_bot, hjust=0)

```

**Potential problem** for 3 integrator model: The model would predict slower decisions because the difference in the absolute value of each attribute integrator RDV would be small.

**BUT** by design there aren't trials that provide strong (distorted) evidence for a single side so for the current set of stimuli this should not be a concern.

```{r}
clean_beh_data %>%
  ggplot(aes(distorted_ev_diff, distorted_qv_diff)) +
  geom_point()+
  geom_abline(aes(slope=1, intercept=0))
```

### Demo

Check if single trial fit function estimates the probabilities correctly on a very simple example

```{r}
# tmp = sim_trial(dLott=1, dFrac=1, dArb=1, sigmaLott = 0.001, sigmaFrac = 0.001, distortedEVDiff = .25, distortedQVDiff = -.1, probFractalDraw = 2, barrierDecay = 0, bias = 0, EVLeft = NA, EVRight = NA, QVLeft = NA, QVRight = NA, debug=TRUE)

tmp = sim_trial(dLott=.3, dFrac=.6, dArb=.7, sigmaLott = 0.05, sigmaFrac = 0.05, distortedEVDiff = .25, distortedQVDiff = -.1, probFractalDraw = 2, barrierDecay = 0, bias = 0, EVLeft = NA, EVRight = NA, QVLeft = NA, QVRight = NA, debug=TRUE)

annot_top = paste0("distorted EV difference = ", round(tmp$out$distortedEVDiff, 3), 
                    "\ndistorted QV difference = ", round(tmp$out$distortedQVDiff, 3),
                    "\nchoice (based on) = ", tmp$out$choice, " (", tmp$out$arbitrator, ")")

tmp$debug_df %>%
  select(arbitratorRDV, lotteryRDV, fractalRDV, time) %>%
  gather(key, value, -time) %>%
  ggplot(aes(time, value, color=key))+
  geom_point()+
  geom_line()+
  geom_hline(aes(yintercept=1))+
  geom_hline(aes(yintercept=-1))+
  geom_hline(aes(yintercept=0), linetype="dashed")+
  theme(legend.position = "bottom",
        panel.grid = element_blank())+
  labs(color="", x = "Timestep (in 10 ms)", y="RDV")+
  annotate(geom="text", x=.25, y = .6, label = annot_top, hjust=0)

```

```{r}
tmp_fit = fit_trial(dLott=.3, dFrac=.6, dArb=.7, sigmaLott = 0.05, sigmaFrac = 0.05, distortedEVDiff = .25,  distortedQVDiff = -.1, probFractalDraw = 2, barrierDecay = 0, bias = 0, EVLeft = NA, EVRight = NA, QVLeft = NA, QVRight = NA,
                    choice = tmp$out$choice, reactionTime = tmp$out$reactionTime, debug=TRUE)

tmp_fit$prStatesArb %>%
  mutate(states = 1:n()) %>%
  gather(timeStep, prob, -states) %>%
  mutate(states = as.factor(states),
         timeStep = gsub("X", "", timeStep), 
         timeStep = as.numeric(timeStep)) %>%
  ggplot(aes(timeStep,states, fill=prob))+
  geom_tile()+
    theme(legend.position = "bottom",
          panel.grid = element_blank(),
          axis.ticks = element_blank(),
          axis.text = element_blank())
```

Is the most likely state the correct state at each time point?

```{r}
stateBin = c()

for(i in 1:nrow(tmp$debug_df)){
  stateBin[i] = which.min(abs(states - tmp$debug_df$arbitratorRDV[i]))
}

tmp_fit$prStatesArb %>%
  mutate(stateBins = 1:n()) %>%
  gather(timeStep, prob, -stateBins) %>%
  group_by(timeStep) %>%
  filter(prob == max(prob)) %>%
  mutate(timeStep = gsub("X", "", timeStep), 
         timeStep = as.numeric(timeStep),
         data_type="est") %>%
  select(-prob) %>%
  rbind(tmp$debug_df %>%
          select(arbitratorRDV, time) %>%
          rename(timeStep = time) %>%
          mutate(stateBins = stateBin, 
                 data_type="true") %>%
          select(-arbitratorRDV)) %>%
  ggplot(aes(timeStep, stateBins, color=data_type))+
  geom_point()

```

```{r}
  
tmp_fit$prStatesArb %>%
  mutate(stateBins = 1:n()) %>%
  gather(timeStep, prob, -stateBins) %>%
  # group_by(timeStep) %>%
  # filter(prob == max(prob)) %>%
  mutate(timeStep = gsub("X", "", timeStep), 
         timeStep = as.numeric(timeStep),
         data_type="est") %>%
    # filter( timeStep<20) %>%
  filter(timeStep %% 10 == 0) %>%
  ggplot(aes(stateBins, prob))+
  geom_bar(stat="identity")+
  coord_flip()+
  facet_grid(.~timeStep, scales="free")+
  scale_x_continuous(breaks=seq(0,21,1))+
  theme(panel.grid.minor = element_blank())
```

### Same trial

```{r}
distortedEVDiff = .3
distortedQVDiff = -.1
n_particles = 250
sim_data = data.frame()

for(i in 1:n_particles){
  tmp = sim_trial(dLott=0.03, dFrac=0.06, dArb=0.05, sigmaLott = 0.03, sigmaFrac = 0.03, distortedEVDiff =distortedEVDiff, distortedQVDiff = distortedQVDiff, EVLeft = NA, EVRight = NA, QVLeft = NA, QVRight = NA, probFractalDraw = .5, barrierDecay = 0, bias=0)
  tmp$iter = i
  sim_data = rbind(sim_data, tmp)
}
```


```{r}
dLott_range = c(.01, .03, .09)
dFrac_range = c(.01, .06, .09)
dArb_range = c(.01, .05, .09)
sigma_fix = .03

threeInt_trial_recovery_df = data.frame(test_dLott = NA, test_dFrac = NA, test_dArb = NA, nll = NA)

for(i in 1:length(dLott_range)){
  for(j in 1:length(dFrac_range)){
    for(k in 1:length(dArb_range)){
      test_dLott = dLott_range[i]
      test_dFrac = dFrac_range[j]
      test_dArb = dArb_range[k]
      test_nll = get_task_nll(data_ = sim_data, par = c(test_dLott, test_dFrac, test_dArb, sigma_fix, sigma_fix), par_names_ = c("dLott", "dFrac", "dArb","sigmaLott", "sigmaFrac"), model_name = "model3", fix_pars_ = list())
      threeInt_trial_recovery_df = rbind(threeInt_trial_recovery_df,
                          data.frame(test_dLott = test_dLott, test_dFrac = test_dFrac, test_dArb = test_dArb, nll = test_nll))
    }
  }
}
threeInt_trial_recovery_df = threeInt_trial_recovery_df %>% drop_na()
```

```{r}
threeInt_trial_recovery_df %>%
  mutate(test_dLott = as.factor(test_dLott),
         test_dFrac = as.factor(test_dFrac),
         test_dArb = as.factor(test_dArb)) %>%
  ggplot(aes(test_dLott, test_dFrac, fill=nll))+
  geom_tile()+
  facet_wrap(~test_dArb)+
  theme(legend.position = "bottom")
```

### Different trials (~single subject)

```{r}
n_trials = 300
stimuli = clean_beh_data[1:n_trials,] %>%
  select(leftLotteryEV, rightLotteryEV, leftQValue, rightQValue, probFractalDraw, reactionTime, choiceLeft, subnum, distorted_ev_diff, distorted_qv_diff) %>%
  rename(EVLeft = leftLotteryEV, EVRight = rightLotteryEV, QVLeft = leftQValue, QVRight = rightQValue, distortedEVDiff = distorted_ev_diff, distortedQVDiff = distorted_qv_diff)

sim_subj = sim_task(stimuli, model_name = "model3", dLott=0.03, dFrac=0.06, dArb=0.05, sigmaLott = 0.001, sigmaFrac = 0.001)
# sim_subj
```

```{r}
dLott_range = c(.01, .03, .09)
dFrac_range = c(.01, .06, .09)
dArb_range = c(.01, .05, .09)
# dLott_range = c(.001, .09, .5)
# dFrac_range = c(.001, .06, .8)
# dArb_range = c(.001, .05, .7)
sigma_fix = .001

threeInt_subj_recovery_df = data.frame(test_dLott = NA, test_dFrac = NA, test_dArb = NA, nll = NA)

for(i in 1:length(dLott_range)){
  for(j in 1:length(dFrac_range)){
    for(k in 1:length(dArb_range)){
      test_dLott = dLott_range[i]
      test_dFrac = dFrac_range[j]
      test_dArb = dArb_range[k]
      test_nll = get_task_nll(data_ = sim_subj, par = c(test_dLott, test_dFrac, test_dArb, sigma_fix, sigma_fix), par_names_ = c("dLott", "dFrac", "dArb","sigmaLott", "sigmaFrac"), model_name = "model3", fix_pars_ = list(), filter_liks_ = F, filter_quant_ = .9)
      threeInt_subj_recovery_df = rbind(threeInt_subj_recovery_df,
                          data.frame(test_dLott = test_dLott, test_dFrac = test_dFrac, test_dArb = test_dArb, nll = test_nll))
    }
  }
}
threeInt_subj_recovery_df = threeInt_subj_recovery_df %>% drop_na()
```

```{r}
threeInt_subj_recovery_df %>%
  mutate(test_dLott = as.factor(test_dLott),
         test_dFrac = as.factor(test_dFrac),
         test_dArb = as.factor(test_dArb)) %>%
  # ggplot(aes(test_dLott, test_dFrac, fill=nll))+
   ggplot(aes(test_dLott, test_dArb, fill=nll))+
   # ggplot(aes(test_dFrac, test_dArb, fill=nll))+
  geom_tile()+
  # facet_wrap(~test_dArb)+
  facet_wrap(~test_dFrac)+
    # facet_wrap(~test_dLott)+
  theme(legend.position = "bottom")
```

```{r}
t1 = fit_task(data_= sim_subj, model_name_ = "model3", pars_ = list(dLott=0.01, dFrac=0.01, dArb=0.05, sigmaLott=.03, sigmaFrac = .03))
sum(log(t1$likelihood))
```
```{r}
t2 = fit_task(data_= sim_subj, model_name_ = "model3", pars_ = list(dLott=0.03, dFrac=0.06, dArb=0.05, sigmaLott=.03, sigmaFrac = .03))
sum(log(t2$likelihood))
```

Plot likelihood of each trial computed using the correct vs incorrect parameter against each other

For a lot of trials, which also have very small likelihoods the difference is very small. For trials with the highest likelihood, the likelihood computed using the true parameter is much larger. 

What proportion of trials is this "most likely" and what if you optimized to maximize based on the most likely trials?

Or maybe ignore all trials with likelihood below some threshold (e.g. .01) because estimates there are too noisy?

```{r}
t1 %>%
  mutate(fit_par_type="false", trial=1:n()) %>%
  rbind(t2 %>%
          mutate(fit_par_type = "true", trial=1:n())) %>%
  # rbind(t3 %>% 
          # mutate(fit_par_type = "false2", trial=1:n())) %>%
  select(likelihood, fit_par_type, trial) %>%
  spread(fit_par_type, likelihood) %>%
  ggplot(aes(true, false))+
  # ggplot(aes(false2, false))+
  geom_point()+
  geom_abline(aes(slope=1, intercept=0))
```
```{r}
t1 %>%
  mutate(fit_par_type="false", trial=1:n()) %>%
  rbind(t2 %>%
          mutate(fit_par_type = "true", trial=1:n())) %>%
  select(likelihood, fit_par_type, trial) %>%
  spread(fit_par_type, likelihood) %>%
  mutate(diff = true-false) %>%
  ggplot(aes(diff))+
  geom_histogram(bins=15, alpha=.5)
```

```{r}
t1 %>%
  filter(likelihood > quantile(likelihood, probs=c(.5))) %>%
  summarise(nll=-sum(log(likelihood)))
```

### Motivation for the model

Simulate data with a 3 integrator model using half the stimuli filtered earlier and this three integrator model.

**Note: this selection of parameters provides a nice qualitative fit to data. It assumes integration is slower for lotteries than for fractals. This is one way of capturing the difference in processing lottery values, which can only be done after the stimulus presentation, as apposed to fractal values which are learned about trialwise. There are alternative ways of modeling this: e.g. integration for the fractal integrator might start before the stimulus presentation screen; ndt for the lottery integrator (or the arbitrator when the lottery is more relevant) might be longer etc. The way to determine which of these hypotheses is most supported by data would be a model comparison.**

```{r}
# m3_1 = sim_task(sub_data, model_name = "model3", dLott=0.03, dFrac=0.06, dArb=0.05, sigmaLott = 0.03, sigmaFrac = 0.03)
m3_1 = sim_task(sub_data, model_name = "model3", dLott=0.03, dFrac=0.06, dArb=0.07, sigmaLott = 0.03, sigmaFrac = 0.03)
```

```{r}
sim_sanity_checks(m3_1, checks=c(1,3,4,5,6,7,8), compare_logits = TRUE)
```


# Fits to data

```{r}
cpueaters_path = '/Users/zeynepenkavi/CpuEaters/DescribedVsLearned_beh/analysis/helpers/'
source(paste0(helpers_path, 'optimPostProcess/get_optim_out.R'))
```

```{r}
sim_trial_list = list()
```

```{r}
# Extract set of stimuli that will be used for simulations
sub_stims = clean_beh_data %>%
  select(leftLotteryEV, rightLotteryEV, leftQValue, rightQValue, probFractalDraw, reactionTime, choiceLeft, subnum, distorted_ev_diff, distorted_qv_diff) %>%
  rename(EVLeft = leftLotteryEV, EVRight = rightLotteryEV, QVLeft = leftQValue, QVRight = rightQValue, distortedEVDiff = distorted_ev_diff, distortedQVDiff = distorted_qv_diff)
```


## One integrator


```{r}
optim_out_path = paste0(cpueaters_path, 'ddModels/cluster_scripts/optim_out/fitOneInt/')
subnums = c("01", "02", "03", "04", "05", "06", "07", "08", "09", "10", "11", "12", "13", "14", "15", "16", "17", "18", "19", "20", "22", "23", "24", "25", "27")
data_prefix ="sub"
data_suffix = "_data"
model = "oneIntegrator_sepProbDistortion"  

ddm_fit_pars = data.frame()

for(i in 1:length(subnums)){
  cur_subnum = subnums[i]
  tmp = get_optim_out(model_=model, data_=paste0(data_prefix, cur_subnum, data_suffix), optim_out_path_=optim_out_path, iters_ = F)
  tmp$subnum = cur_subnum
  ddm_fit_pars = rbind.all.columns(tmp, ddm_fit_pars)
}
```

Check if there is much variability in the converged values

```{r}
ddm_fit_pars %>%
  ggplot(aes(Param2))+
  geom_histogram(bins=10)+
  facet_wrap(~subnum)
```

There isn't so summarise subject parameters as a mean

```{r}
oneIntEsts = ddm_fit_pars %>%
  group_by(subnum) %>%
  summarise(d = mean(Param1),
            sigma = mean(Param2))
```

Make posterior predictive data

```{r}
source(paste0(helpers_path, 'ddModels/r_ddm_models/ddm_oneIntegrator_sepProbDistortion.R'))
sim_trial_list[['model1']] = sim_trial
```

```{r}

oneIntPpc = data.frame()

for(i in 1:length(unique(oneIntEsts$subnum))){
  cur_sub = unique(oneIntEsts$subnum)[i]
  cur_stims =  sub_stims %>% filter(subnum == cur_sub)
  cur_pars = oneIntEsts %>% filter(subnum == cur_sub)
  sim_subj = sim_task(cur_stims, model_name = "model1", d=cur_pars$d, sigma=cur_pars$sigma)
  oneIntPpc = rbind(oneIntPpc, sim_subj)
}

```

```{r}
sim_sanity_checks(oneIntPpc, checks=c(1,3,4,5,6,7,8), compare_logits = T, compare_rts = T, true_data = sub_stims)
```

## Three integrators

```{r}
optim_out_path = paste0(cpueaters_path, 'ddModels/cluster_scripts/optim_out/fitThreeInts/')
subnums = c("01", "02", "03", "04", "05", "06", "07", "08", "09", "10", "11", "12", "13", "14", "15", "16", "17", "18", "19", "20", "22", "23", "24", "25", "27")
data_prefix ="sub"
data_suffix = "_data"
model = "threeIntegrators_sepProbDistortion"  

ddm_fit_pars = data.frame()

for(i in 1:length(subnums)){
  cur_subnum = subnums[i]
  tmp = get_optim_out(model_=model, data_=paste0(data_prefix, cur_subnum, data_suffix), optim_out_path_=optim_out_path, iters_ = F)
  tmp$subnum = cur_subnum
  ddm_fit_pars = rbind.all.columns(tmp, ddm_fit_pars)
}
```

Check if there is much variability in the converged values

```{r}
ddm_fit_pars %>%
  ggplot(aes(Param1))+
  geom_histogram(bins=10)+
  facet_wrap(~subnum)
```

There isn't so summarise subject parameters as a mean

```{r}
threeIntEsts = ddm_fit_pars %>%
  group_by(subnum) %>%
  summarise(dLott = mean(Param1),
            dFrac = mean(Param2),
            dArb = mean(Param3),
            sigmaLott = mean(Param4),
            sigmaFrac = mean(Param5))
```

Make posterior predictive data

```{r}
source(paste0(helpers_path, 'ddModels/r_ddm_models/ddm_threeIntegrators_sepProbDistortion.R'))
# sim_trial_list = list()
sim_trial_list[['model3']] = sim_trial
```

```{r}

threeIntPpc = data.frame()

for(i in 1:length(unique(threeIntEsts$subnum))){
  cur_sub = unique(threeIntEsts$subnum)[i]
  cur_stims =  sub_stims %>% filter(subnum == cur_sub)
  cur_pars = threeIntEsts %>% filter(subnum == cur_sub)
  sim_subj = sim_task(cur_stims, model_name = "model3", dLott=cur_pars$dLott, dFrac=cur_pars$dFrac, dArb=cur_pars$dArb, sigmaLott=cur_pars$sigmaLott,  sigmaFrac=cur_pars$sigmaFrac)
  threeIntPpc = rbind(threeIntPpc, sim_subj)
}

```

```{r}
sim_sanity_checks(threeIntPpc, checks=c(1,3,4,5,6,7,8), compare_logits = T, compare_rts = T, true_data = sub_stims)
```


