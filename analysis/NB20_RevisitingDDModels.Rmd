---
title: 'Experience vs. description based decision-making project: Revisiting DD models'
output:
  html_document:
    toc: yes
    toc_float: yes
    code_folding: 'hide'
  pdf_document:
    toc: yes
---


```{r include=FALSE}
library(tidyverse)
theme_set(theme_bw())
library(here)
cbbPalette <- c("#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
helpers_path = here('analysis/helpers/')

source(paste0(helpers_path,'ddModels/sim_task.R'))
source(paste0(helpers_path,'ddModels/fit_task.R'))
source(paste0(helpers_path,'01_clean_behavioral_data.R'))
source(paste0(helpers_path, 'get_qvals.R'))
source(paste0(helpers_path,'optimPostProcess/sim_sanity_checks.R'))


set.seed(38573)
```

Add distorted value estimates using the hierarchical RL fit.

```{r message=FALSE}

source(paste0(helpers_path, 'rlModels/fit_rl_hierarchical_oneParamDoubleSymmLinearProbDistortion_rpeBoth.R'))

clean_beh_data = par_ests %>%
  group_by(subnum, par) %>%
  summarise(est = mean(value), .groups='keep') %>%
  spread(par, est) %>%
  left_join(clean_beh_data, by='subnum')

## Add Q values of fractals to each trial
clean_beh_data = clean_beh_data %>%
  group_by(subnum) %>%
  do(get_qvals(., model_name="original")) %>%
  ungroup()

clean_beh_data = clean_beh_data %>%
  mutate(rightLotteryEV = referenceProb * referenceValue,
         leftLotteryEV = lotteryValue * lotteryProb,
         lottery_ev_diff = leftLotteryEV - rightLotteryEV,
         fractal_qv_diff = leftQValue - rightQValue,
         distorted_ev_diff = (1-theta)*(1-probFractalDraw)*lottery_ev_diff,
         distorted_qv_diff = theta*probFractalDraw*fractal_qv_diff)
```

**Potential problem** for 3 integrator model: The model would predict slower decisions because the difference in the absolute value of each attribute integrator RDV would be small.

**BUT** by design there aren't trials that provide strong (distorted) evidence for a single side so for the current set of stimuli this should not be a concern.

```{r}
clean_beh_data %>%
  ggplot(aes(distorted_ev_diff, distorted_qv_diff)) +
  geom_point()+
  geom_abline(aes(slope=1, intercept=0))
```

Simulate data with a 3 integrator model.

Select half the data to use as input stimuli for simulated data.

```{r}
sub_data = clean_beh_data %>%
  filter(subnum  %in% c("01", "03", "05","07", "09", "11", "13", "15", "17", "19")) %>%
  select(leftLotteryEV, rightLotteryEV, leftQValue, rightQValue, probFractalDraw, reactionTime, choiceLeft, subnum, distorted_ev_diff, distorted_qv_diff) %>%
  rename(EVLeft = leftLotteryEV, EVRight = rightLotteryEV, QVLeft = leftQValue, QVRight = rightQValue, distortedEVDiff = distorted_ev_diff, distortedQVDiff = distorted_qv_diff)
```

Source trial simulating and fitting function three integrator model. The model only had the ddm parameters as variables; choice parameters (learning rate and probability distortion) are fitted elsewhere and used to compute the distorted value differences fed into this model.

```{r}
sim_trial_list = list()
source(paste0(helpers_path, 'ddModels/r_ddm_models/ddm_model4b_separatedProbDistortion.R'))
sim_trial_list[['model4b']] = sim_trial
```

Test if trial simulating function works.

```{r}
sim_trial(dLott=0.03, dFrac=0.04, dArb=0.04, sigmaLott = 0.03, sigmaFrac = 0.03, distortedEVDiff = sub_data$distortedEVDiff[100], distortedQVDiff = sub_data$distortedQVDiff[100], probFractalDraw = sub_data$probFractalDraw[100], barrierDecay = 0, EVLeft = sub_data$EVLeft[100], EVRight = sub_data$EVRight[100], QVLeft = sub_data$QVLeft[100], QVRight = sub_data$QVRight[100])
```

Simulate a dataset using half the stimuli filtered earlier and this three integrator model.

```{r}
m4b_1 = sim_task(sub_data, model_name = "model4b", dLott=0.03, dFrac=0.06, dArb=0.05, sigmaLott = 0.03, sigmaFrac = 0.03)
```

```{r}
sim_sanity_checks(m4b_1, checks=c(1,3,4,5,6,7,8), compare_logits = TRUE)
```

Are the predicted response times close to the true response times? Not really. Despite the apparent correspondence when looking at aggregate data grouped by probFractalDraw level the individual trial estimates are not correlated at all.

Does a well-established model do better in such an absolute check of model fit?

```{r}
m4b_1 %>%
  left_join(sub_data, by=c("EVLeft", "EVRight", "QVLeft", "QVRight", "distortedEVDiff", "distortedQVDiff", "probFractalDraw")) %>%
  ggplot(aes(reactionTime.y, reactionTime.x))+
  geom_point(color="light gray")+
  geom_smooth(formula="y~x", method="lm")+
  geom_abline(aes(slope=1, intercept=0), linetype="dashed")+
  xlab("True RT")+
  ylab("Predicted RT")
```

Check the fitting function

```{r}
fit_trial_list = list()
fit_trial_list[['model4b']] = fit_trial
```

```{r}
i = 100

fit_trial(dLott=0.03, dFrac=0.06, dArb=0.06, sigmaLott = 0.03, sigmaFrac = 0.03, barrierDecay=0, distortedEVDiff = m4b_1$distortedEVDiff[i],
    distortedQVDiff = m4b_1$distortedQVDiff[i], choice = m4b_1$choice[i], reactionTime = m4b_1$reactionTime[i], probFractalDraw = m4b_1$probFractalDraw[i], debug=TRUE)
```

Too slow..

```{r}
# optim_out = visualMLE::optim_save(c(.05, .05, .05, .05, .05, .05), get_task_nll, data=m4b_2, par_names = c("dArb", "dLott", "dFrac","sigmaArb", "sigmaLott", "sigmaFrac", ), model_name="model4b", fix_pars = list(bias = 0.1), control = list(maxit=100))

```

What does the distribution of the absolute value difference between two random variables look like?
Sampling approach
Can I get a sense of the mean of the arbitrator to use the Lombardi toolbox?


```{r}
get_abs_dist_moments = function(mu, sigma){
  
  # Definitions of moments
  # https://en.wikipedia.org/wiki/Folded_normal_distribution
  
  mu_y = sigma * sqrt(2/pi) * exp((-mu^2)/(2*sigma^2)) + mu * pracma::erf((mu)/(sqrt(2*sigma^2)))
  
  sigma_y = sqrt(mu^2 + sigma^2 - mu_y^2)
    
  return(list(mu_y = mu_y, sigma_y = sigma_y))
}


get_abs_diff_dist_moments = function(mu1, sigma1, mu2, sigma2){
  
  tmp = get_abs_dist_moments(mu1, sigma1)
  abs_mu1 = tmp$mu_y
  abs_sigma1 = tmp$sigma_y
  
  tmp = get_abs_dist_moments(mu2, sigma2)
  abs_mu2 = tmp$mu_y
  abs_sigma2 = tmp$sigma_y
  
  diff_mu = abs_mu1 - abs_mu2
  diff_sigma = sqrt(abs_sigma1^2 + abs_sigma2^2)
  
  # out = data.frame(abs_mu1 = abs_mu1, abs_sigma1 = abs_sigma1, abs_mu2 = abs_mu2, abs_sigma2 = abs_sigma2, diff_mu = diff_mu, diff_sigma = diff_sigma)
  out = list(diff_mu = diff_mu, diff_sigma = diff_sigma)
  
  return(out)
}
```

```{r}
mu1 = 0
sigma1 = 2
mu2 = -5
sigma2 = 2

data.frame(var1 = rnorm(10000, mean = mu1, sd = sigma1),
           var2 = rnorm(10000, mean = mu2, sd = sigma2)) %>%
  mutate(avar1 = abs(var1),
         avar2 = abs(var2),
         var3 = avar1 - avar2) %>%
  gather(key, value) %>%
  group_by(key) %>%
  summarise(mu = mean(value),
            sd = sd(value))
```

```{r}
get_abs_diff_dist_moments(mu1, sigma1, mu2, sigma2)
```

Interactive figure updating state probabilities

```{r}

```