---
title: 'Experience vs. description based decision-making project: Revisiting DD models'
output:
  html_document:
    toc: yes
    toc_float: yes
    code_folding: 'hide'
  pdf_document:
    toc: yes
---


```{r include=FALSE}
library(tidyverse)
theme_set(theme_bw())
library(here)
cbbPalette <- c("#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
helpers_path = here('analysis/helpers/')
source(paste0(helpers_path,'01_clean_behavioral_data.R'))
```

```{r message=FALSE}
source(paste0(helpers_path, 'get_qvals.R'))

source(paste0(helpers_path, 'rlModels/fit_rl_hierarchical_oneParamDoubleSymmLinearProbDistortion_rpeBoth.R'))

clean_beh_data = par_ests %>%
  group_by(subnum, par) %>%
  summarise(est = mean(value), .groups='keep') %>%
  spread(par, est) %>%
  left_join(clean_beh_data, by='subnum')

## Add Q values of fractals to each trial
clean_beh_data = clean_beh_data %>%
  group_by(subnum) %>%
  do(get_qvals(., model_name="original")) %>%
  ungroup()

clean_beh_data = clean_beh_data %>%
  mutate(rightLotteryEV = referenceProb * referenceValue,
         leftLotteryEV = lotteryValue * lotteryProb,
         lottery_ev_diff = leftLotteryEV - rightLotteryEV,
         fractal_qv_diff = leftQValue - rightQValue,
         distorted_ev_diff = (1-theta)*(1-probFractalDraw)*lottery_ev_diff,
         distorted_qv_diff = theta*probFractalDraw*fractal_qv_diff)
```

**Potential problem** for 3 integrator model: The model would predict slower decisions because the difference in the absolute value of each attribute integrator RDV would be small.

**BUT** by design there aren't trials that provide strong (distorted) evidence for a single side so for the current set of stimuli this should not be a concern.

```{r}
clean_beh_data %>%
  ggplot(aes(distorted_ev_diff, distorted_qv_diff)) +
  geom_point()+
  geom_abline(aes(slope=1, intercept=0))
```

Simulate data with a 3 integrator model.

```{r message=FALSE}
source(paste0(helpers_path,'ddModels/sim_task.R')) # do this first not to mess with cluster setup?
source(paste0(helpers_path,'optimPostProcess/sim_sanity_checks.R'))

set.seed(38573)
```

Select half the data to use as input stimuli for simulated data.

```{r}
sub_data = clean_beh_data %>%
  filter(subnum  %in% c("01", "03", "05","07", "09", "11", "13", "15", "17", "19")) %>%
  select(leftLotteryEV, rightLotteryEV, leftQValue, rightQValue, probFractalDraw, reactionTime, choiceLeft, subnum, distorted_ev_diff, distorted_qv_diff) %>%
  rename(EVLeft = leftLotteryEV, EVRight = rightLotteryEV, QVLeft = leftQValue, QVRight = rightQValue, distortedEVDiff = distorted_ev_diff, distortedQVDiff = distorted_qv_diff)
```

Source trial simulating and fitting function three integrator model. The model only had the ddm parameters as variables; choice parameters (learning rate and probability distortion) are fitted elsewhere and used to compute the distorted value differences fed into this model.

```{r}
sim_trial_list = list()
source(paste0(helpers_path, 'ddModels/r_ddm_models/ddm_model4b_separatedProbDistortion.R'))
sim_trial_list[['model4b']] = sim_trial
```

Test if trial simulating function works.

```{r}
sim_trial(dLott=0.03, dFrac=0.04, dArb=0.04, sigmaLott = 0.03, sigmaFrac = 0.03, sigmaArb = 0.01, distortedEVDiff = sub_data$distortedEVDiff[100], distortedQVDiff = sub_data$distortedQVDiff[100], probFractalDraw = sub_data$probFractalDraw[100], barrierDecay = 0, EVLeft = sub_data$EVLeft[100], EVRight = sub_data$EVRight[100], QVLeft = sub_data$QVLeft[100], QVRight = sub_data$QVRight[100])
```

Simulate a dataset using half the stimuli filtered earlier and this three integrator model.

```{r}
m4b_1 = sim_task(sub_data, model_name = "model4b", dLott=0.04, dFrac=0.03, dArb=0.06, sigmaLott = 0.03, sigmaFrac = 0.03, sigmaArb = 0.01)
```

Check how well the RT patterns in the simulated data match the true data.

With this parameter setting predicted choice is systematically slower for trials where the fractals matter more. The true data histograms versus predicted density curves also do not look in general.

```{r}
sim_sanity_checks(m4b_1, checks=c(1,3,4))
```

Increasing the fractal drift rate can take care of the slower choice for when fractals are more relevant to a large degree except for the edge case trials where only the fractals matter.

```{r}
m4b_2 = sim_task(sub_data, model_name = "model4b", dLott=0.03, dFrac=0.06, dArb=0.06, sigmaLott = 0.03, sigmaFrac = 0.03, sigmaArb = 0.01)
```

```{r}
sim_sanity_checks(m4b_2, checks=c(1,3,4))
```

Are the effects by value difference there?

```{r}
m4b_2 %>%
  mutate(lottery_ev_diff = round(abs(EVLeft - EVRight),3),
         lottery_ev_diff = ifelse(lottery_ev_diff ==0, "no EV diff", ifelse(lottery_ev_diff == .2, "small EV diff", ifelse(lottery_ev_diff == .4, "large EV diff", NA))),
         lottery_ev_diff = factor(lottery_ev_diff, levels=c("no EV diff", "small EV diff", "large EV diff"), labels = c("no", "small", "large")),
         logRt = log(reactionTime),
         probFractalDraw = as.factor(probFractalDraw)) %>%
  group_by(probFractalDraw, lottery_ev_diff) %>%
  summarise(.groups = "keep",
            mean_logRt = mean(logRt),
            sem_logRt = sd(logRt)/sqrt(n())) %>%
  ggplot(aes(probFractalDraw, mean_logRt,color=lottery_ev_diff))+
  geom_point(position=position_dodge(width=.5))+
  geom_errorbar(aes(ymin = mean_logRt - sem_logRt, ymax = mean_logRt + sem_logRt), width=.2,position=position_dodge(width=.5))+
  theme(legend.position = "bottom")+
  labs(color="Lottery EV difference", y="Mean Log RT", x="p(Fractal)")+
  scale_color_manual(values = c(cbbPalette[3], cbbPalette[5:6]))
```

Model not surprisingly predicts QV diff effects on RTs BUT note that these QV diff bins are not grouped by subject.

So effectively this assumes the same drift properties for all subjects and 

Maybe this isn't a good way of looking at value difference effects. Maybe instead I should use absolute distorted value.

```{r}
m4b_2 %>%
  mutate(logRt = log(reactionTime),
         QVDiff = abs(QVLeft - QVRight),
         diff_level = ifelse(QVDiff < quantile(QVDiff, probs=c(.33))[[1]], "small",
                             ifelse(QVDiff > quantile(QVDiff, probs=c(.66))[[1]], "large", "medium")),
         diff_level = factor(diff_level, levels=c("small", "medium", "large")),
         probFractalDraw = as.factor(probFractalDraw)) %>%
  group_by(probFractalDraw, diff_level) %>%
  summarise(.groups = "keep",
            mean_logRt = mean(logRt),
            sem_logRt = sd(logRt)/sqrt(n())) %>%
  ggplot(aes(probFractalDraw, mean_logRt,color=diff_level))+
  geom_point(position=position_dodge(width=.5))+
  geom_errorbar(aes(ymin = mean_logRt - sem_logRt, ymax = mean_logRt + sem_logRt), width=.2,position=position_dodge(width=.5))+
  theme(legend.position = "bottom")+
  labs(color="Fractal QV difference", y="Mean Log RT", x="p(Fractal)")+
  scale_color_manual(values = c(cbbPalette[3], cbbPalette[5:6]))
```

```{r}
sub_data %>%
  group_by(subnum) %>%
  mutate(logRt = log(reactionTime),
         QVDiff = abs(QVLeft - QVRight),
         diff_level = ifelse(QVDiff < quantile(QVDiff, probs=c(.33))[[1]], "small",
                             ifelse(QVDiff > quantile(QVDiff, probs=c(.66))[[1]], "large", "medium")),
         diff_level = factor(diff_level, levels=c("small", "medium", "large")),
         probFractalDraw = as.factor(probFractalDraw)) %>%
  group_by(probFractalDraw, diff_level) %>%
  summarise(.groups = "keep",
            mean_logRt = mean(logRt),
            sem_logRt = sd(logRt)/sqrt(n())) %>%
  ggplot(aes(probFractalDraw, mean_logRt,color=diff_level))+
  geom_point(position=position_dodge(width=.5))+
  geom_errorbar(aes(ymin = mean_logRt - sem_logRt, ymax = mean_logRt + sem_logRt), width=.2,position=position_dodge(width=.5))+
  theme(legend.position = "bottom")+
  labs(color="Fractal QV difference", y="Mean Log RT", x="p(Fractal)")+
  scale_color_manual(values = c(cbbPalette[3], cbbPalette[5:6]))
```

```{r}
sub_data %>%
  ggplot(aes(abs(distortedEVDiff), reactionTime))+
  geom_point()+
  geom_smooth(method="lm", formula='y~x')
```

Are the effects by what the choice depends on there?

```{r}

```

Are the predicted response times close to the true response times? No! Despite the apparent correspondance when looking at aggregate data grouped by probFractalDraw level the individual trial estimates are not correlated at all.

```{r}
m4b_2 %>%
  left_join(sub_data, by=c("EVLeft", "EVRight", "QVLeft", "QVRight", "distortedEVDiff", "distortedQVDiff", "probFractalDraw")) %>%
  ggplot(aes(reactionTime.y, reactionTime.x))+
  geom_point(color="light gray")+
  geom_smooth(formula="y~x", method="lm")+
  geom_abline(aes(slope=1, intercept=0), linetype="dashed")+
  xlab("True RT")+
  ylab("Predicted RT")
```

Does a well-established model do better in such an absolute check of model fit????


Check the fitting function

```{r}

```
