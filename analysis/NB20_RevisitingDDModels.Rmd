---
title: 'Experience vs. description based decision-making project: Revisiting DD models'
output:
  html_document:
    toc: yes
    toc_float: yes
    code_folding: 'hide'
  pdf_document:
    toc: yes
---

```{r include=FALSE}
library(tidyverse)
theme_set(theme_bw())
library(here)
cbbPalette <- c("#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
helpers_path = here('analysis/helpers/')

source(paste0(helpers_path,'ddModels/sim_task.R'))
source(paste0(helpers_path,'ddModels/fit_task.R'))
source(paste0(helpers_path,'01_clean_behavioral_data.R'))
source(paste0(helpers_path, 'get_qvals.R'))
source(paste0(helpers_path,'optimPostProcess/sim_sanity_checks.R'))


set.seed(38573)
```

Add distorted value estimates using the hierarchical RL fit.

```{r message=FALSE, warning=FALSE}

source(paste0(helpers_path, 'rlModels/fit_rl_hierarchical_oneParamDoubleSymmLinearProbDistortion_rpeBoth.R'))

clean_beh_data = par_ests %>%
  group_by(subnum, par) %>%
  summarise(est = mean(value), .groups='keep') %>%
  spread(par, est) %>%
  left_join(clean_beh_data, by='subnum')

## Add Q values of fractals to each trial
clean_beh_data = clean_beh_data %>%
  group_by(subnum) %>%
  do(get_qvals(., model_name="original")) %>%
  ungroup()

clean_beh_data = clean_beh_data %>%
  mutate(rightLotteryEV = referenceProb * referenceValue,
         leftLotteryEV = lotteryValue * lotteryProb,
         lottery_ev_diff = leftLotteryEV - rightLotteryEV,
         fractal_qv_diff = leftQValue - rightQValue,
         distorted_ev_diff = (1-theta)*(1-probFractalDraw)*lottery_ev_diff,
         distorted_qv_diff = theta*probFractalDraw*fractal_qv_diff)

rm(fit, g_par_est, par_ests)
```

**Potential problem** for 3 integrator model: The model would predict slower decisions because the difference in the absolute value of each attribute integrator RDV would be small.

**BUT** by design there aren't trials that provide strong (distorted) evidence for a single side so for the current set of stimuli this should not be a concern.

```{r}
clean_beh_data %>%
  ggplot(aes(distorted_ev_diff, distorted_qv_diff)) +
  geom_point()+
  geom_abline(aes(slope=1, intercept=0))
```


```{r}
# Extract set of stimuli that will be used for simulations
sub_data = clean_beh_data %>%
  filter(subnum  %in% c("01", "03", "05","07", "09", "11", "13", "15", "17", "19")) %>%
  select(leftLotteryEV, rightLotteryEV, leftQValue, rightQValue, probFractalDraw, reactionTime, choiceLeft, subnum, distorted_ev_diff, distorted_qv_diff) %>%
  rename(EVLeft = leftLotteryEV, EVRight = rightLotteryEV, QVLeft = leftQValue, QVRight = rightQValue, distortedEVDiff = distorted_ev_diff, distortedQVDiff = distorted_qv_diff)
```

# The 3 integrator model

Source trial simulating and fitting function three integrator model. The model only had the ddm parameters as variables; choice parameters (learning rate and probability distortion) are fitted elsewhere and used to compute the distorted value differences fed into this model.

```{r}
sim_trial_list = list()
source(paste0(helpers_path, 'ddModels/r_ddm_models/ddm_threeIntegrators_sepProbDistortion.R'))
sim_trial_list[['model3']] = sim_trial
```

Test if trial simulating function works.

**ANNNOTATE THIS PLOT AUTOMATICALLY**

```{r}
i=300
tmp = sim_trial(dLott=0.03, dFrac=0.06, dArb=0.07, sigmaLott = 0.03, sigmaFrac = 0.03, distortedEVDiff = sub_data$distortedEVDiff[i], distortedQVDiff = sub_data$distortedQVDiff[i], probFractalDraw = sub_data$probFractalDraw[i], barrierDecay = 0, EVLeft = sub_data$EVLeft[i], EVRight = sub_data$EVRight[i], QVLeft = sub_data$QVLeft[i], QVRight = sub_data$QVRight[i], debug=TRUE)

tmp$debug_df %>%
  select(arbitratorRDV, lotteryRDV, fractalRDV, time) %>%
  gather(key, value, -time) %>%
  ggplot(aes(time, value, color=key))+
  geom_line()+
  geom_hline(aes(yintercept=1))+
  geom_hline(aes(yintercept=-1))+
  geom_hline(aes(yintercept=0), linetype="dashed")+
  theme(legend.position = "bottom")

```
```{r}
i=300
tmp = sim_trial(dLott=0.03, dFrac=0.06, dArb=0.07, sigmaLott = 0.03, sigmaFrac = 0.03, distortedEVDiff = sub_data$distortedEVDiff[i], distortedQVDiff = sub_data$distortedQVDiff[i], probFractalDraw =1, barrierDecay = 0, EVLeft = sub_data$EVLeft[i], EVRight = sub_data$EVRight[i], QVLeft = sub_data$QVLeft[i], QVRight = sub_data$QVRight[i], debug=TRUE)

tmp$debug_df %>%
  select(arbitratorRDV, lotteryRDV, fractalRDV, time) %>%
  gather(key, value, -time) %>%
  ggplot(aes(time, value, color=key))+
  geom_line()+
  geom_hline(aes(yintercept=1))+
  geom_hline(aes(yintercept=-1))+
  geom_hline(aes(yintercept=0), linetype="dashed")+
  theme(legend.position = "bottom")

tmp
```

## Aggregate checks 

Simulate data with a 3 integrator model using half the stimuli filtered earlier and this three integrator model.

**Note: this selection of parameters provides a nice qualitative fit to data. It assumes integration is slower for lotteries than for fractals. This is one way of capturing the difference in processing lottery values, which can only be done after the stimulus presentation, as apposed to fractal values which are learned about trialwise. There are alternative ways of modeling this: e.g. integration for the fractal integrator might start before the stimulus presentation screen; ndt for the lottery integrator (or the arbitrator when the lottery is more relevant) might be longer etc. The way to determine which of these hypotheses is most supported by data would be a model comparison.**

```{r}
# m3_1 = sim_task(sub_data, model_name = "model3", dLott=0.03, dFrac=0.06, dArb=0.05, sigmaLott = 0.03, sigmaFrac = 0.03)
m3_1 = sim_task(sub_data, model_name = "model3", dLott=0.03, dFrac=0.06, dArb=0.07, sigmaLott = 0.03, sigmaFrac = 0.03)
```

```{r}
sim_sanity_checks(m3_1, checks=c(1,3,4,5,6,7,8), compare_logits = TRUE)
```

## Question: Absolute check

Are the predicted response times close to the true response times? Not really. Despite the apparent correspondence when looking at aggregate data grouped by probFractalDraw level the individual trial estimates are not correlated at all.

Does a well-established model do better in such an absolute check of model fit?

```{r}
m3_1 %>%
  left_join(sub_data, by=c("EVLeft", "EVRight", "QVLeft", "QVRight", "distortedEVDiff", "distortedQVDiff", "probFractalDraw")) %>%
  ggplot(aes(reactionTime.y, reactionTime.x))+
  geom_point(color="light gray")+
  geom_smooth(formula="y~x", method="lm")+
  geom_abline(aes(slope=1, intercept=0), linetype="dashed")+
  xlab("True RT")+
  ylab("Predicted RT")
```

# Recovery checks

Using Gabi's discrete time and state-space method

**Why might this not have been used previously? Some ideas:**  
**The boundary in traditional DDM is not fixed at 1 and -1. Instead it is a parameter. It's not immediately apparent to me how to use the sum of random variables approach without assuming the boundaries at 1 and -1.**
**The traditional DDM often models the whole of a response time distribution for correct vs incorrect.**


## One integrator

```{r}
source(paste0(helpers_path, 'ddModels/r_ddm_models/ddm_oneIntegrator_sepProbDistortion.R'))
```

### Same trial

```{r}
d = 0.03
distortedEVDiff = .3
distortedQVDiff = .1
sigma = .05
n_particles = 250
sim_data = data.frame()

for(i in 1:n_particles){
  tmp = sim_trial(d = d, sigma = sigma, distortedEVDiff =distortedEVDiff, distortedQVDiff =distortedQVDiff, EVLeft = NA, EVRight = NA, QVLeft = NA, QVRight = NA, probFractalDraw = NA)
  tmp$iter = i
  sim_data = rbind(sim_data, tmp)
}
```

```{r}
fit_trial_list = list(model1 = fit_trial)

d_range = seq(.01, .1, .01)
sigma_range = seq(.01, .1, .01)

recovery_df = data.frame(test_d = NA, test_sigma = NA, nll = NA)

for(i in 1:length(d_range)){
  for(j in 1:length(sigma_range)){
    test_d = d_range[i]
    test_sigma = sigma_range[j]
    test_nll = get_task_nll(data_ = sim_data, par = c(test_d, test_sigma), par_names_ = c("d", "sigma"), model_name = "model1", fix_pars_ = list())
    recovery_df = rbind(recovery_df,
                        data.frame(test_d = test_d, test_sigma = test_sigma, nll = test_nll))
    
  }
}
recovery_df = recovery_df %>% drop_na()
```


```{r}
recovery_df %>%
  mutate(test_d = as.factor(test_d),
         test_sigma = as.factor(test_sigma)) %>%
  ggplot(aes(test_d, test_sigma, fill=nll))+
  geom_tile()

#Zoom in
recovery_df %>%
  filter(test_sigma>.04 & test_d < .06)%>%
  mutate(test_d = as.factor(test_d),
         test_sigma = as.factor(test_sigma)) %>%
  ggplot(aes(test_d, test_sigma, fill=nll))+
  geom_tile()
```

### Different trials (~single subject)

```{r}
sim_trial_list = list()
sim_trial_list[['model1']] = sim_trial
```

```{r}
n_trials = 300
stimuli = clean_beh_data[1:n_trials,] %>%
  select(leftLotteryEV, rightLotteryEV, leftQValue, rightQValue, probFractalDraw, reactionTime, choiceLeft, subnum, distorted_ev_diff, distorted_qv_diff) %>%
  rename(EVLeft = leftLotteryEV, EVRight = rightLotteryEV, QVLeft = leftQValue, QVRight = rightQValue, distortedEVDiff = distorted_ev_diff, distortedQVDiff = distorted_qv_diff)
sim_subj = sim_task(stimuli, model_name = "model1", d=d, sigma=sigma)
# sim_subj
```

```{r}
d_range = seq(.01, .1, .02)
sigma_range = seq(.01, .1, .02)

recovery_df = data.frame(test_d = NA, test_sigma = NA, nll = NA)

for(i in 1:length(d_range)){
  for(j in 1:length(sigma_range)){
    test_d = d_range[i]
    test_sigma = sigma_range[j]
    test_nll = get_task_nll(data_ = sim_subj, par = c(test_d, test_sigma), par_names_ = c("d", "sigma"), model_name = "model1", fix_pars_ = list())
    recovery_df = rbind(recovery_df,
                        data.frame(test_d = test_d, test_sigma = test_sigma, nll = test_nll))
    
  }
}
recovery_df = recovery_df %>% drop_na()

```

```{r}
recovery_df %>%
  mutate(test_d = as.factor(test_d),
         test_sigma = as.factor(test_sigma)) %>%
  ggplot(aes(test_d, test_sigma, fill=nll))+
  geom_tile()

recovery_df %>%
  filter(test_sigma > .03) %>%
  mutate(test_d = as.factor(test_d),
         test_sigma = as.factor(test_sigma)) %>%
  ggplot(aes(test_d, test_sigma, fill=nll))+
  geom_tile()
```


## Three integrators

Extending the state space approach

```{r}
source(paste0(helpers_path, 'ddModels/r_ddm_models/ddm_threeIntegrators_sepProbDistortion.R'))
```

### Same trial

```{r}
d = 0.03
distortedEVDiff = .3
distortedQVDiff = .1
sigma = .05
n_particles = 250
sim_data = data.frame()

for(i in 1:n_particles){
  tmp = sim_trial(dLott=0.03, dFrac=0.06, dArb=0.05, sigmaLott = 0.03, sigmaFrac = 0.03, distortedEVDiff =distortedEVDiff, distortedQVDiff = distortedQVDiff, EVLeft = NA, EVRight = NA, QVLeft = NA, QVRight = NA, probFractalDraw = .5, barrierDecay = 0)
  tmp$iter = i
  sim_data = rbind(sim_data, tmp)
}
```

```{r}
fit_trial_list = list(model3 = fit_trial)

dLott_range = c(.01, .03, .09)
dFrac_range = c(.01, .06, .09)
dArb_range = c(.01, .05, .09)
sigma_fix = .03

recovery_df = data.frame(test_dLott = NA, test_dFrac = NA, test_dArb = NA, nll = NA)

for(i in 1:length(dLott_range)){
  for(j in 1:length(dFrac_range)){
    for(k in 1:length(dArb_range)){
      test_dLott = dLott_range[i]
      test_dFrac = dFrac_range[j]
      test_dArb = dArb_range[k]
      test_nll = get_task_nll(data_ = sim_data, par = c(test_dLott, test_dFrac, test_dArb, sigma_fix, sigma_fix), par_names_ = c("dLott", "dFrac", "dArb","sigmaLott", "sigmaFrac"), model_name = "model3", fix_pars_ = list())
      recovery_df = rbind(recovery_df,
                          data.frame(test_dLott = test_dLott, test_dFrac = test_dFrac, test_dArb = test_dArb, nll = test_nll))
    }
  }
}
recovery_df = recovery_df %>% drop_na()
```

```{r}
recovery_df %>%
  arrange(nll)
```

### Folded distribution schematic representation

```{r}
numTimeSteps = 1000
# muLott = .03*0.3
muLott = .25
sigmaLott = 0.03
# muFrac = .06*(-.1)
muFrac = -.1
sigmaFrac = 0.03


data.frame(timeStep = 1:numTimeSteps,
           changeLott = rnorm(numTimeSteps , muLott, sigmaLott),
           changeFrac = rnorm(numTimeSteps, muFrac, sigmaFrac)) %>%
  mutate(RDVLott = cumsum(changeLott),
         RDVFrac = cumsum(changeFrac),
         absRDVLott = abs(RDVLott),
         absRDVFrac = abs(RDVFrac),
         changeArb = absRDVLott - absRDVFrac,
         RDVArb = cumsum(changeArb)) %>%
  summarise(meanChangeArb = mean(changeArb),
            sdChangeArb = sd(changeArb))
  # select(RDVLott, RDVFrac, RDVArb, timeStep) %>%
  # gather(key, value, -timeStep) %>%
  # ggplot(aes(timeStep, value, color=key))+
  # geom_line()+
  # geom_point()

```

Expected change and its sd **at time t** for the arbitrator. This is what you can use in the loop for estimation.

```{r}
get_abs_diff_dist_moments(muLott*numTimeSteps, sqrt(sigmaLott^2*numTimeSteps), muFrac*numTimeSteps, sqrt(sigmaFrac^2*numTimeSteps))
```

Mean/expected constant change of the arbitrator for whole timecourse

```{r}
get_abs_diff_dist_moments(muLott, sigmaLott, muFrac, sigmaFrac)$diff_mu*sum(1:numTimeSteps)/numTimeSteps
```


```{r}
data.frame(prStatesArb) %>%
  mutate(state= 1:n()) %>%
  gather(time, value, -state) %>%
  ggplot(aes(time, state, fill=value))+
  geom_tile()
```

## TBD

- What do you with these for the neuroimaging analyses?
- Model all subjects together? Or can you get hierarchical Bayesian posteriors?
- Are the individual parameter needed for anything or is the more interesting question one of model comparison to explain the RT patterns?