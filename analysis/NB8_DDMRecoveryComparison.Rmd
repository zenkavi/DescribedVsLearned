---
title: "Experience vs. description based decision-making project: DDM parameter recovery comparison with grid search and `optim`"
output: 
  html_document:
    toc: true
    toc_float: true
    code_folding: 'hide'
---

# Setup

Set up environment and load in data

```{r include=FALSE, message=FALSE}
library(tidyverse)
library(here)
cbbPalette <- c("#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
theme_set(theme_classic())
sem <- function(x) {sd(x, na.rm=T) / sqrt(length(x))}
helpers_path = here('analysis/helpers/')

set.seed(38573)
```

```{r message=FALSE}
source(paste0(helpers_path,'ddmSims/fit_task.R'))
source(paste0(helpers_path,'ddmSims/sim_task.R'))
source(paste0(helpers_path,'ddmSims/fit_ddm_pta.R'))
test_trial_conditions = read.csv(paste0(helpers_path, 'ddmSims/test_data/test_trial_conditions.csv'))
```

```{r include=FALSE, message=FALSE}
library(visualMLE)
```

Empty lists to store the trial simulators for the forthcoming models.

```{r}
sim_trial_list = list()
fit_trial_list = list()
```

# Grid search with posterior model probability

## Model 1

```{r}
source(paste0(helpers_path, 'ddmSims/r_ddm_models/ddm_model1.R'))

sim_trial_list[['model1']] = sim_trial
fit_trial_list[['model1']] = fit_trial
```

Simulate data

```{r}
d = .06
sigma = .08
rangeD = c(0.05, 0.06, 0.07)
rangeSigma = c(0.065, 0.08, 0.095)
trialsFileName=NA
trialsPerCondition=250 
```

```{r}
# Replicate same conditions n times
test_data = dplyr::bind_rows(replicate(trialsPerCondition, test_trial_conditions, simplify = FALSE))

# Simulate choice and RT for the replicated trial conditions
test_data = sim_task(test_data, model_name = "model1", d = d, sigma = sigma) %>%drop_na()
```

Fit using PTA

```{r}
numModels = length(rangeD) * length(rangeSigma)
likelihoods = list()
models = c()
posteriors = list()

# Get likelihoods for all models and all artificial trials.
for (i in 1:length(rangeD)){
  curD = rangeD[i]
  for (j in 1:length(rangeSigma)){
    curSigma = rangeSigma[j]
    model = paste0(as.character(curD), ", ", as.character(curSigma))
    curFit = fit_task(test_data, model_name = "model1", pars_ = list(d=curD, sigma = curSigma))
    likelihoods[[model]] = curFit$likelihood
    models = c(models, model)
    posteriors[[model]] = 1/numModels
  }
}
```

```{r}
# Compute the posteriors.
for(t in 1:nrow(test_data)){
  denominator = 0
  for(m in 1:length(models)){
    model = models[m]
    denominator = denominator + (posteriors[[model]] * likelihoods[[model]][t]) 
    if(denominator == 0){
      next
    }
  }
  
  for(m in 1:length(models)){
    model = models[m]
    prior = posteriors[[model]]
    posteriors[[model]] = likelihoods[[model]][t] * prior /denominator
  }
}
```

Likelihood surface

```{r}
data.frame(m = models) %>%
  separate(m, c("d", "sigma"), sep= ",") %>%
  mutate(likelihoods = unlist(lapply(likelihoods, sum), use.names = FALSE)) %>%
  ggplot(aes(sigma, d, fill=likelihoods))+
  geom_tile()
```

```{r eval=FALSE}
# What do the likelihoods for each trial look like for each model? Of comparable ranges, rising and falling similarly for each trial.

data.frame(likelihoods) %>%
  gather(key, value) %>%
  ggplot(aes(value))+
  geom_histogram(bins=30, alpha=.5, position="identity")+
  facet_grid(key~.)

data.frame(likelihoods) %>%
  gather(key, value) %>%
  group_by(key) %>%
  mutate(trial = 1:n()) %>%
  ggplot(aes(trial, value))+
  geom_line()+
  facet_grid(key~.)+
  xlim(0, 200)
```

Model posteriors

```{r}
data.frame(m = models) %>%
  separate(m, c("d", "sigma"), sep= ",") %>%
  mutate(posteriors = unlist(posteriors, use.names = FALSE)) %>%
  ggplot(aes(sigma, d, fill=posteriors))+
  geom_tile()
```

How do the posteriors change across trials for each parameter combination?

```{r}
posteriors_tbt = list()

for (i in 1:length(models)){
  model = models[i]
  posteriors_tbt[[model]] = c(1/numModels, rep(NA,length(likelihoods[[1]])-1))
}

```

```{r}
# Compute the posteriors.
for(t in 1:nrow(test_data)){
  denominator = 0
  for(m in 1:length(models)){
    model = models[m]
    denominator = denominator + (posteriors_tbt[[model]][t] * likelihoods[[model]][t]) 
    if(denominator == 0){
      next
    }
  }
  
  for(m in 1:length(models)){
    model = models[m]
    prior = posteriors_tbt[[model]][t]
    posteriors_tbt[[model]][t+1] = likelihoods[[model]][t] * prior /denominator
  }
}
```

```{r}
tmp = dplyr::bind_rows(replicate(nrow(test_data)+1, data.frame(m = models), simplify = FALSE)) %>%
  arrange(m) %>%
  mutate(posteriors = unlist(posteriors_tbt, use.names = FALSE)) %>%
  group_by(m) %>%
  mutate(trial = 1:n()) 
```

Posteriors maxes out in relatively few trials for the true model.  

In this case there are 21 combinations repeated 250 times. Since `fit_task` takes in `test_data` which repeats these 21 trials in a single block the maxing out should be happening after all trials have been fit about 20 times (400 on the plot above). So you should be able to get to correct parameter combination with much fewer trials.

```{r}
tmp %>%
  ggplot(aes(trial, posteriors, color=m))+
  geom_line()+
  theme(legend.position = "bottom")+
  xlim(0, 500)
```
```{r}
rm(likelihoods, posteriors, posteriors_tbt, numModels, models)
```

Confirm that you can indeed recover the parameters with fewer repetitions.

```{r}
trialsPerCondition=25 

# Replicate same conditions n times
test_data = dplyr::bind_rows(replicate(trialsPerCondition, test_trial_conditions, simplify = FALSE))

# Simulate choice and RT for the replicated trial conditions
test_data = sim_task(test_data, model_name = "model1", d = d, sigma = sigma) %>%drop_na()
```

```{r}
out = fit_ddm_pta(data_to_fit_ = test_data, model_name_ = "model1", search_space_ = list(rangeD = rangeD, rangeSigma = rangeSigma))
```

```{r}
data.frame(m = out$models) %>%
  separate(m, c("d", "sigma", "delta", "gamma"), sep= ",") %>%
  mutate(posteriors = unlist(out$posteriors, use.names = FALSE)) %>%
  ggplot(aes(sigma, d, fill=posteriors))+
  geom_tile()
```

Ok, this was for the simplest model. Does it work for a more complicated model?

Initially considered trying Model 2b. This is the one with early integration for the `probFractalDraw == 1` case and probability distortion for the fractals. This had captured several aspects of the true data in simulations. 

Initial efforts (no longer shown here) failed to recover the true parameters. There might be at least two reasons for this:  

1. Grid search happened only for d and sigma and not for the other two parameters (delta and gamma), which were set to 1 both in simulating and fitting the task.  

2. The trial likelihood calculation using the state-space approach depends on the assumption that integration happens until the RT as a function of the value difference. For a model where early integration is allowed it is possible that a decision is reached before the stimuli are presented and the RT is then sampled from some log-normal distribution. In such cases the RT that would be looped until is not generated as a function of the value difference in the model. **So how would the state likelihood estimation should work when early integration is allowed?**  

So first check if a model with distortion but no early integration converges on the correct parameter combination. 

## Model 1b

This model expands the simplest model by adding probability distortion to the fractals but does not have early integration for the `probFractalDraw == 1` case.

```{r}
source(paste0(helpers_path, 'ddmSims/r_ddm_models/ddm_model1b.R'))
```

```{r}
sim_trial_list[['model1b']] = sim_trial
fit_trial_list[['model1b']] = fit_trial
```

Setting only d and sigma and leaving delta and gamma at 1.

```{r}
trialsPerCondition=50 

# Replicate same conditions n times
test_data = dplyr::bind_rows(replicate(trialsPerCondition, test_trial_conditions, simplify = FALSE))

# Simulate choice and RT for the replicated trial conditions
test_data = sim_task(test_data, model_name = "model1b", d = d, sigma = sigma) %>%drop_na()
```

```{r}
out = fit_ddm_pta(data_to_fit_ = test_data, model_name_ = "model1b", search_space_= list(rangeD = rangeD, rangeSigma = rangeSigma))
```

Successful recovery even with 50 particles per trial condition.

```{r}
data.frame(m = out$models) %>%
  separate(m, c("d", "sigma", "delta", "gamma"), sep= ",") %>%
  mutate(posteriors = unlist(out$posteriors, use.names = FALSE)) %>%
  ggplot(aes(sigma, d, fill=posteriors))+
  geom_tile()
```

What about with a different combination of delta and gamma but still only doing a grid search through delta and sigma?

```{r}
trialsPerCondition=50 

# Replicate same conditions n times
test_data = dplyr::bind_rows(replicate(trialsPerCondition, test_trial_conditions, simplify = FALSE))

test_data = sim_task(test_data, model_name = "model1b", d = d, sigma = sigma, delta=3, gamma=3) %>%drop_na()

out = fit_ddm_pta(data_to_fit_ = test_data, model_name_ = "model1b", search_space_ = list(rangeD = rangeD, rangeSigma = rangeSigma), posteriors_tbt_ = TRUE)
```

Have seen all possible cases (failed recovery, successful recovery and split posterior) with with 50 particles.

```{r}
data.frame(m = out$models) %>%
  separate(m, c("d", "sigma", "delta", "gamma"), sep= ",") %>%
  mutate(posteriors = unlist(out$posteriors, use.names = FALSE)) %>%
  ggplot(aes(sigma, d, fill=posteriors))+
  geom_tile()
```

How do the posteriors change trial by trial? Is the convergence fast or is there an in-between period with high uncertainty?

```{r}
tmp = dplyr::bind_rows(replicate(nrow(test_data)+1, data.frame(m = out$models), simplify = FALSE)) %>%
  arrange(m) %>%
  mutate(posteriors = unlist(out$posteriors_tbt, use.names = FALSE)) %>%
  group_by(m) %>%
  mutate(trial = 1:n()) 
```

```{r}
tmp %>%
  ggplot(aes(trial, posteriors, color=m))+
  geom_line()+
  theme(legend.position = "bottom")
```

What if you have more particles?

```{r}
trialsPerCondition=150 

# Replicate same conditions n times
test_data = dplyr::bind_rows(replicate(trialsPerCondition, test_trial_conditions, simplify = FALSE))

test_data = sim_task(test_data, model_name = "model1b", d = d, sigma = sigma, delta=3, gamma=3) %>%drop_na()

out = fit_ddm_pta(data_to_fit_ = test_data, model_name_ = "model1b", search_space_ = list(rangeD = rangeD, rangeSigma = rangeSigma), posteriors_tbt_ = TRUE)

data.frame(m = out$models) %>%
  separate(m, c("d", "sigma", "delta", "gamma"), sep= ",") %>%
  mutate(posteriors = unlist(out$posteriors, use.names = FALSE)) %>%
  ggplot(aes(sigma, d, fill=posteriors))+
  geom_tile()
```

```{r}
tmp = dplyr::bind_rows(replicate(nrow(test_data)+1, data.frame(m = out$models), simplify = FALSE)) %>%
  arrange(m) %>%
  mutate(posteriors = unlist(out$posteriors_tbt, use.names = FALSE)) %>%
  group_by(m) %>%
  mutate(trial = 1:n()) 
```

```{r}
tmp %>%
  ggplot(aes(trial, posteriors, color=m))+
  geom_line()+
  theme(legend.position = "bottom")
```

These managed to recover the true d and sigma but delta and gamma were incorrectly fixed at 1. What if you expand to search space to do a grid search across those as well?

Can you recover the true combination if the grid search included all the parameters?

```{r}
rangeDelta = c(1.5, 3, 4.5)
rangeGamma = c(1.5, 3, 4.5)
```

Reducing number of trials per condition because the search space will be much larger

```{r}
trialsPerCondition=30 

# Replicate same conditions n times
test_data = dplyr::bind_rows(replicate(trialsPerCondition, test_trial_conditions, simplify = FALSE))

test_data = sim_task(test_data, model_name = "model1b", d = d, sigma = sigma, delta=3, gamma=3) %>%drop_na()

out = fit_ddm_pta(data_to_fit_ = test_data, model_name_ = "model1b", search_space_ = list(rangeD = rangeD, rangeSigma = rangeSigma, rangeDelta = rangeDelta, rangeGamma =
                                                                                          rangeGamma), posteriors_tbt_ = TRUE)
```

I have seen both successful recovery and split posteriors between models but at least one of them is the correct one.

```{r}
data.frame(m = out$models) %>%
  separate(m, c("d", "sigma", "delta", "gamma"), sep= ",") %>%
  mutate(posteriors = unlist(out$posteriors, use.names = FALSE)) %>%
  mutate(d_sigma_comb = paste0("d= ", d, ", sigma= ", sigma),
         delta_gamma_comb = paste0("delta= ", delta, ", gamma= ", gamma)) %>%
  ggplot(aes(d_sigma_comb, delta_gamma_comb, fill=posteriors))+
  geom_tile()+
  labs(x="", y = "")+
  theme(axis.text.x = element_text(angle=45))
```

Note that, if you had tried to use the sum of trial likelihoods, you would not have been able to tell many models apart from each other.

```{r}
data.frame(m = out$models) %>%
  separate(m, c("d", "sigma", "delta", "gamma"), sep= ",") %>%
  mutate(d_sigma_comb = paste0("d= ", d, ", sigma= ", sigma),
         delta_gamma_comb = paste0("delta= ", delta, ", gamma= ", gamma)) %>%
  mutate(likelihoods = unlist(lapply(out$likelihoods, sum), use.names = FALSE)) %>%
  ggplot(aes(d_sigma_comb, delta_gamma_comb, fill=likelihoods))+
  geom_tile()+
  labs(x="", y = "")+
  theme(axis.text.x = element_text(angle=45))
```

How do the posteriors change over trials?

```{r}
tmp = dplyr::bind_rows(replicate(nrow(test_data)+1, data.frame(m = out$models), simplify = FALSE)) %>%
  arrange(m) %>%
  mutate(posteriors = unlist(out$posteriors_tbt, use.names = FALSE)) %>%
  group_by(m) %>%
  mutate(trial = 1:n()) 
```

```{r}
tmp %>%
  separate(m, c("d", "sigma", "delta", "gamma"), sep= ",") %>%
  ggplot(aes(trial, posteriors))+
  geom_line(aes(linetype=d, color=sigma))+
  theme(legend.position = "bottom")+
  facet_grid(delta ~ gamma)+
  scale_linetype_manual(values=c("twodash", "solid", "dotted"))
```

*Interim conclusion: Sum of trial likelihoods from the state-space approach does not seem viable to estimate parameters when doing a grid search. Model posteriors based on trial likelihoods are able to recover parameters successfully.*

**Question: [Not immediately crucial but to understand how ML with what I understand to be the "standard" way of fitting with RT histograms] What is the intuition behind the likelihood computation from the RT histograms conditioned on choice?**

So is a grid search and then computing the parameter combination posteriors the way to go for estimation? Or can the built-in optimizers work as well?

# Built-in Optimizer

If I save the parameter combinations used by `optim` in each iteration (using `jbryer/visualMLE` package) I should be able to generate trial likelihoods and then compute posteriors for the parameters that were tried by the optimizer. Then I can also compare them to its "best-fitting" parameters as well.

## Model 1

Try this first with the simpler model model1. Does optim recover the true parameters? Or at least move in the right direction?

```{r}
trialsPerCondition=25 

# Replicate same conditions n times
test_data = dplyr::bind_rows(replicate(trialsPerCondition, test_trial_conditions, simplify = FALSE))

# Simulate choice and RT for the replicated trial conditions
test_data = sim_task(test_data, model_name = "model1", d = d, sigma = sigma) %>%drop_na()
```

Got pretty close to the true parameters without convergence due to `maxit` limit. But even with no limit it doesn't change much more.

```{r}
optim_out = optim_save(c(.01, .01), get_task_nll, data=test_data, par_names = c("d", "sigma"), model_name="model1", control = list(maxit=75))
```

```{r}
optim_out$par
```

What about starting from another point? Didn't make a big difference.

```{r}
optim_out = optim_save(c(.1, .1), get_task_nll, data=test_data, par_names = c("d", "sigma"), model_name="model1", control = list(maxit=75))
```

```{r}
optim_out$par
```

What does the search space look like with the optimizer?

```{r}
tmp = data.frame(key = c("d", "sigma"), true_val = c(d, sigma))

optim_out$iterations_df %>%
  gather(key, value, -Result, -Iteration) %>%
  mutate(key =ifelse(key == "Param1", "d", "sigma")) %>%
  ggplot(aes(Iteration, value))+
  geom_point(aes(color=Result))+
  geom_line(alpha=.5, color="gray")+
  facet_wrap(~key)+
  geom_hline(data=tmp, aes(yintercept = true_val), linetype="dashed")+
  theme(legend.position="bottom")
```

How about with number of trials that each subject has in the empirical data?

```{r}
trialsPerCondition=15 

# Replicate same conditions n times
test_data = dplyr::bind_rows(replicate(trialsPerCondition, test_trial_conditions, simplify = FALSE))

# Simulate choice and RT for the replicated trial conditions
test_data = sim_task(test_data, model_name = "model1", d = d, sigma = sigma) %>%drop_na()
```

```{r}
optim_out = optim_save(c(.01, .01), get_task_nll, data=test_data, par_names = c("d", "sigma"), model_name="model1", control = list(maxit=75))
```

Still pretty good. Though note that this is different than empirical data in that it repeats the same condition several times. 

```{r}
optim_out$par
```

```{r}
tmp = data.frame(key = c("d", "sigma"), true_val = c(d, sigma))

optim_out$iterations_df %>%
  gather(key, value, -Result, -Iteration) %>%
  mutate(key =ifelse(key == "Param1", "d", "sigma")) %>%
  ggplot(aes(Iteration, value))+
  geom_point(aes(color=Result))+
  geom_line(alpha=.5, color="gray")+
  facet_wrap(~key)+
  geom_hline(data=tmp, aes(yintercept = true_val), linetype="dashed")+
  theme(legend.position="bottom")
```

### Non-repeated conditions

How about same number of trials but without repeated conditions?

```{r}
sub_data = read.csv(paste0(helpers_path, 'ddmSims/test_data/single_sub_data.csv'))
sub_data = sub_data %>%
  select(leftQValue, rightQValue, leftLotteryEV, rightLotteryEV, probFractalDraw) %>%
  rename(QVLeft = leftQValue, QVRight = rightQValue, EVLeft = leftLotteryEV, EVRight = rightLotteryEV)
```

```{r}
sub_data = sim_task(sub_data, model_name = "model1", d = d, sigma = sigma) %>%drop_na()
```

```{r}
optim_out = optim_save(c(.01, .01), get_task_nll, data=sub_data, par_names = c("d", "sigma"), model_name="model1", control = list(maxit=75))
```

```{r}
optim_out$par
```

```{r}
tmp = data.frame(key = c("d", "sigma"), true_val = c(d, sigma))

optim_out$iterations_df %>%
  gather(key, value, -Result, -Iteration) %>%
  mutate(key =ifelse(key == "Param1", "d", "sigma")) %>%
  ggplot(aes(Iteration, value))+
  geom_point(aes(color=Result))+
  geom_line(alpha=.5, color="gray")+
  facet_wrap(~key)+
  geom_hline(data=tmp, aes(yintercept = true_val), linetype="dashed")+
  theme(legend.position="bottom")
```

How about more complex model?

## Model1b

### Fitting two parameters, d and sigma

```{r}
trialsPerCondition=15 

# Replicate same conditions n times
test_data = dplyr::bind_rows(replicate(trialsPerCondition, test_trial_conditions, simplify = FALSE))

# Simulate choice and RT for the replicated trial conditions
test_data = sim_task(test_data, model_name = "model1b", d = d, sigma = sigma) %>%drop_na()
```

```{r}
optim_out = optim_save(c(.01, .01), get_task_nll, data=test_data, par_names = c("d", "sigma"), model_name="model1b", control = list(maxit=75))
```

Not bad.

```{r}
optim_out$par
```

```{r}
tmp = data.frame(key = c("d", "sigma"), true_val = c(d, sigma))

optim_out$iterations_df %>%
  gather(key, value, -Result, -Iteration) %>%
  mutate(key =ifelse(key == "Param1", "d", "sigma")) %>%
  ggplot(aes(Iteration, value))+
  geom_point(aes(color=Result))+
  geom_line(alpha=.5, color="gray")+
  facet_wrap(~key)+
  geom_hline(data=tmp, aes(yintercept = true_val), linetype="dashed")+
  theme(legend.position="bottom")
```

### Fitting four parameters

d and sigma are somewhat robust but haven't found success in recovering delta and gamma.

```{r}
trialsPerCondition=15 

# Replicate same conditions n times
test_data = dplyr::bind_rows(replicate(trialsPerCondition, test_trial_conditions, simplify = FALSE))

# Simulate choice and RT for the replicated trial conditions
test_data = sim_task(test_data, model_name = "model1b", d = d, sigma = sigma, delta = 3, gamma = 3) %>%drop_na()
```

Examples with different starting points for the same data.

Example 1: c(.01, .01, 1, 1)

```{r}
optim_out = optim_save(c(.01, .01, 1, 1), get_task_nll, data=test_data, par_names = c("d", "sigma", "delta", "gamma"), model_name="model1b", control = list(maxit=75))
```

```{r}
optim_out$par
```

```{r}
tmp = data.frame(key = c("d", "sigma", "delta", "gamma"), true_val = c(d, sigma, 3, 3))

optim_out$iterations_df %>%
  gather(key, value, -Result, -Iteration) %>%
  mutate(key =ifelse(key == "Param1", "d", ifelse(key == "Param2", "sigma", ifelse(key == "Param3", "delta", "gamma")))) %>%
  ggplot(aes(Iteration, value))+
  geom_point(aes(color=Result))+
  geom_line(alpha=.5, color="gray")+
  facet_wrap(~key, scales="free")+
  geom_hline(data=tmp, aes(yintercept = true_val), linetype="dashed")+
  theme(legend.position="bottom")
```

Example 2: c(.01, .01, 3, 3)

```{r}
optim_out = optim_save(c(.01, .01, 3, 3), get_task_nll, data=test_data, par_names = c("d", "sigma", "delta", "gamma"), model_name="model1b", control = list(maxit=75))
```

```{r}
optim_out$par
```

```{r}
tmp = data.frame(key = c("d", "sigma", "delta", "gamma"), true_val = c(d, sigma, 3, 3))

optim_out$iterations_df %>%
  gather(key, value, -Result, -Iteration) %>%
  mutate(key =ifelse(key == "Param1", "d", ifelse(key == "Param2", "sigma", ifelse(key == "Param3", "delta", "gamma")))) %>%
  ggplot(aes(Iteration, value))+
  geom_point(aes(color=Result))+
  geom_line(alpha=.5, color="gray")+
  facet_wrap(~key, scales="free")+
  geom_hline(data=tmp, aes(yintercept = true_val), linetype="dashed")+
  theme(legend.position="bottom")
```

Example 3: c(.01, .01, 2, 2)

```{r}
optim_out = optim_save(c(.01, .01, 2, 2), get_task_nll, data=test_data, par_names = c("d", "sigma", "delta", "gamma"), model_name="model1b", control = list(maxit=75))
```

```{r}
optim_out$par
```

```{r}
tmp = data.frame(key = c("d", "sigma", "delta", "gamma"), true_val = c(d, sigma, 3, 3))

optim_out$iterations_df %>%
  gather(key, value, -Result, -Iteration) %>%
  mutate(key =ifelse(key == "Param1", "d", ifelse(key == "Param2", "sigma", ifelse(key == "Param3", "delta", "gamma")))) %>%
  ggplot(aes(Iteration, value))+
  geom_point(aes(color=Result))+
  geom_line(alpha=.5, color="gray")+
  facet_wrap(~key, scales="free")+
  geom_hline(data=tmp, aes(yintercept = true_val), linetype="dashed")+
  theme(legend.position="bottom")
```

Example 4: c(.1, .1, 2, 2)

```{r}
optim_out = optim_save(c(.1, .1, 2, 2), get_task_nll, data=test_data, par_names = c("d", "sigma", "delta", "gamma"), model_name="model1b", control = list(maxit=75))
```

```{r}
optim_out$par
```

```{r}
tmp = data.frame(key = c("d", "sigma", "delta", "gamma"), true_val = c(d, sigma, 3, 3))

optim_out$iterations_df %>%
  gather(key, value, -Result, -Iteration) %>%
  mutate(key =ifelse(key == "Param1", "d", ifelse(key == "Param2", "sigma", ifelse(key == "Param3", "delta", "gamma")))) %>%
  ggplot(aes(Iteration, value))+
  geom_point(aes(color=Result))+
  geom_line(alpha=.5, color="gray")+
  facet_wrap(~key, scales="free")+
  geom_hline(data=tmp, aes(yintercept = true_val), linetype="dashed")+
  theme(legend.position="bottom")
```

# Stop clusters

```{r}
parallel::stopCluster(cl = my.fit.cluster)
parallel::stopCluster(cl = my.sim.cluster)
```
