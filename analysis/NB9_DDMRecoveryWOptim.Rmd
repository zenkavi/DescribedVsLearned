---
title: "Experience vs. description based decision-making project: DDM parameter recovery by perturbing the `optim` function"
output: 
  html_document:
    toc: true
    toc_float: true
    code_folding: 'hide'
---

# Setup

Set up environment and load in data

```{r include=FALSE, message=FALSE}
library(tidyverse)
library(here)
cbbPalette <- c("#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
theme_set(theme_classic())
sem <- function(x) {sd(x, na.rm=T) / sqrt(length(x))}
helpers_path = here('analysis/helpers/')

set.seed(38573)
```

```{r message=FALSE}
source(paste0(helpers_path,'ddmSims/fit_task.R'))
source(paste0(helpers_path,'ddmSims/sim_task.R'))
test_trial_conditions = read.csv(paste0(helpers_path, 'ddmSims/test_data/test_trial_conditions.csv'))
```

```{r include=FALSE, message=FALSE}
library(visualMLE)
```

Empty lists to store the trial simulators for the forthcoming models.

```{r}
sim_trial_list = list()
fit_trial_list = list()
```

```{r}
source(paste0(helpers_path, 'ddmSims/r_ddm_models/ddm_model1a.R'))

sim_trial_list[['model1a']] = sim_trial
fit_trial_list[['model1a']] = fit_trial
```

```{r}
true_d = .06
true_sigma = .08
true_delta = 3
true_gamma = 3
```

```{r}
trialsPerCondition=15 

# Replicate same conditions n times
test_data = dplyr::bind_rows(replicate(trialsPerCondition, test_trial_conditions, simplify = FALSE))

# Simulate choice and RT for the replicated trial conditions
test_data = sim_task(test_data, model_name = "model1a", d = true_d, sigma = true_sigma, delta = true_delta, gamma = true_gamma) %>%drop_na()
```

Examples with different starting points for the same data.

Example 1: c(.01, .01, 1, 1)

```{r}
optim_out = optim_save(c(.01, .01, 1, 1), get_task_nll, data=test_data, par_names = c("d", "sigma", "delta", "gamma"), model_name="model1a", control = list(maxit=75))
```

```{r}
optim_out$par
```

```{r}
tmp = data.frame(key = c("d", "sigma", "delta", "gamma"), true_val = c(true_d, true_sigma, true_delta, true_gamma))

optim_out$iterations_df %>%
  gather(key, value, -Result, -Iteration) %>%
  mutate(key =ifelse(key == "Param1", "d", ifelse(key == "Param2", "sigma", ifelse(key == "Param3", "delta", "gamma")))) %>%
  ggplot(aes(Iteration, value))+
  geom_point(aes(color=Result))+
  geom_line(alpha=.5, color="gray")+
  facet_wrap(~key, scales="free")+
  geom_hline(data=tmp, aes(yintercept = true_val), linetype="dashed")+
  theme(legend.position="bottom")
```

Path plots to see how to think through the perturbations

Look into the Nelder-Mead algorithm to understand how the particle moves.
[Here's a quick tutorial](http://www.brnt.eu/phd/node10.html#SECTION00622200000000000000) on how it works

```{r}
optim_out$iterations_df %>%
  mutate(iter_block = round(Iteration/10),
         start_point = c(1,diff(iter_block)),
         end_point = -1*lead(c(0, diff(iter_block))),
         end_point = ifelse(is.na(end_point), 0, end_point),
         point_shape = as.factor(start_point+end_point)) %>%
  rename(d= Param1, sigma = Param2)%>%
  ggplot(aes(d, sigma, color=Iteration))+
  geom_point(aes(shape=point_shape, size=point_shape))+
  geom_path(arrow = arrow(type = "closed", length = unit(0.05, "npc")))+
  geom_point(aes(x = true_d, y = true_sigma), size=3, color="red", pch=8)+
  facet_wrap(~iter_block, scales="free")+
  theme(legend.position = "none")+
  scale_shape_manual(values = c(22,20,21))+
  scale_size_manual(values=c(2.5,2,2.5))
```

How much to perturb in what dimension?

```{r}

```

How would that be different from many random starts?
Random starts can be parallelized more by generating a list of starter values and then submitting each as a separate job.
Can also generate many random datasets.
How would you then organize the output of each?
Would you compute posterior among these different optimized values?

Quick test with a loop to make sure naming and saving works

```{r}
num_starts = 2

all_optim_out = list()

for(i in 1:num_starts){
  start_d = runif(1, 0, 1)
  start_sigma = runif(1, 0, 1)
  start_delta = runif(1, 1, 5)
  start_gamma = runif(1, 1, 5)
  
  start_str = paste(round(start_d, 2), round(start_sigma, 2), round(start_delta, 2), round(start_gamma, 2), sep = ", ")
  
  all_optim_out[[start_str]] = optim_save(c(start_d, start_sigma, start_delta, start_sigma), get_task_nll, data=test_data, par_names = c("d", "sigma", "delta", "gamma"), model_name="model1a", control = list(maxit=10))
}
```

```{r}
names(all_optim_out)
```

```{r}
all_optim_out[[1]]$iterations_df
```

# Stop clusters

```{r}
# parallel::stopCluster(cl = my.fit.cluster)
# parallel::stopCluster(cl = my.sim.cluster)
```

------------------------------------------------------------------------------------------------------------------------------------------------------------------------
How viable is this with Stan or with the Lombardi toolbox using hierarchical models? Can you use the trial likelihood function to code the bespoke model in Stan?

```{r}

```

What do we know so far?
  Slight lottery bias in pooled data
  Categorically faster RTs when probFractalDraw == 1 in pooled data
  Slower decisions the more both attributes need to be considered in pooled data
  Individual differences both in all of the above stylized facts and in the best fitting RL model
What will we do with these parameters? 
  Individual difference analyses?
  Trial level covariate for imaging?
Move things over to remote cluster for subject estimation?
Combined DDM + RL modeling:
  Wouldn't be able to take advantage of `foreach` package in `sim_task` and `fit_task`.
  Without paralellization how would you implement it in `sim_task` and `fit_task` with serial updating of QValues?
  Would it be possible to implement in Stan?