---
title: "Experience vs. description based decision-making project: RL model fits onto behavioral data"
output: 
  html_document:
    toc: true
    toc_float: true
---

# Set up environment and load in data

```{r}
library(tidyverse)
```

```{r}
library(rstan)
```

```{r}
helpers_path = '~/Documents/RangelLab/DescribedVsLearned/helpers/'
```

# Read in *clean* behavioral data

```{r}
source(paste0(helpers_path,'clean_behavioral_data.R'))
source(paste0(helpers_path, 'extract_var_for_stan.R'))
```

# Evidence for "learning" fractal values

Is there evidence if "learning" to justify the fitting of an RL model?

As time goes by are subjects more likely to choose the fractal with the higher reward probability? There is a subtle increase in the probability of choosing the fractal with the higher reward probability. This change in probability of choosing the fractal with the higher reward probability is larger when the reward depends only on fractals (except for the last session, which bizarrely has the opposite pattern).

```{r}
p1 = clean_beh_data %>%
  mutate(leftFractalBetter = fractalLeftProb>fractalRightProb,
         choseBetterFractal = ifelse(leftFractalBetter & choiceLeft == 1, 1, 
                                     ifelse(!leftFractalBetter & choiceLeft == 0, 1, 0))) %>%
  ggplot(aes(trialNum, choseBetterFractal, col=as.factor(session)))+
  geom_smooth(formula = 'y~x', method = "glm", method.args = list(family=binomial), fullrange=TRUE, alpha=.1)+
  labs(title="All trials", x="Trial Number", y="p(Chose better fractal)", color="Session")+
  coord_cartesian(ylim=c(0.4,.8))

p2 = clean_beh_data %>%
  filter(probFractalDraw > .5) %>%
  mutate(leftFractalBetter = fractalLeftProb>fractalRightProb,
         choseBetterFractal = ifelse(leftFractalBetter & choiceLeft == 1, 1, 
                                     ifelse(!leftFractalBetter & choiceLeft == 0, 1, 0))) %>%
  ggplot(aes(trialNum, choseBetterFractal, col=as.factor(session)))+
  geom_smooth(formula = 'y~x', method = "glm", method.args = list(family=binomial), fullrange=TRUE, alpha=.1)+
  labs(title="p(Fractal)>.5", x="Trial Number", y="p(Chose better fractal)", color="Session")+
  coord_cartesian(ylim=c(0.4,.8))

grid.arrange(p1, p2, nrow=1, ncol=2)
```

```{r}
rm(p1, p2)
```

**ADD Bayesian multilevel model and check the significance of slopes**

```{r}

```

# Reshape data for model

```{r}
num_subjs = length(unique(clean_beh_data$subnum))

num_trials = clean_beh_data %>%
  count(subnum) %>%
  select(n)
num_trials = num_trials$n

#subjects in rows, trials in columns
choices = extract_var_for_stan(clean_beh_data, choiceLeft)

outcomes_left = extract_var_for_stan(clean_beh_data, leftFractalReward)
  
outcomes_right = extract_var_for_stan(clean_beh_data, rightFractalReward)

m_data=list(num_subjs = num_subjs,
            num_trials = num_trials,
            choices = choices,
            outcomes_left = outcomes_left,
            outcomes_right=outcomes_right)

rm(num_subjs, num_trials, choices, outcomes_left, outcomes_right)
```

# Fit model for all subjects

```{r}
m = stan_model('../helpers/stanModels/fit_qlearning.stan')
```

```{r}
fit = sampling(m, data=m_data)
```

# Organize output

```{r}
# Extract parameters from fit object
par_ests = data.frame(extract(fit, c("alphas", "betas")))  %>%
  gather(key, value) %>%
  separate(key, c('par', 'subj'), sep='\\.')

# Add correct subject identifiers
par_ests = data.frame(subnum = unique(clean_beh_data$subnum)) %>%
  mutate(subj = as.character(1:n())) %>%
  right_join(par_ests, by='subj') %>%
  select(-subj)
```

Distributions of the recovered (median) parameters

```{r}
par_ests %>%
  group_by(subnum, par) %>%
  summarise(est = median(value), .groups='keep') %>%
  ggplot(aes(est))+
  geom_histogram(alpha=.5, bins=30)+
  facet_wrap(~par, scales='free_x')+
  xlab("Median estimates for all subjects")
```

```{r}
par_ests %>%
  filter(par == "alphas") %>%
  ggplot(aes(value))+
  geom_histogram(alpha=.5, bins=50)+
  facet_wrap(~subnum, scales='free_y')+
  labs(title = "Posterior distribution of learning rates for each subject",
       xlab="", ylab="")
```

```{r}
par_ests %>%
  filter(par == "betas") %>%
  ggplot(aes(value))+
  geom_histogram(alpha=.5, bins=50)+
  facet_wrap(~subnum, scales='free_y')+
  labs(title = "Posterior distribution of inverse temperatures for each subject",
       xlab="", ylab="")
```

Save median estimates to `clean_beh_data`

```{r}
clean_beh_data = par_ests %>%
  group_by(subnum, par) %>%
  summarise(est = median(value), .groups='keep') %>%
  spread(par, est) %>%
  left_join(clean_beh_data, by='subnum')
rm(fit, par_ests)
```

Add Q values to each trial using median parameter estimates from the Q-learning model fit.

```{r}

get_qvals = function(subj_data){
  subj_data$leftQValue = 0
  subj_data$rightQValue = 0
  for (i in 2:nrow(subj_data)){
  subj_data$leftQValue[i] = subj_data$alphas[i] * (subj_data$leftFractalReward[i-1] - subj_data$leftQValue[i-1])
  subj_data$rightQValue[i] = subj_data$alphas[i] * (subj_data$rightFractalReward[i-1] - subj_data$rightQValue[i-1])
  }
  return(subj_data)
}

clean_beh_data = clean_beh_data %>%
  group_by(subnum) %>%
  do(get_qvals(.)) %>%
  ungroup()

```
