---
title: "Experience vs. description based decision-making project: Two valuation systems modeling"
output: 
  html_document:
    toc: true
    toc_float: true
---

# Set up environment and load in data

```{r}
library(tidyverse)
library(rstan)
library(brms)
library(GGally)
library(here)
```

```{r}
helpers_path = here('helpers/')
```

Set theme for plots

```{r}
theme_set(theme_bw())
```

# Read in *clean* behavioral data

```{r}
source(paste0(helpers_path,'01_clean_behavioral_data.R'))
source(paste0(helpers_path, 'extract_var_for_stan.R'))
source(paste0(helpers_path, 'get_qvals.R'))
```

In the previous notebook we found that subjects rely more on description based lottery value differences more than they should when their reward does not depend on this attribute. The fractal values in the previous notebook were based on an RL model estimated using only the fractal information in each trial. What the subjects experience on each trial is, however, more comprehensive than just the two fractal. So to describe the choice process in this task we must take into account both the lottery and fractal information, as well as, their relevance on each trial. In this notebook we

- define a two valuation systems that takes both attributes into account
- fit this model on behavioral to get estimates both for learning rate and inverse temperature as well as how each attribute is weighted 
- compare this expanded model with the RL only model to show that it fits data better
- check if the behavioral effect of interest from the last notebook, ie the over-reliance on irrelevant description-based attribute
- check whether this effect can be explained more by distortion of probability or distorted fractal values

# Define two systems model

$$p(choice = left) = \frac{1}{1+e^{-\beta(V_{left} - V_{right})}}$$

$$V_i = (1-w(pFrac))EV_i + w(pFrac)QV_i, \:i \in \{left, right\}$$
$$EV_{i, t} = p_{i, t} V{i_t}$$

$$QV_{i,t} = QV_{i, t-1} + \alpha(R_{i, t-1}- QV_{i, t-1})$$

$$w(pFrac) = \frac{\delta*pFrac^{\gamma}}{\delta*pFrac^{\gamma}+(1- pFrac)^{\gamma}}$$
## Fit Q learning + two value system simultaneously

Organize data

```{r}
num_subjs = length(unique(clean_beh_data$subnum))

num_trials = clean_beh_data %>%
  count(subnum) %>%
  select(n)
num_trials = num_trials$n

#subjects in rows, trials in columns
choices = extract_var_for_stan(clean_beh_data, choiceLeft)

clean_beh_data = clean_beh_data %>%
  mutate(leftLotteryEV = lotteryValue*lotteryProb,
         rightLotteryEV = referenceValue*referenceProb)

ev_left = extract_var_for_stan(clean_beh_data, leftLotteryEV)

ev_right = extract_var_for_stan(clean_beh_data, rightLotteryEV)

fractal_outcomes_left = extract_var_for_stan(clean_beh_data, leftFractalReward)

fractal_outcomes_right = extract_var_for_stan(clean_beh_data, rightFractalReward)

trial_pFrac = extract_var_for_stan(clean_beh_data, probFractalDraw)

m_data=list(num_subjs = num_subjs,
            num_trials = num_trials,
            choices = choices,
            ev_left = ev_left,
            ev_right = ev_right,
            fractal_outcomes_left = fractal_outcomes_left,
            fractal_outcomes_right = fractal_outcomes_right,
            trial_pFrac = trial_pFrac)

rm(num_subjs, num_trials, choices, ev_left, ev_right, fractal_outcomes_left, fractal_outcomes_right, trial_pFrac)
```

## Fit model for all subjects

```{r}
if(file.exists(paste0(helpers_path, 'stanModels/fit_twoValSystemsWithRL.RDS'))){
  fit = readRDS(paste0(helpers_path, 'stanModels/fit_twoValSystemsWithRL.RDS'))
} else {
  m = stan_model('../helpers/stanModels/fit_twoValSystemsWithRL.stan')
  fit = sampling(m, data=m_data)}
```

## Organize model output

```{r}
# Extract parameters from fit object
par_ests = data.frame(extract(fit, c("alpha","gamma", "delta", "beta")))  %>%
  gather(key, value) %>%
  separate(key, c('par', 'subj'), sep='\\.')

# Add correct subject identifiers
par_ests = data.frame(subnum = unique(clean_beh_data$subnum)) %>%
  mutate(subj = as.character(1:n())) %>%
  right_join(par_ests, by='subj') %>%
  select(-subj)
```

# Model comparison of RL only vs two systems model

How do the parameter estimates from the RL only fit differ from the alpha and betas in the simultaneous fit?

```{r}
fit_rl = readRDS(paste0(helpers_path, 'stanModels/fit_qlearning.RDS'))

par_ests_rl = data.frame(extract(fit_rl, c("alpha", "beta")))  %>%
  gather(key, value) %>%
  separate(key, c('par', 'subj'), sep='\\.')

# Add correct subject identifiers
par_ests_rl = data.frame(subnum = unique(clean_beh_data$subnum)) %>%
  mutate(subj = as.character(1:n())) %>%
  right_join(par_ests_rl, by='subj') %>%
  select(-subj)
```

The learning rates don't have a clear pattern of difference, although they are mostly not the same but the inverse temperatures are systematically higher when estimates

Higher inverse temperatures should suggest that the choice depends more on the value difference than chance.

```{r}
par_ests %>%
  group_by(subnum, par) %>%
  summarise(est = median(value), .groups='keep') %>%
  filter(par %in% c("beta", "alpha")) %>%
  mutate(fit = "simulatanous") %>%
  rbind(par_ests_rl %>%
          group_by(subnum, par) %>%
          summarise(est = median(value), .groups='keep') %>%
          filter(par %in% c("betas", "alphas")) %>%
          mutate(fit = "separate",
                 par = ifelse(par == "alphas", "alpha", "beta"))) %>%
  spread(fit, est) %>%
  ggplot(aes(separate, simulatanous))+
  geom_point()+
  facet_wrap(~par, scales="free")+
  geom_abline(intercept=0, slope=1, linetype="dashed")

```

With these RL estimates do you get the same pattern for the Q values? Yes.

```{r}
clean_beh_data = par_ests %>%
  group_by(subnum, par) %>%
  summarise(est = median(value), .groups='keep') %>%
  spread(par, est) %>%
  left_join(clean_beh_data, by='subnum')

clean_beh_data = clean_beh_data %>%
  group_by(subnum) %>%
  do(get_qvals(.)) %>%
  ungroup()

rm(get_qvals)

```

```{r}
clean_beh_data %>%
  filter(probFractalDraw == 1 | probFractalDraw == 0) %>%
  mutate(leftQVAdv = leftQValue - rightQValue,
         leftLotteryEV = lotteryValue*lotteryProb,
         rightLotteryEV = referenceValue*referenceProb,
         leftEVAdv = leftLotteryEV - rightLotteryEV) %>%
  select(leftQVAdv, leftEVAdv, choiceLeft, probFractalDraw) %>%
  gather(key, value, -choiceLeft, -probFractalDraw) %>%  
  mutate(key = ifelse(key == "leftEVAdv", "EV_left - EV_right", "QV_left - QV_right"),
         probFractalDraw = ifelse(probFractalDraw == 0, "p(Fractal)=0", "p(Fractal)=1"))%>%
  ggplot(aes(value, choiceLeft))+
  geom_jitter(width=0.03, height=0.08, alpha = 0.05)+
  geom_smooth(formula = 'y~x', method = "glm", method.args = list(family=binomial), fullrange=TRUE)+
  facet_grid(probFractalDraw~key)+
  xlab("")+
  ylab("p(Left)")
```

How about model "fit". How do you evaluate model fit? 

```{r}

```

# Lottery bias 

**DO THE BEHAVIORAL EFFECTS FROM THE LAST NOTEBOOK REMAIN WITH THE NEW PARAMETER ESTIMATES?**

```{r}

```

# Examine two value systems parameters

How does the distortion change for different values of delta and gamma exponent? This analysis isn't based on data. It is to build intuition to understand how each prob fractal might be perceived as by subjects for different values of the model parameters.

Facets - values of pFrac (true prob of Fractal)
Blue w(pFrac)>pFrac - overweighting prob fractal
Red pFrac>w(pFrac) - underweighting prob fractal

```{r}
expand.grid(rep(list(seq(0,1.5,.1)), 3)) %>%
  rename(delta=Var1, gamma=Var2, pFrac=Var3)%>%
  mutate(wpFrac = (delta*(pFrac^gamma)) / ((delta*(pFrac^gamma) + ((1-pFrac)^gamma))), 
         distortion = pFrac-wpFrac) %>%
  filter(pFrac > 0 & pFrac < 1) %>%
  mutate(pFrac = paste0("p(Fractal) = ", pFrac)) %>%
  ggplot2::ggplot(aes(as.factor(delta), as.factor(gamma)))+
  geom_raster(aes(fill=distortion))+
  facet_wrap(~as.factor(pFrac))+
  labs(x="\U03B4", y="Prob Distortion Exponent", 
       title="Distortion of p(Fractal)")+
  scale_fill_gradient2(low = scales::muted("blue"), 
                       high= scales::muted("red"))+
  theme(axis.ticks = element_blank(), 
        axis.text.x = element_text(angle=90),
        legend.title = element_blank())+
  scale_y_discrete(breaks=seq(0, 1.5, .3))
```

Where do subjects fall in the theoretical graph above?

```{r}
tmp = par_ests %>%
  group_by(subnum, par) %>%
  summarise(est = median(value), .groups='keep') %>%
  spread(par, est)

expand.grid(rep(list(seq(0,1.5,.1)), 3)) %>%
  rename(delta=Var1, gamma=Var2, pFrac=Var3)%>%
  mutate(wpFrac = (delta*(pFrac^gamma)) / ((delta*(pFrac^gamma) + ((1-pFrac)^gamma))), 
         distortion = pFrac-wpFrac) %>%
  filter(pFrac > 0 & pFrac < 1) %>%
  mutate(pFrac = paste0("p(Fractal) = ", pFrac)) %>%
  ggplot2::ggplot(aes(as.factor(delta), as.factor(gamma)))+
  geom_raster(aes(fill=distortion))+
  facet_wrap(~as.factor(pFrac))+
  labs(x="\U03B4", y="Prob Distortion Exponent", 
       fill="Overestimation -> underestimation", 
       title="Distortion of p(Fractal)")+
  scale_fill_gradient2(low = scales::muted("blue"), high=scales::muted("red"))+
  theme(axis.ticks = element_blank(), axis.text.x = element_text(angle=90), legend.position="bottom")+
  scale_y_discrete(breaks=seq(0, 1.5, .3))+
  annotate("point", x = 10*tmp$delta, y=10*tmp$gamma)
```

Distributions of the recovered (median) parameters

```{r}
par_ests %>%
  group_by(subnum, par) %>%
  summarise(est = median(value), .groups='keep') %>%
  ggplot(aes(est))+
  geom_histogram(alpha=.5, bins=30)+
  facet_wrap(~par, scales='free_x')+
  xlab("Median estimates for all subjects")
```

Are there any dependencies between the parameters? gamma is correlated with both beta and delta.

```{r}
par_ests %>%
  group_by(subnum, par) %>%
  summarise(est = median(value), .groups='keep') %>%
  ungroup() %>%
  spread(par, est) %>%
  select(-subnum) %>%
  ggpairs(progress = FALSE)
```

How do the median estimates suggest the probability of a fractal draw is distorted for each subject?

```{r}
tmp = par_ests %>%
  group_by(subnum, par) %>%
  summarise(est = median(value), .groups='keep') %>%
  filter(par != "beta" & par != "alpha") %>%
  spread(par, est)

tmp = do.call("rbind", replicate(11, tmp, simplify = FALSE)) %>%
  arrange(subnum) %>%
  ungroup() %>%
  mutate(pFrac = rep(seq(0, 1, .1), 25), 
         wpFrac = (delta*pFrac^gamma)/(delta*pFrac^gamma + (1-pFrac)^gamma)) 

tmp %>%
  mutate(delta_gt_1 = ifelse(delta>=1, 1, 0),
         gamma_gt_1 = ifelse(gamma>=1,"prodDistortion >= 1", "prodDistortion < 0")) %>%
  ggplot(aes(pFrac, wpFrac, group=subnum))+
  geom_line(aes(col = as.factor(gamma_gt_1)))+
  geom_abline(slope=1, intercept=0, linetype="dashed")+
  labs(x="p(Fractal)", y="w(pFractal)", title="Distortion of p(Fractal)", color = element_blank())
```