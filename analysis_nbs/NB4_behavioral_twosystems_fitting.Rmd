---
title: "Experience vs. description based decision-making project: Two valuation systems modeling"
output: html_notebook
---

# Set up environment and load in data

```{r}
library(tidyverse)
```

```{r}
library(rstan)
```

```{r}
helpers_path = '~/Documents/RangelLab/DescribedVsLearned/helpers/'
```

# Read in *clean* behavioral data

```{r}
source(paste0(helpers_path,'fit_qlearning.R'))
source(paste0(helpers_path, 'extract_var_for_stan.R'))
```

# Reshape data for model

```{r}
num_subjs = length(unique(clean_beh_data$subnum))

num_trials = clean_beh_data %>%
  count(subnum) %>%
  select(n)
num_trials = num_trials$n

#subjects in rows, trials in columns
choices = extract_var_for_stan(clean_beh_data, choiceLeft)

qv_left = extract_var_for_stan(clean_beh_data, leftQValue)

qv_right = extract_var_for_stan(clean_beh_data, rightQValue)

clean_beh_data = clean_beh_data %>%
  mutate(leftLotteryEV = lotteryValue*lotteryProb,
         rightLotteryEV = referenceValue*referenceProb)

ev_left = extract_var_for_stan(clean_beh_data, leftLotteryEV)

ev_right = extract_var_for_stan(clean_beh_data, rightLotteryEV)

trial_pi = extract_var_for_stan(clean_beh_data, probFractalDraw)

m_data=list(num_subjs = num_subjs,
            num_trials = num_trials,
            choices = choices,
            ev_left = ev_left,
            ev_right = ev_right,
            qv_left = qv_left,
            qv_right = qv_right,
            trial_pi = trial_pi)

rm(num_subjs, num_trials, choices, ev_left, ev_right, qv_left, qv_right, trial_pi)
```

# Fit model for all subjects

$$p(choice = left) = \frac{1}{1+e^{-\beta(V_{left} - V_{right})}}$$

$$V_i = (1-w(\pi))EV_i + w(\pi)QV_i , \:i \in \{left, right\}$$
$$w(\pi) = \frac{\delta\pi^\gamma}{\delta\pi^\gamma+(1-\pi)^\gamma}$$

```{r}
m = stan_model('../helpers/stanModels/fit_twoValSystems.stan')
```

```{r}
fit = sampling(m, data=m_data)
```

# Organize output

```{r}
# Extract parameters from fit object
par_ests = data.frame(extract(fit, c("gamma", "delta", "beta")))  %>%
  gather(key, value) %>%
  separate(key, c('par', 'subj'), sep='\\.')

# Add correct subject identifiers
par_ests = data.frame(subnum = unique(clean_beh_data$subnum)) %>%
  mutate(subj = as.character(1:n())) %>%
  right_join(par_ests, by='subj') %>%
  select(-subj)
```

Distributions of the recovered (median) parameters

```{r}
par_ests %>%
  group_by(subnum, par) %>%
  summarise(est = median(value), .groups='keep') %>%
  ggplot(aes(est))+
  geom_histogram(alpha=.5, bins=30)+
  facet_wrap(~par, scales='free_x')+
  xlab("Median estimates for all subjects")
```

How do the median estimates suggest the probability of a fractal draw is distorted for each subject?

```{r}
tmp = par_ests %>%
  group_by(subnum, par) %>%
  summarise(est = median(value), .groups='keep') %>%
  filter(par != "beta") %>%
  spread(par, est)

do.call("rbind", replicate(9, tmp, simplify = FALSE)) %>%
  arrange(subnum) %>%
  ungroup() %>%
  mutate(pi = rep(seq(0.1, .9, .1), 25), 
         wpi = (delta*pi^gamma)/(delta*pi^gamma + (1-pi)^gamma)) %>%
  ggplot()+
  geom_boxplot(aes(as.factor(pi), wpi))+
  geom_abline(intercept = 0, slope=.1, linetype='dashed')+
  labs(x="\u03c0", y="w(\u03c0)", title="Distortion of p(Fractal)")+
  ylim(0, 1)
```

How does the distortion change for different values of delta and gamma?

```{r}

```

# Individual posteriors

```{r}
par_ests %>%
  filter(par == "gamma") %>%
  ggplot(aes(value))+
  geom_histogram(alpha=.5, bins=50)+
  facet_wrap(~subnum, scales='free_y')+
  labs(title = "Posterior distribution of \U03B3",
       xlab="", ylab="")
```

```{r}
par_ests %>%
  filter(par == "delta") %>%
  ggplot(aes(value))+
  geom_histogram(alpha=.5, bins=50)+
  facet_wrap(~subnum, scales='free_y')+
  labs(title = "Posterior distribution of \U03B4",
       xlab="", ylab="")
```

```{r}
par_ests %>%
  filter(par == "beta") %>%
  ggplot(aes(value))+
  geom_histogram(alpha=.5, bins=50)+
  facet_wrap(~subnum, scales='free_y')+
  labs(title = "Posterior distribution of inverse temperature \U03B2",
       xlab="", ylab="")
```

# Model comparisons

1. Fit Q learning + two value system separately
2. Fit Q learning + two value system simultaneously
3. Two value systems with one parameter