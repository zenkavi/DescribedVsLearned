---
title: "Experience vs. description based decision-making project: Two valuation systems modeling"
output: html_notebook
---

# Set up environment and load in data

```{r}
library(tidyverse)
```

```{r}
library(rstan)
```

```{r}
helpers_path = '~/Documents/RangelLab/DescribedVsLearned/helpers/'
```

# Read in *clean* behavioral data

```{r}
source(paste0(helpers_path,'fit_qlearning.R'))
source(paste0(helpers_path, 'extract_var_for_stan.R'))
```

# Reshape data for model

```{r}
num_subjs = length(unique(clean_beh_data$subnum))

num_trials = clean_beh_data %>%
  count(subnum) %>%
  select(n)
num_trials = num_trials$n

#subjects in rows, trials in columns
choices = extract_var_for_stan(clean_beh_data, choiceLeft)

qv_left = extract_var_for_stan(clean_beh_data, leftQValue)

qv_right = extract_var_for_stan(clean_beh_data, rightQValue)

clean_beh_data = clean_beh_data %>%
  mutate(leftLotteryEV = lotteryValue*lotteryProb,
         rightLotteryEV = referenceValue*referenceProb)

ev_left = extract_var_for_stan(clean_beh_data, leftLotteryEV)

ev_right = extract_var_for_stan(clean_beh_data, rightLotteryEV)

trial_pi = extract_var_for_stan(clean_beh_data, probFractalDraw)

m_data=list(num_subjs = num_subjs,
            num_trials = num_trials,
            choices = choices,
            ev_left = ev_left,
            ev_right = ev_right,
            qv_left = qv_left,
            qv_right = qv_right,
            trial_pi = trial_pi)

rm(num_subjs, num_trials, choices, ev_left, ev_right, qv_left, qv_right, trial_pi)
```

# Fit model for all subjects

$$p(choice = left) = \frac{1}{1+e^{-\beta(V_{left} - V_{right})}}$$

$$V_i = (1-w(\pi))EV_i + w(\pi)QV_i , \:i \in \{left, right\}$$
$$w(\pi) = \frac{\delta\pi^\gamma}{\delta\pi^\gamma+(1-\pi)^\gamma}$$

```{r}
m = stan_model('../helpers/stanModels/fit_twoValSystems.stan')
```

```{r}
fit = sampling(m, data=m_data)
```

# Organize output

```{r}
# Extract parameters from fit object
par_ests = data.frame(extract(fit, c("gamma", "delta", "beta")))  %>%
  gather(key, value) %>%
  separate(key, c('par', 'subj'), sep='\\.')

# Add correct subject identifiers
par_ests = data.frame(subnum = unique(clean_beh_data$subnum)) %>%
  mutate(subj = as.character(1:n())) %>%
  right_join(par_ests, by='subj') %>%
  select(-subj)
```

Distributions of the recovered (median) parameters

```{r}
par_ests %>%
  group_by(subnum, par) %>%
  summarise(est = median(value), .groups='keep') %>%
  ggplot(aes(est))+
  geom_histogram(alpha=.5, bins=30)+
  facet_wrap(~par, scales='free_x')+
  xlab("Median estimates for all subjects")
```

How do the median estimates suggest the probability of a fractal draw is distorted for each subject?

```{r}
tmp = par_ests %>%
  group_by(subnum, par) %>%
  summarise(est = median(value), .groups='keep') %>%
  filter(par != "beta") %>%
  spread(par, est)

tmp = do.call("rbind", replicate(9, tmp, simplify = FALSE)) %>%
  arrange(subnum) %>%
  ungroup() %>%
  mutate(pi = rep(seq(0.1, .9, .1), 25), 
         wpi = (delta*pi^gamma)/(delta*pi^gamma + (1-pi)^gamma)) 
tmp %>% ggplot()+
  geom_boxplot(aes(as.factor(pi), wpi))+
  geom_abline(intercept = 0, slope=.1, linetype='dashed')+
  labs(x="\u03c0", y="w(\u03c0)", title="Distortion of p(Fractal)")+
  ylim(0, 1)
```

How does the distortion change for different values of delta and gamma? This isn't based on data. Just to build intuition to understand what each prob fractal might look like for different estimates for subjects.

$$w(\pi) = \frac{\delta\pi^\gamma}{\delta\pi^\gamma+(1-\pi)^\gamma}$$
Facets - values of pi
Blue w(pi)>pi - overweighting prob fractal
Red pi>w(pi) - underweighting prob fractal

```{r}
expand.grid(rep(list(seq(0,1,.1)), 3)) %>%
  rename(delta=Var1, gamma=Var2, pi=Var3) %>%
  mutate(wpi = (delta*pi^gamma)/(delta*pi^gamma + (1-pi)^gamma), 
         distortion = pi-wpi) %>%
  ggplot2::ggplot(aes(as.factor(delta), as.factor(gamma)))+
  geom_raster(aes(fill=distortion))+
  facet_wrap(~as.factor(pi))+
  labs(x="\U03B4", y="\U03B3", fill="\u03c0 - w(\u03c0)", title="Distortion of p(Fractal)")+
  # scale_fill_gradientn(colours=c("#0000FFFF","#FFFFFFFF","#FF0000FF"))+
  scale_fill_gradient2()+
  theme(axis.ticks = element_blank(), axis.text.x = element_blank(), axis.text.y = element_blank())
```


# Individual posteriors

```{r}
par_ests %>%
  filter(par == "gamma") %>%
  ggplot(aes(value))+
  geom_histogram(alpha=.5, bins=50)+
  facet_wrap(~subnum, scales='free_y')+
  labs(title = "Posterior distribution of \U03B3",
       xlab="", ylab="")
```

```{r}
par_ests %>%
  filter(par == "delta") %>%
  ggplot(aes(value))+
  geom_histogram(alpha=.5, bins=50)+
  facet_wrap(~subnum, scales='free_y')+
  labs(title = "Posterior distribution of \U03B4",
       xlab="", ylab="")
```

```{r}
par_ests %>%
  filter(par == "beta") %>%
  ggplot(aes(value))+
  geom_histogram(alpha=.5, bins=50)+
  facet_wrap(~subnum, scales='free_y')+
  labs(title = "Posterior distribution of inverse temperature \U03B2",
       xlab="", ylab="")
```

# Model comparisons

1. Fit Q learning + two value system separately
2. Fit Q learning + two value system simultaneously
3. Two value systems with one parameter