---
title: "Experience vs. description based decision-making project: Post imaging analyses checks"
output: 
  html_document:
    toc: true
    toc_float: true
    code_folding: 'hide'
---

Set up environment and load in data

```{r include=FALSE}
library(tidyverse)
library(gridExtra)
library(brms)
library(here)
cbbPalette <- c("#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
# theme_set(theme_bw())
theme_set(theme_classic())
sem <- function(x) {sd(x, na.rm=T) / sqrt(length(x))}
```

```{r include=FALSE}
helpers_path = here('helpers/')
source(paste0(helpers_path,'fit_twoValSystemsWithRL_hierarchical.R'))
source(paste0(helpers_path,'add_inferred_pars.R'))
```

Add estimated model parameters and inferred bundle values using those parameters.

```{r}
clean_beh_data = add_inferred_pars(clean_beh_data, par_ests)

clean_beh_data = clean_beh_data %>%
  mutate(valChosen = ifelse(choiceLeft, leftBundleVal, rightBundleVal),
         valUnchosen = ifelse(choiceLeft == 0, leftBundleVal, rightBundleVal),
         wpFracBins = as.factor(round(wpFrac,1)),
         leftQVAdvWeighted = leftQVAdv*wpFrac,
         leftEVAdvWeighted = leftEVAdv*(1-wpFrac)) 
```

## Correlation between reggressors

### Value

Is there a correlation between valChosen and valUnchosen? Yes.

```{r}
with(clean_beh_data, cor(valChosen, valUnchosen))
```
    
A second thing to note about the correlation between the bundle values is that they also depend on the distorted probabilities. The more a subject thinks the reward depends on the fractal (lighter colors) the lower both bundles' value. 

A third interesting pattern is that choices above the diagonal where the value of the unchosen bundle is higher than the value of the chosen bundle must be trials where subjects chose differently than what the value difference suggested.

Below they are broken down by the five levels of the lottery EV difference. Facet values < 0 are trials where the right/reference lottery is better.

```{r}
clean_beh_data %>%
  ggplot(aes(valChosen, valUnchosen, col=wpFrac))+
  geom_point()+
  geom_abline(aes(intercept=0, slope = 1), linetype="dashed") + 
  # facet_grid(.~as.factor(leftEVAdv))+
  theme(legend.position="bottom")
```

What are the two prongs in the graph above? The split is by choice side.

Left choices (blue) when leftEVAdvantage<0 and right (yellow) choices when leftEVAdvantage>0 are also those where valUnchosen > valChosen (above diagonal).

This suggests that the bundle value is mostly determined by the lottery value.

```{r}
clean_beh_data %>%
  ggplot(aes(valChosen, valUnchosen, col=as.factor(choiceLeft)))+
  geom_point()+
  geom_abline(aes(intercept=0, slope = 1), linetype="dashed") + 
  facet_grid(.~as.factor(leftEVAdv))+
  theme(legend.position="bottom")+
  labs(color="choiceLeft")+
  scale_color_manual(values=cbbPalette[1:2])
```
Back to the correlation between valChosen and valUnchosen.  

valChosen and valUnchosen is the left and right bundle values rearranged by choice. What does the relationship between the bundle values look like regardless of choice.

Both the correlation between the bundle values and its interaction with subjective probability remains.

```{r}
clean_beh_data %>%
  ggplot(aes(leftBundleVal, rightBundleVal, col=wpFrac))+
  geom_point()+
  geom_abline(aes(intercept=0, slope = 1), linetype="dashed") + 
  facet_grid(.~as.factor(leftEVAdv))+
  theme(legend.position = "bottom")
```

Is this relationship the same for all subjects? No.

```{r}
clean_beh_data %>%
  mutate(lab_col = paste0(subnum, ", alpha = ",round(alpha, 3))) %>%
  ggplot(aes(leftBundleVal, rightBundleVal, col=wpFrac))+
  geom_point()+
  geom_abline(aes(intercept=0, slope = 1), linetype="dashed")+
  facet_wrap(~lab_col)
```

How much the value of the bundles correlate with each other is associated with learning. The higher the learning rate the less the values of the bundles correlate with each other.

```{r}
clean_beh_data %>%
  group_by(subnum) %>%
  summarise(val_cor = cor(leftBundleVal, rightBundleVal),
            alpha = unique(alpha)) %>%
  ggplot(aes(alpha, val_cor))+
  geom_point()+
  geom_smooth(method="lm", formula='y~x')+
  labs(y="Bundle value correlation", x="Learning rate")
```
Why does the bundle values correlate highly for low learning rates?

Because Q values have little to no variance for small learning rates.

```{r}
clean_beh_data %>%
  mutate(lab_col = paste0(subnum, ", alpha = ",round(alpha, 3))) %>%
  ggplot(aes(leftQValue*wpFrac, rightQValue*wpFrac, color=alpha))+
  geom_point()+
  facet_wrap(~lab_col)+
  geom_abline(aes(intercept=0, slope = 1), linetype="dashed")+
  theme(legend.position = "none")
```
So the relationship between bundle values is determined entirely by the weighted lottery EVs.

```{r}
clean_beh_data %>%
  mutate(lab_col = paste0(subnum, ", alpha = ",round(alpha, 3))) %>%
  ggplot(aes(leftLotteryEV*(1-wpFrac), rightLotteryEV*(1-wpFrac), col=alpha))+
  geom_point()+
  geom_abline(aes(intercept=0, slope = 1), linetype="dashed")+
  facet_wrap(~lab_col)+
  theme(legend.position="none")
```

The second thing to explain regarding the relationship between the bundle values was the interaction with weighted probabilities. Above we saw the trend that bundle values were higher for lower weighted probabilities.

This is true even for people with high learning rates. So where is it coming from?

Since it is there for everybody it shouldn't depend on the prob distortion parameters beta or gamma either.

When wpFrac = 1 the bundle value depends only on the lottery value
--> Lottery EV's are higher than QV's in general

```{r}
clean_beh_data %>%
  select(leftLotteryEV, leftQValue, rightQValue) %>%
  gather(key, value) %>%
  ggplot(aes(value, fill=key))+
  geom_histogram(position = "identity", alpha = 0.5, bins=30)+
  scale_fill_manual(values=cbbPalette[1:3])+
  labs(fill="")
```
Is this by design? Are true fractal values also lower than the EVs?

```{r}
clean_beh_data %>%
  select(leftLotteryEV, fractalLeftProb, fractalRightProb) %>%
  gather(key, value) %>%
  ggplot(aes(value, fill=key))+
  geom_histogram(position = "identity", alpha = 0.5, bins=30)+
  scale_fill_manual(values=cbbPalette[3:1])+
  labs(fill="")
```

The Q value distribution is not the same for all subjects. As expected from the above exploration they are more variable for better learners.

But the range is more limited compared to lottery EVs regardless of learning rates.

```{r}
clean_beh_data %>%
  mutate(lab_col = paste0(subnum, ", alpha = ",round(alpha, 3))) %>%
  select(lab_col, leftQValue, rightQValue) %>%
  gather(key, value, -lab_col) %>%
  ggplot(aes(value, fill=key))+
  geom_histogram(position = "identity", alpha = 0.5, bins=30)+
  scale_fill_manual(values=cbbPalette[1:2])+
  labs(fill="", x="", y = "")+
  facet_wrap(~lab_col)+
  theme(legend.position = "bottom")
```

Trial by trial Q value for a good learner

```{r}
clean_beh_data %>%
  filter(subnum == "19") %>%
  select(session, leftQValue, fractalLeftProb, rightQValue, fractalRightProb, trialNum) %>%
  gather(key, value, -session, -trialNum) %>%
  mutate(side = ifelse(grepl("eft", key), "left", "right"),
         learned = ifelse(grepl("fractal", key), "true", "learned")) %>%
  ggplot(aes(trialNum, value, color=learned))+
  geom_point()+
  geom_line()+
  facet_grid(session~side)+
  labs(color="", title="High alpha (subnum 19)")+
  scale_color_manual(values=cbbPalette[5:6])
```

```{r}
clean_beh_data %>%
  filter(subnum == "02") %>%
  select(session, leftQValue, fractalLeftProb, rightQValue, fractalRightProb, trialNum) %>%
  gather(key, value, -session, -trialNum) %>%
  mutate(side = ifelse(grepl("eft", key), "left", "right"),
         learned = ifelse(grepl("fractal", key), "true", "learned")) %>%
  ggplot(aes(trialNum, value, color=learned))+
  geom_point()+
  geom_line()+
  facet_grid(session~side)+
  labs(color="", title="Low alpha (subnum 02)")+
  scale_color_manual(values=cbbPalette[5:6])

```

### Reward and rpe

```{r}
clean_beh_data %>%
  filter(reward < 5) %>%
  ggplot(aes(reward, valChosen, color=rpe))+
  geom_jitter(height=0.1)
```

## Logit model comparison: what effects choice?

Is a model where choice depends only on the lottery value difference explain data better than a model that doesn't include the fractal value difference?

```{r}
m1 = brm(choiceLeft ~ leftQVAdv + leftEVAdv + probFractalDraw + leftQVAdv:probFractalDraw + leftEVAdv:probFractalDraw + (1|subnum),
            data=clean_beh_data, family=bernoulli(link="logit"), silent=2, refresh=0)
m1 = add_criterion(m1, "waic")

m2 = brm(choiceLeft ~ leftEVAdv * probFractalDraw + (1|subnum),
            data=clean_beh_data, family=bernoulli(link="logit"), silent=2, refresh=0)
m2 = add_criterion(m2, "waic")
```

```{r}
m3 = brm(choiceLeft ~ leftbundleValAdv * probFractalDraw + (1|subnum),
            data=clean_beh_data, family=bernoulli(link="logit"), silent=2, refresh=0)
m3 = add_criterion(m3, "waic")
```

```{r}
m1a = brm(choiceLeft ~ leftQVAdvWeighted + leftEVAdvWeighted + (1|subnum),
            data=clean_beh_data, family=bernoulli(link="logit"), silent=2, refresh=0)
m1a = add_criterion(m1a, "waic")
```

```{r}
loo_compare(m1, m1a, m2, m3, criterion = "waic")
```

```{r}
m3$criteria
```

```{r}
m1a$criteria
```

```{r}
m3
```

```{r}
m1a
```



## Where is QV in the brain?

Are we not finding a neural correlate for fractal value regressors because they are more variable across subjects?

```{r}
source(paste0(helpers_path,'logit_choiceLeft_randomEffects_conflictCollapsed.R'))
source(paste0(helpers_path,'logit_choiceLeft_randomEffects_conflictCollapsed_pFracWeightedValDiff.R'))
```

```{r}
out_choiceLeft_re_pfw %>%
  filter(var != "intercept") %>%
  pivot_wider(values_from = c("Estimate", "Q2.5", "Q97.5"),
              id_cols = c(subnum, probFractalDraw),
              names_from = var) %>%
  ggplot(aes(Estimate_qv_slopes, Estimate_ev_slopes))+
  geom_point()+
  geom_errorbar(aes(ymin=Q2.5_ev_slopes, ymax=Q97.5_ev_slopes), alpha=.5, color=cbbPalette[2])+
  geom_errorbarh(aes(xmin=Q2.5_qv_slopes, xmax=Q97.5_qv_slopes), alpha=.5, color=cbbPalette[1])+
  facet_wrap(~probFractalDraw)+
  labs(x="Logit slope for QV(left)-QV(right)", y="Logit slope for EV(left)-EV(right)")+
  theme_bw()
```

```{r}
out_choiceLeft_re %>%
  filter(var != "intercept") %>%
  pivot_wider(values_from = c("Estimate", "Q2.5", "Q97.5"),
              id_cols = c(subnum, probFractalDraw),
              names_from = var) %>%
  ggplot(aes(Estimate_qv_slopes, Estimate_ev_slopes))+
  geom_point()+
  geom_errorbar(aes(ymin=Q2.5_ev_slopes, ymax=Q97.5_ev_slopes), alpha=.5, color=cbbPalette[2])+
  geom_errorbarh(aes(xmin=Q2.5_qv_slopes, xmax=Q97.5_qv_slopes), alpha=.5, color=cbbPalette[1])+
  facet_wrap(~probFractalDraw)+
  labs(x="Logit slope for QV(left)-QV(right)", y="Logit slope for EV(left)-EV(right)")+
  theme_bw()
```

Compare width of errorbars more directly?
You're trying to capture where there is more individual variability.
Not where an individual's estimates might be more variable.
So what you should look at is the variance of estimates for each slope at each pfractal level.

```{r}
out_choiceLeft_re_pfw %>%
  filter(var != "intercept") %>%
  ggplot(aes(as.factor(probFractalDraw), Estimate, color=var))+
  geom_boxplot()
```

```{r}
out_choiceLeft_re %>%
  filter(var != "intercept") %>%
  ggplot(aes(as.factor(probFractalDraw), Estimate, color=var))+
  geom_boxplot()
```