---
title: "Experience vs. description based decision-making project: Post imaging analyses checks"
output: 
  html_document:
    toc: true
    toc_float: true
    code_folding: 'hide'
---

Set up environment and load in data

```{r include=FALSE}
library(tidyverse)
library(gridExtra)
library(brms)
library(here)
cbbPalette <- c("#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
# theme_set(theme_bw())
theme_set(theme_classic())
sem <- function(x) {sd(x, na.rm=T) / sqrt(length(x))}
helpers_path = here('helpers/')
```

```{r include=FALSE}
source(paste0(helpers_path,'fit_twoValSystemsWithRL_hierarchical_rpeWhenFractalRewarded.R'))
fit_rpeWhenFractalRewarded = fit
g_par_ests_rpeWhenFractalRewarded = g_par_ests
par_ests_rpeWhenFractalRewarded = par_ests

source(paste0(helpers_path,'fit_twoValSystemsWithRL_hierarchical_rpeChosenBundleFractal.R'))
fit_rpeChosenBundleFractal = fit
g_par_ests_rpeChosenBundleFractal = g_par_ests
par_ests_rpeChosenBundleFractal = par_ests

source(paste0(helpers_path,'fit_twoValSystemsWithRL_hierarchical.R'))
source(paste0(helpers_path,'add_inferred_pars.R'))
```

```{r}
clean_beh_data_original = add_inferred_pars(clean_beh_data, par_ests, model_name="original")
clean_beh_data_rpeChosenBundleFractal = add_inferred_pars(clean_beh_data, par_ests_rpeChosenBundleFractal, model_name="rpeChosenBundleFractal")
clean_beh_data_rpeWhenFractalRewarded = add_inferred_pars(clean_beh_data, par_ests_rpeWhenFractalRewarded, model_name="rpeWhenFractalRewarded")
```

# Individual differences in RPE updating

## Behavioral fit comparison

There are individual differences in the best fitting model.

```{r}
par_ests %>%
  mutate(model = "original") %>%
  rbind(par_ests_rpeChosenBundleFractal %>% mutate(model = "rpeChosenBundleFractal")) %>%
  rbind(par_ests_rpeWhenFractalRewarded %>% mutate(model = "rpeWhenFractalRewarded")) %>%
  ggplot(aes(logLik, fill=model))+
  geom_histogram(bins=30, position="identity", alpha=0.5)+
  facet_wrap(~subnum, scales='free')+
  scale_fill_manual(values=cbbPalette[1:3])+
  theme(legend.position = "bottom")+
  labs(x="",y="", fill="", title = "Distribution of log likelihoods")
```

```{r}
best_model_for_subj = par_ests %>%
  mutate(model = "original") %>%
  rbind(par_ests_rpeChosenBundleFractal %>% mutate(model = "rpeChosenBundleFractal")) %>%
  rbind(par_ests_rpeWhenFractalRewarded %>% mutate(model = "rpeWhenFractalRewarded")) %>%
  group_by(model, subnum) %>%
  summarise(aveLL = mean(logLik),.groups='keep') %>%
  ungroup() %>%
  group_by(subnum) %>%
  mutate(minaveLL = min(aveLL)) %>%
  spread(model, aveLL) %>%
  mutate(winningModel = ifelse(minaveLL == original, "original", ifelse(minaveLL == rpeChosenBundleFractal, "rpeChosenBundleFractal", "rpeWhenFractalRewarded"))) %>%
  select(-minaveLL) 

best_model_for_subj %>%
  ungroup()%>%
  count(winningModel)
```

## Correlation between parameter estimates across the three models 

```{r}
par_ests %>%
  mutate(model = "original") %>%
  rbind(par_ests_rpeChosenBundleFractal %>% mutate(model = "rpeChosenBundleFractal")) %>%
  rbind(par_ests_rpeWhenFractalRewarded %>% mutate(model = "rpeWhenFractalRewarded")) %>%
  filter(par == "alpha") %>%
  ggplot(aes(value, fill=model)) +
  geom_histogram(bins=30, position="identity", alpha=0.5)+
  facet_wrap(~subnum, scales='free')+
  scale_fill_manual(values=cbbPalette[1:3])+
  theme(legend.position = "bottom")+
  labs(x="",y="", fill="", title = "Distribution of learning rates")
```

Plotting mean posterior estimates for each subject in the following two plots.

Models where the RPE is not updated on each trial tend to estimate slightly higher learning rates.

```{r}
clean_beh_data_original %>%
  mutate(model = "original") %>%
  select(subnum, model, alpha) %>%
  rbind(clean_beh_data_rpeChosenBundleFractal %>%
          mutate(model = "rpeChosenBundleFractal") %>%
          select(subnum, model, alpha)) %>%
  rbind(clean_beh_data_rpeWhenFractalRewarded %>%
          mutate(model = "rpeWhenFractalRewarded") %>%
          select(subnum, model, alpha)) %>%
  distinct() %>%
  gather(par, est, -subnum, -model) %>%
  spread(model, est) %>%
  gather(model, value, -subnum, -par, -original) %>%
  ggplot(aes(original, value)) +
  geom_point()+
  geom_abline(aes(slope=1, intercept=0), linetype="dashed")+
  facet_grid(model ~ par, scales='free')+
  theme_bw()
  
```

```{r}
clean_beh_data_original %>%
  mutate(model = "original") %>%
  select(subnum, model, beta, delta, gamma) %>%
  rbind(clean_beh_data_rpeChosenBundleFractal %>%
          mutate(model = "rpeChosenBundleFractal") %>%
          select(subnum, model, beta, delta, gamma)) %>%
  rbind(clean_beh_data_rpeWhenFractalRewarded %>%
          mutate(model = "rpeWhenFractalRewarded") %>%
          select(subnum, model, beta, delta, gamma)) %>%
  distinct() %>%
  gather(par, est, -subnum, -model) %>%
  spread(model, est) %>%
  gather(model, value, -subnum, -par, -original) %>%
  ggplot(aes(original, value)) +
  geom_point()+
  geom_abline(aes(slope=1, intercept=0), linetype="dashed")+
  facet_grid(model ~ par, scales='free')+
  theme_bw()
  
```

## Correlation of RPE regressors for each model

Depicting three different subjects in the columns.

```{r}
clean_beh_data_original %>%
  mutate(model = "original") %>%
  group_by(subnum) %>%
  mutate(trialNumCont = 1:n()) %>%
  select(subnum, model, trialNumCont, rpeLeftRightSum) %>%
  rbind(clean_beh_data_rpeChosenBundleFractal %>%
          mutate(model = "rpeChosenBundleFractal") %>%
          group_by(subnum) %>%
          mutate(trialNumCont = 1:n()) %>%
          select(subnum, model, trialNumCont, rpeLeftRightSum)) %>%
  rbind(clean_beh_data_rpeWhenFractalRewarded %>%
          mutate(model = "rpeWhenFractalRewarded")%>%
          group_by(subnum) %>%
          mutate(trialNumCont = 1:n()) %>%
          select(subnum, model, trialNumCont, rpeLeftRightSum)) %>%
  spread(model, rpeLeftRightSum) %>%
  gather(model, value, -subnum, -trialNumCont, -original) %>%
  filter(subnum %in% c("02", "04", "08")) %>%
  ggplot(aes(original, value)) +
  geom_point()+
  geom_abline(aes(slope=1, intercept=0), linetype="dashed")+
  facet_grid(model~subnum, scales='free')+
  theme_bw()
  
```

# Reliability of value signal

Get behavioral data with the parameter estimates and **RPE's from the best fitting model for each subject**.

```{r}
source(paste0(helpers_path, 'save_imaging_events_wBestRpe.R'))
```

What do the RPEs look like? Is there enough variance in them if you wanted to use their absolute value as a "reliability" signal?

```{r}
clean_beh_data %>%
  select(leftFractalRpe, rightFractalRpe) %>%
  gather(key, value) %>%
  ggplot(aes(value))+
  geom_histogram(alpha=.5, bins=30)+
  facet_wrap(~key)
```

```{r}
clean_beh_data %>%
  select(leftFractalRpe, rightFractalRpe) %>%
  gather(key, value) %>%
  ggplot(aes(abs(value)))+
  geom_histogram(alpha=.5, bins=30)+
  facet_wrap(~key)
```
Are absolute RPE distributions similar for both fractals for all subjects or do some subjects learn more/less about one fractal than the other?

```{r}
clean_beh_data %>%
  select(leftFractalRpe, rightFractalRpe, subnum) %>%
  gather(key, value, -subnum) %>%
  filter(abs(value)>0) %>%
  ggplot(aes(abs(value), fill=key))+
  geom_histogram(alpha=.5, bins=30, position="identity")+
  facet_wrap(~subnum)+
  theme(legend.position ="bottom")+
  scale_fill_manual(values=c(cbbPalette[1:2]))+
  labs(fill="")
```
Subjects 3, 5, 8, 10, 15, 27 might be learning differently about the two fractals.

```{r}
clean_beh_data %>%
  select(leftFractalRpe, rightFractalRpe, subnum) %>%
  gather(key, value, -subnum) %>%
  mutate(value=abs(value)) %>% #reliability
  filter(value>0) %>%
  group_by(subnum, key) %>%
  summarise(.groups = 'keep', 
            sem_val = sem(value), 
            mean_val = mean(value)) %>%
  ggplot(aes(subnum, mean_val, fill=key))+
  geom_bar(stat="identity",position=position_dodge(width = .9), alpha=.5)+
  geom_errorbar(aes(ymin=mean_val-sem_val, ymax=mean_val+sem_val), position=position_dodge(width = .9), width=.25)+
  theme(legend.position = "bottom")+
  scale_fill_manual(values=c(cbbPalette[1:2]))+
  labs(fill="", y="")
```

When there is an rpe for at least one fractal how correlated are they for the two fractals for each subject? Would the absolute value of an average rpe be a good reliability signal?

```{r}
clean_beh_data %>%
  select(leftFractalRpe, rightFractalRpe, subnum) %>%
  filter(abs(leftFractalRpe)>0 | abs(rightFractalRpe)>0) %>%
  ggplot(aes(abs(leftFractalRpe), abs(rightFractalRpe))) +
  geom_point()+
  geom_abline(aes(slope=1, intercept=0), linetype="dashed")+
  facet_wrap(~subnum)
```

If learning about fractal is **model-free**    
and  
choosing based on lotteries in **model-based**  
then  
does this reliability signal (abs rpe; but from previous trial?) associate with behavior?

Arbitration should only be relevant when there is a conflict. Conflict isn't just if the value difference between the lotteries and fractals point to different bundles. This would be irrelevant if the trial reward does not depend on one of the attributes as much. Should it be operationalized as high subjective uncertainty (e.g. wpFrac 0.4-0.6)?

arbitration trials: 0.4 < wpFrac < 0.6
dv: choice left? choice mf (better fractal)? choice mb (better lottery)?
iv: reliability. absolute value of rpe but which one since there are two for each trial? start with average

```{r}
  
```

# Response times 

## RT by relevant attribute

Subjects choose faster when reward depends only on fractals.

```{r}
clean_beh_data %>%
  mutate(log_rt = log(reactionTime), 
         probFractalDraw = as.factor(probFractalDraw)) %>%
  group_by(subnum, probFractalDraw) %>%
  summarise(mean_log_rt = mean(log_rt), .groups='keep') %>%
  ungroup()%>%
  group_by(probFractalDraw)%>%
  summarise(sem_log_rt = sem(mean_log_rt),
            mean_log_rt = mean(mean_log_rt)) %>%
  ggplot(aes(probFractalDraw, mean_log_rt))+
  geom_bar(stat="identity")+
  geom_errorbar(aes(ymin=  mean_log_rt - sem_log_rt, ymax=mean_log_rt + sem_log_rt), width=.2)
```

```{r}
clean_beh_data %>%
  mutate(probFractalDraw = as.factor(probFractalDraw)) %>%
  group_by(subnum, probFractalDraw) %>%
  summarise(mean_rt = mean(reactionTime), .groups='keep') %>%
  ungroup()%>%
  group_by(probFractalDraw)%>%
  summarise(sem_rt = sem(mean_rt),
            mean_rt = mean(mean_rt)) %>%
  ggplot(aes(probFractalDraw, mean_rt))+
  geom_bar(stat="identity")+
  geom_errorbar(aes(ymin=  mean_rt - sem_rt, ymax=mean_rt + sem_rt), width=.2)

```
## RT by bundle value difference

```{r}
clean_beh_data %>%
  mutate(probFractalDraw = as.factor(probFractalDraw),
         logRt = log(reactionTime)) %>%
  ggplot(aes(leftBundleValAdv, reactionTime, color=probFractalDraw))+
  geom_smooth(method = "lm", formula = y ~ x + I(x^2), se=FALSE)+
  theme(legend.position = "bottom")+
  labs(x="Bundle value difference", color="") +
  guides(color=guide_legend(nrow=1,byrow=TRUE))
```
Does RT depend similarly on the EV and QV difference at each level of prob fractal draw?

```{r}
clean_beh_data %>%
  mutate(probFractalDraw = as.factor(probFractalDraw)) %>%
  select(probFractalDraw, leftQVAdv, leftEVAdv, reactionTime)
```

## RT by prob distortion 

```{r}

```

# Relative strength of preference

EV_diff and QV_diff

```{r}

```