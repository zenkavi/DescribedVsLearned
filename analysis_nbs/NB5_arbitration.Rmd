---
title: "Experience vs. description based decision-making project: Adding arbitration to behavioral modeling"
output: 
  html_document:
    toc: true
    toc_float: true
    code_folding: 'hide'
---

Set up environment and load in data

```{r include=FALSE}
library(tidyverse)
library(gridExtra)
library(brms)
library(here)
cbbPalette <- c("#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
# theme_set(theme_bw())
theme_set(theme_classic())
sem <- function(x) {sd(x, na.rm=T) / sqrt(length(x))}
helpers_path = here('helpers/')
```

# Reliability of value signal

Get behavioral data with the parameter estimates and **RPE's from the best fitting model for each subject**.

```{r}
source(paste0(helpers_path, 'save_imaging_events_wBestRpe.R'))
```

What do the RPEs look like? Is there enough variance in them if you wanted to use their absolute value as a "reliability" signal?

```{r}
clean_beh_data %>%
  select(leftFractalRpe, rightFractalRpe) %>%
  gather(key, value) %>%
  ggplot(aes(value))+
  geom_histogram(alpha=.5, bins=30)+
  facet_wrap(~key)
```

```{r}
clean_beh_data %>%
  select(leftFractalRpe, rightFractalRpe) %>%
  gather(key, value) %>%
  ggplot(aes(abs(value)))+
  geom_histogram(alpha=.5, bins=30)+
  facet_wrap(~key)
```
Are absolute RPE distributions similar for both fractals for all subjects or do some subjects learn more/less about one fractal than the other?

```{r}
clean_beh_data %>%
  select(leftFractalRpe, rightFractalRpe, subnum) %>%
  gather(key, value, -subnum) %>%
  filter(abs(value)>0) %>%
  ggplot(aes(abs(value), fill=key))+
  geom_histogram(alpha=.5, bins=30, position="identity")+
  facet_wrap(~subnum)+
  theme(legend.position ="bottom")+
  scale_fill_manual(values=c(cbbPalette[1:2]))+
  labs(fill="")
```
Subjects 3, 5, 8, 10, 15, 27 might be learning differently about the two fractals.

```{r}
clean_beh_data %>%
  select(leftFractalRpe, rightFractalRpe, subnum) %>%
  gather(key, value, -subnum) %>%
  mutate(value=abs(value)) %>% #reliability
  filter(value>0) %>%
  group_by(subnum, key) %>%
  summarise(.groups = 'keep', 
            sem_val = sem(value), 
            mean_val = mean(value)) %>%
  ggplot(aes(subnum, mean_val, fill=key))+
  geom_bar(stat="identity",position=position_dodge(width = .9), alpha=.5)+
  geom_errorbar(aes(ymin=mean_val-sem_val, ymax=mean_val+sem_val), position=position_dodge(width = .9), width=.25)+
  theme(legend.position = "bottom")+
  scale_fill_manual(values=c(cbbPalette[1:2]))+
  labs(fill="", y="")
```

When there is an rpe for at least one fractal how correlated are they for the two fractals for each subject? Would the absolute value of an average rpe be a good reliability signal?

```{r}
clean_beh_data %>%
  select(leftFractalRpe, rightFractalRpe, subnum) %>%
  filter(abs(leftFractalRpe)>0 | abs(rightFractalRpe)>0) %>%
  ggplot(aes(abs(leftFractalRpe), abs(rightFractalRpe))) +
  geom_point()+
  geom_abline(aes(slope=1, intercept=0), linetype="dashed")+
  facet_wrap(~subnum)
```

If learning about fractal is **model-free**    
and  
choosing based on lotteries in **model-based**  
then  
does this reliability signal (abs rpe; but from previous trial?) associate with behavior?

Arbitration should only be relevant when there is a conflict. Conflict isn't just if the value difference between the lotteries and fractals point to different bundles. This would be irrelevant if the trial reward does not depend on one of the attributes as much. Should it be operationalized as high subjective uncertainty (e.g. wpFrac 0.4-0.6)?

arbitration trials: 0.4 < wpFrac < 0.6
dv: choice left? choice mf (better fractal)? choice mb (better lottery)?
iv: reliability. absolute value of rpe but which one since there are two for each trial? start with average

```{r}
  
```

# Response times 

## RT by relevant attribute

Subjects choose faster when reward depends only on fractals.

```{r}
clean_beh_data %>%
  mutate(log_rt = log(reactionTime), 
         probFractalDraw = as.factor(probFractalDraw)) %>%
  group_by(subnum, probFractalDraw) %>%
  summarise(mean_log_rt = mean(log_rt), .groups='keep') %>%
  ungroup()%>%
  group_by(probFractalDraw)%>%
  summarise(sem_log_rt = sem(mean_log_rt),
            mean_log_rt = mean(mean_log_rt)) %>%
  ggplot(aes(probFractalDraw, mean_log_rt))+
  geom_bar(stat="identity")+
  geom_errorbar(aes(ymin=  mean_log_rt - sem_log_rt, ymax=mean_log_rt + sem_log_rt), width=.2)
```

```{r}
clean_beh_data %>%
  mutate(probFractalDraw = as.factor(probFractalDraw)) %>%
  group_by(subnum, probFractalDraw) %>%
  summarise(mean_rt = mean(reactionTime), .groups='keep') %>%
  ungroup()%>%
  group_by(probFractalDraw)%>%
  summarise(sem_rt = sem(mean_rt),
            mean_rt = mean(mean_rt)) %>%
  ggplot(aes(probFractalDraw, mean_rt))+
  geom_bar(stat="identity")+
  geom_errorbar(aes(ymin=  mean_rt - sem_rt, ymax=mean_rt + sem_rt), width=.2)

```
## RT by bundle value difference

```{r}
clean_beh_data %>%
  mutate(probFractalDraw = as.factor(probFractalDraw),
         logRt = log(reactionTime)) %>%
  ggplot(aes(leftBundleValAdv, reactionTime, color=probFractalDraw))+
  geom_smooth(method = "lm", formula = y ~ x + I(x^2), se=FALSE)+
  theme(legend.position = "bottom")+
  labs(x="Bundle value difference", color="") +
  guides(color=guide_legend(nrow=1,byrow=TRUE))
```
Does RT depend similarly on the EV and QV difference at each level of prob fractal draw?

```{r}
clean_beh_data %>%
  mutate(probFractalDraw = as.factor(probFractalDraw)) %>%
  select(probFractalDraw, leftQVAdv, leftEVAdv, reactionTime) %>%
  mutate(leftQVAdv = round(leftQVAdv, 1)) %>%
  gather(key, value, -probFractalDraw, -reactionTime) %>%
  group_by(key, value, probFractalDraw) %>%
  summarise(mean_rt = mean(reactionTime),
            sem_rt = sem(reactionTime), .groups='keep') %>%
  ggplot(aes(value, mean_rt))+
  geom_point()+
  geom_errorbar(aes(ymin=mean_rt-sem_rt, ymax=mean_rt+sem_rt))+
  facet_grid()
```

## RT by prob distortion 

```{r}

```

# Relative strength of preference

EV_diff and QV_diff

```{r}

```