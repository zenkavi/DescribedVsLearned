---
title: "Experience vs. description based decision-making project: Adding arbitration to behavioral modeling"
output: 
  html_document:
    toc: true
    toc_float: true
    code_folding: 'hide'
---

# Setup

Set up environment and load in data

```{r include=FALSE}
library(tidyverse)
library(gridExtra)
library(brms)
library(here)
library(broom)
cbbPalette <- c("#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
# theme_set(theme_bw())
theme_set(theme_classic())
sem <- function(x) {sd(x, na.rm=T) / sqrt(length(x))}
helpers_path = here('helpers/')

set.seed(385723)
```

Adding in parameters from the two systems model for all subjects (i.e. not choosing the best fitting one per subject)

```{r}
source(paste0(helpers_path,'fit_twoValSystemsWithRL_hierarchical.R'))
source(paste0(helpers_path,'add_inferred_pars.R'))
clean_beh_data = add_inferred_pars(clean_beh_data, par_ests, model_name="original")
source(paste0(helpers_path,'sim_task.R'))
source(paste0(helpers_path,'sim_sanity_checks.R'))
```

# True data

### Motivation for competition

```{r}
clean_beh_data %>%
  mutate(wAbsLeftEVAdv = (1-probFractalDraw)*abs(leftEVAdv),
         wAbsLeftQVAdv = (probFractalDraw)*abs(leftQVAdv),
         EVAdvMinQVAdv = abs(wAbsLeftEVAdv - wAbsLeftQVAdv),
         probFractalDraw = as.factor(probFractalDraw)) %>%
  group_by(probFractalDraw) %>%
  summarise(meanEVAdvMinQVAdv = mean(EVAdvMinQVAdv),
            semEVAdvMinQVAdv = sem(EVAdvMinQVAdv)) %>%
  ggplot(aes(probFractalDraw, meanEVAdvMinQVAdv))+
  geom_point()+
  geom_errorbar(aes(ymin = meanEVAdvMinQVAdv - semEVAdvMinQVAdv, ymax = meanEVAdvMinQVAdv + semEVAdvMinQVAdv), width=.2)
```

Filter data for a few subjects with a range of learning rates (i.e. variance in QValue differences) to simulate RTs using DDM. Rename columns to work with task simulation function. 

```{r}
sub_data = clean_beh_data %>%
  filter(subnum  %in% c("01", "03", "05","07", "09", "11", "13", "15", "17", "19")) %>%
  select(leftQValue, rightQValue, leftLotteryEV, rightLotteryEV, probFractalDraw, reactionTime, choiceLeft, subnum) %>%
  rename(EVLeft = leftLotteryEV, EVRight = rightLotteryEV, QVLeft = leftQValue, QVRight = rightQValue)
```

How do the sanity checks look in the sampled data?

```{r}
sim_sanity_checks(sub_data %>%
                    select(-subnum) %>%
                    mutate(choice = ifelse(choiceLeft == 1, "left", "right")), 
                  compare_rts = FALSE)
```

# Model 1: Integrate both starting at stim presentation

DDM that can take our task specific arguments as input

```{r}
sim_trial = function(d, sigma,  barrier=1, nonDecisionTime=0, bias=0, timeStep=10, maxIter=1000, epsilon = 0.0002, ...){
  
  # d : drift rate
  # sigma: sd of the normal distribution 
  # timeStep: in ms
  # nonDecisionTime: in ms
  # maxIter: num max samples. if a barrier isn't hit by this sampling of evidence no decision is made. If time step is 10ms and maxIter is 1000 this would be a (1000 iterations * 10 ms (per iteration) / 1000 convert back to sec =) 10sec timeout maximum
  
  RDV = bias
  time = 1
  elapsedNDT = 0
  choice = 0
  RT = NA
  
  kwargs = list(...)
  EVLeft=kwargs$EVLeft
  EVRight=kwargs$EVRight
  QVLeft=kwargs$QVLeft
  QVRight=kwargs$QVRight
  probFractalDraw=kwargs$probFractalDraw
  
  while (time<maxIter){
    
    # If the RDV hit one of the barriers, the trial is over.
    if (RDV >= barrier | RDV <= -barrier){
      RT = (time * timeStep)/1000 #convert back to secs
      if (RDV >= barrier){
        choice = "left"
      } else if (RDV <= -barrier){
        choice = "right"
      }
      break
    } 
    
    # nonDecisionTime/timeStep gives how many sampling iterations the nonDecisionTime corresponds to
    nonDecIters = nonDecisionTime / timeStep
    # If elapsed time is less than the number of sampling iterations required for the nonDecisionTime set evidence sampling distribution mean to 0 so any move from starting point would only be noise
    if (elapsedNDT < nonDecIters){
      mu_mean = 0
      elapsedNDT = elapsedNDT + 1
    } else{
      # If the nonDecisionTime has passed set the mean of the distribution the decision variable will be sampled from to a value proportional to the value difference and the drift rate 
      valueLeft = probFractalDraw*QVLeft + (1-probFractalDraw)*(EVLeft)
      valueRight = probFractalDraw*QVRight + (1-probFractalDraw)*(EVRight)
      mu_mean = d*(valueLeft - valueRight)
    }
    
    # Sample the change in RDV from the distribution with mean proportional to the value difference
    mu = rnorm(1, mu_mean, epsilon)
    RDV = RDV + rnorm(1, mu, sigma)
    
    # Increment sampling iteration
    time = time + 1
  }
  
  #Organize output 
  out = data.frame(EVLeft = EVLeft, EVRight = EVRight, QVLeft = QVLeft, QVRight = QVRight, probFractalDraw = probFractalDraw, choice=choice, reactionTime = RT)
  return(out)
}
```

**NOTE on drift rate: with a value like d=0.002 there are too many timeout trials because the scale of the value difference is much smaller than e.g. the value difference in the aDDM papers**

```{r}
sim_data_m1_1 = sim_task(stimuli = sub_data, d = .01, sigma = .1)
```

```{r}
sim_sanity_checks(sim_data_m1_1)
```

Too fast with d=0.01. Can we slow it down with d=.005? Yes but then it's too noisy and choice doesn't depend on the relevant attributes as much as it should.

```{r}
sim_data_m1_2 = sim_task(stimuli = sub_data, d = .005, sigma = .1)
```

```{r}
sim_sanity_checks(sim_data_m1_2)
```

Error bars for RTs are very wide. Can we make them smaller with smaller sigma? (from .1 to .05)

```{r}
sim_data_m1_3 = sim_task(stimuli = sub_data, d = .005, sigma = .05)
```

```{r}
sim_sanity_checks(sim_data_m1_3)
```

**Bottom line: Can get close to the choice psychometrics but not the response time distributions/relationship with attribute relevance.**

# Model 2: Begin integration about Q values earlier if that is the only relevant option

```{r}
sim_trial = function(d, sigma, barrierDecay, barrier=1, nonDecisionTime=0, bias=0, timeStep=10, maxIter=400, epsilon = 0.0002, debug=FALSE,...){
  
  # d : drift rate
  # sigma: sd of the normal distribution 
  # timeStep: in ms
  # nonDecisionTime: in ms
  # maxIter: num max samples. if a barrier isn't hit by this sampling of evidence no decision is made. If time step is 10ms and maxIter is 1000 this would be a 10sec timeout maximum
  
  RDV = bias
  time = 1
  elapsedNDT = 0
  choice = 0
  RT = NA
  
  kwargs = list(...)
  EVLeft=kwargs$EVLeft
  EVRight=kwargs$EVRight
  QVLeft=kwargs$QVLeft
  QVRight=kwargs$QVRight
  probFractalDraw=kwargs$probFractalDraw
  stimDelay = 2000 #Stimulus screen comes on 2 secs after the presentation of probFractalDraw
  stimDelayIters = stimDelay / timeStep
  nonDecIters = nonDecisionTime / timeStep
  
  initialBarrier = barrier
  
  # The values of the barriers can change over time.
  barrier = rep(initialBarrier, maxIter)
  for(t in seq(2, maxIter, 1)){
    barrier[t] = initialBarrier / (1 + barrierDecay * (t))
  }
  
  while (time<maxIter){
    
    # If the RDV hit one of the barriers, the trial is over.
    if (RDV >= barrier[time] | RDV <= -barrier[time]){
      RT = (time * timeStep)/1000 #convert ms back to secs
      
      # Debugging
      if(debug){
        print(paste0("pre subtraction RT = ", RT))
      }
      
      RT = RT - (stimDelay/1000) #subtract stimDelay
      
      #if decision is reached before the stim screen sample rt from log normal distribution similar to with empirical
      # CHANGE THIS TO A MORE MEANINGFUL WAY OF GENERATING RT; AT THE VERY LEAST BASED ON A CHOICE RT TASK RT DISTRIBUTION
      if (RT < (stimDelay/1000)){
        RT=rlnorm(1, mean = 0, sd = 0.5)
      }
      
      if (RDV >= barrier[time]){
        choice = "left"
      } else if (RDV <= -barrier[time]){
        choice = "right"
      }
      break
    } 
    
    if (elapsedNDT < nonDecIters){
      mu_mean = 0
      elapsedNDT = elapsedNDT + 1
    } else{
          
    # Stim hasn't been presented yet
    # integration begins using only QVs for trials when they are the only relevant attribute
      if (time < stimDelayIters){
        if (probFractalDraw == 1){
          mu_mean = d*(QVLeft - QVRight)
        } else {mu_mean = 0}
      } else{
        # integration for both attributes begins at stim presentation
        valueLeft = probFractalDraw*QVLeft + (1-probFractalDraw)*(EVLeft)
        valueRight = probFractalDraw*QVRight + (1-probFractalDraw)*(EVRight)
        mu_mean = d*(valueLeft - valueRight)
      }
    }
    
    
    # Sample the change in RDV from the distribution.
    mu = rnorm(1, mu_mean, epsilon)
    RDV = RDV + rnorm(1, mu, sigma)
    
    if (debug){
      print(paste0("time = ", time, " mu_mean = ", mu_mean, " mu = ", round(mu, 3), " RDV = ", round(RDV, 3), " barrier = ", round(barrier[time], 3)))
    }
    
    # Increment sampling iteration
    time = time + 1
  }
  
  #Organize output 
  out = data.frame(EVLeft = EVLeft, EVRight = EVRight, QVLeft = QVLeft, QVRight = QVRight, probFractalDraw = probFractalDraw, choice=choice, reactionTime = RT)
  return(out)
}
```

Why is rt not jumping for probFractalDraw == 1?
- Change model to integrate a lot faster when pFrac == 1
- Changed the logit slope to rely more on the q value difference for pfrac == 1 trials but didn't make those trials faster compared to the other conditions
- Change the RT distribution for decisions made pre stim presentation to be super fast
- Made all trials fast. I think there is a bug in the RT draws. Seems to be happening for all trials instead of only pFrac == 1 trials
- Debug output: for each step where is RDV; is it higher for the first 20 pre stimulus iterations for trials where pFrac == 1

```{r}
sim_trial(d = .005, sigma = .05, barrierDecay = .1, EVLeft = .5, EVRight = .5, QVLeft = .5, QVRight = .5, probFractalDraw = 1, debug=TRUE)
```

```{r}
# sim_data_m2_1 = sim_task(stimuli=sub_data, d = .01, sigma = .1, barrierDecay = .1)
sim_data_m2_1 = sim_task(stimuli=sub_data, d = .005, sigma = .05, barrierDecay = .1)
```

```{r}
sim_sanity_checks(sim_data_m2_1)
```

```{r}
data.frame(val = rlnorm(1000, mean = 0, sd = 0.5)) %>%
  ggplot(aes(val))+
  geom_histogram(bins = 30)
```

```{r}
data.frame(val = rlnorm(1000, mean = -1, sd = 0.5)) %>%
  ggplot(aes(val))+
  geom_histogram(bins = 30)
```

Why are rt so slow even with a massive barrierDecay?

```{r}
sim_data_m2_2 = sim_task(stimuli = sub_data, d = .0075, sigma = .05, barrierDecay = 1)
```

```{r}
sim_sanity_checks(sim_data_m2_2)
```

# Model 3:

Things to incorporate:
- Choice bias for lotteries
- Computation of EV for lotteries takes time
- There is something other than EV computation going on for 1 > probFractalDraw > 0
- Competition based on relative strength of preference
