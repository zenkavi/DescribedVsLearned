---
title: "Experience vs. description based decision-making project: Adding arbitration to behavioral modeling"
output: 
  html_document:
    toc: true
    toc_float: true
    code_folding: 'hide'
---

# Setup

Set up environment and load in data

```{r include=FALSE}
library(tidyverse)
library(gridExtra)
library(brms)
library(here)
library(broom)
cbbPalette <- c("#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
# theme_set(theme_bw())
theme_set(theme_classic())
sem <- function(x) {sd(x, na.rm=T) / sqrt(length(x))}
helpers_path = here('helpers/')

set.seed(385723)
```

Adding in parameters from the two systems model for all subjects (i.e. not choosing the best fitting one per subject)

```{r}
source(paste0(helpers_path,'fit_twoValSystemsWithRL_hierarchical.R'))
source(paste0(helpers_path,'add_inferred_pars.R'))
clean_beh_data = add_inferred_pars(clean_beh_data, par_ests, model_name="original")
source(paste0(helpers_path,'sim_task.R'))
source(paste0(helpers_path,'sim_sanity_checks.R'))
```

# True data

### Motivation for competition

Graph below shows the difference in strength of preference for the left bundle based on EV versus QV. The smaller this difference the harder it should be to make the decision based on one attribute only. 

So if choice is faster when this value is larger that would suggest it is driven primarily by (the relative preference for) one attribute. Alternatively if choice is slower when this value is smaller it suggests integrating

```{r}
clean_beh_data %>%
  mutate(wAbsLeftEVAdv = (1-probFractalDraw)*abs(leftEVAdv), # strength of left preference based on EV
         wAbsLeftQVAdv = (probFractalDraw)*abs(leftQVAdv), # strength of left preference based on QV
         EVAdvMinQVAdv = abs(wAbsLeftEVAdv - wAbsLeftQVAdv), # difference in strength of preference
         probFractalDraw = as.factor(probFractalDraw)) %>%
  group_by(probFractalDraw) %>%
  summarise(meanEVAdvMinQVAdv = mean(EVAdvMinQVAdv),
            semEVAdvMinQVAdv = sem(EVAdvMinQVAdv)) %>%
  ggplot(aes(probFractalDraw, meanEVAdvMinQVAdv))+
  geom_point()+
  geom_errorbar(aes(ymin = meanEVAdvMinQVAdv - semEVAdvMinQVAdv, ymax = meanEVAdvMinQVAdv + semEVAdvMinQVAdv), width=.2)
```

Filter data for a few subjects with a range of learning rates (i.e. variance in QValue differences) to simulate RTs using DDM. Rename columns to work with task simulation function. 

```{r}
sub_data = clean_beh_data %>%
  filter(subnum  %in% c("01", "03", "05","07", "09", "11", "13", "15", "17", "19")) %>%
  select(leftQValue, rightQValue, leftLotteryEV, rightLotteryEV, probFractalDraw, reactionTime, choiceLeft, subnum) %>%
  rename(EVLeft = leftLotteryEV, EVRight = rightLotteryEV, QVLeft = leftQValue, QVRight = rightQValue)
```

## Sanity checks in the sampled data

```{r}
sim_sanity_checks(sub_data %>%
                    select(-subnum) %>%
                    mutate(choice = ifelse(choiceLeft == 1, "left", "right")), 
                  compare_rts = FALSE)
```
```{r}
sim_trial_list = list()
```


# Model 1: Simplest

- Integration begins at stim presentation for all conditions
- Drift rate is proportional to the bundle value difference 
- Bundle values are computed as sums of QV and EV weighted by their relevance (no distortion of probability)

```{r}
sim_trial = function(d, sigma,  barrier=1, nonDecisionTime=0, bias=0, timeStep=10, maxIter=1000, epsilon = 0.0002, ...){
  
  # d : drift rate
  # sigma: sd of the normal distribution 
  # timeStep: in ms
  # nonDecisionTime: in ms
  # maxIter: num max samples. if a barrier isn't hit by this sampling of evidence no decision is made. If time step is 10ms and maxIter is 1000 this would be a (1000 iterations * 10 ms (per iteration) / 1000 convert back to sec =) 10sec timeout maximum
  
  RDV = bias
  time = 1
  elapsedNDT = 0
  choice = 0
  RT = NA
  
  kwargs = list(...)
  EVLeft=kwargs$EVLeft
  EVRight=kwargs$EVRight
  QVLeft=kwargs$QVLeft
  QVRight=kwargs$QVRight
  probFractalDraw=kwargs$probFractalDraw
  
  valueLeft = probFractalDraw*QVLeft + (1-probFractalDraw)*(EVLeft)
  valueRight = probFractalDraw*QVRight + (1-probFractalDraw)*(EVRight)
  valDiff_mu_mean = d*(valueLeft - valueRight)
  
  while (time<maxIter){
    
    # If the RDV hit one of the barriers, the trial is over.
    if (RDV >= barrier | RDV <= -barrier){
      RT = (time * timeStep)/1000 #convert back to secs
      if (RDV >= barrier){
        choice = "left"
      } else if (RDV <= -barrier){
        choice = "right"
      }
      break
    } 
    
    # nonDecisionTime/timeStep gives how many sampling iterations the nonDecisionTime corresponds to
    nonDecIters = nonDecisionTime / timeStep
    # If elapsed time is less than the number of sampling iterations required for the nonDecisionTime set evidence sampling distribution mean to 0 so any move from starting point would only be noise
    if (elapsedNDT < nonDecIters){
      mu_mean = 0
      elapsedNDT = elapsedNDT + 1
    } else{
      # If the nonDecisionTime has passed set the mean of the distribution the decision variable will be sampled from to a value proportional to the value difference and the drift rate 
      mu_mean = valDiff_mu_mean
    }
    
    # Sample the change in RDV from the distribution with mean proportional to the value difference
    mu = rnorm(1, mu_mean, epsilon)
    RDV = RDV + rnorm(1, mu, sigma)
    
    # Increment sampling iteration
    time = time + 1
  }
  
  #Organize output 
  out = data.frame(EVLeft = EVLeft, EVRight = EVRight, QVLeft = QVLeft, QVRight = QVRight, probFractalDraw = probFractalDraw, choice=choice, reactionTime = RT)
  return(out)
}
sim_trial_list[['model1']] = sim_trial
```

```{r}
sim_data_m1_1 = sim_task(stimuli = sub_data, d = .05, sigma = .025)
```

```{r}
sim_sanity_checks(sim_data_m1_1)
```

## Checks

- RT
  - No inverse U
  - No fast pFrac == 1 trials
- Choice
  - Logits are too high
  - No lottery bias

# Model 2: Early integration, relative preference weighting

- Two kinds of early integration
  - For probFractalDraw == 1 trials begin integrating before stimulus presentation proportional to QV difference weighted by drift rate
  - For all trials, if a decision hasn't already been made before the stim presentation, first integrate only based on the weighted EV difference. This is intended to capture EV computation at stim presentation and possibly result in a lottery bias
- Once any early integration is complete integration uses both QV and EV differences weighted by relevance. They are also weighted by how strong the difference on one attribute is compared to the other attribute.

```{r}
sim_trial = function(d, sigma, barrierDecay, barrier=1, nonDecisionTime=0, bias=0, timeStep=10, maxIter=400, epsilon = 0.0002, stimDelay = 2000, evCompTime = 300, debug=FALSE,...){
  
  # d : drift rate
  # sigma: sd of the normal distribution 
  # timeStep: in ms
  # nonDecisionTime: in ms
  # maxIter: num max samples. if a barrier isn't hit by this sampling of evidence no decision is made. If time step is 10ms and maxIter is 1000 this would be a 10sec timeout maximum
  
  if (debug){
    debug_df = data.frame()
  }
  
  RDV = bias
  time = 1
  elapsedNDT = 0
  choice = 0
  RT = NA
  
  decPreStim = 0
  timeOut = 0
  
  kwargs = list(...)
  EVLeft=kwargs$EVLeft
  EVRight=kwargs$EVRight
  QVLeft=kwargs$QVLeft
  QVRight=kwargs$QVRight
  probFractalDraw=kwargs$probFractalDraw
  # Stimulus screen comes on 2 secs after the presentation of probFractalDraw
  stimDelayIters = stimDelay / timeStep
  nonDecIters = nonDecisionTime / timeStep
  evCompIters = evCompTime / timeStep
  
  # Integration starts before stim presentation (though meaningful move from 0 happens only for pFrac = 1 trials) but decision can only be indicated after stim. Since total iterations depend on maxIter the addition of iterations before stim presentation controls for the desired max time out for the trial. In the arguments to the function it is specified as the maximum time out duration after stim presentation
  maxIter = maxIter + stimDelayIters
  
  initialBarrier = barrier
  barrier = rep(initialBarrier, maxIter)
  
  # The values of the barriers can change over time
  # Barrier decay starts after stim presentation. Not during any possible sampling before that
  for(t in seq(stimDelayIters, maxIter, 1)){
    barrier[t] = initialBarrier / (1 + barrierDecay * (t-stimDelayIters))
  }
  
  qv_mu_mean = d*(QVLeft - QVRight)
  ev_mu_mean = d * (1-probFractalDraw) * (EVLeft - EVRight)
  
  leftFractalAdv =  probFractalDraw* (QVLeft - QVRight)
  leftLotteryAdv = (1-probFractalDraw) * (EVLeft - EVRight)
  relPrefFractal = abs(leftFractalAdv)/(abs(leftLotteryAdv)+1e-6)
  weighted_mu_mean = d * (relPrefFractal * leftFractalAdv + (1/(relPrefFractal+1e-6)) * leftLotteryAdv)
  
  while (time<maxIter){
    
    # If the RDV hit one of the barriers, the trial is over.
    if (RDV >= barrier[time] | RDV <= -barrier[time]){
      
      # Convert ms back to secs
      RT = (time * timeStep)/1000 
      
      # Debugging
      if(debug){
        print(paste0("pre subtraction RT = ", RT))
      }
      
      #subtract stimDelay
      RT = RT - (stimDelay/1000) 
      
      # If decision is reached before the stim screen sample rt from log normal distribution similar to choice RT 
      if (RT < 0){
        decPreStim = 1
        RT=rlnorm(1, mean = -.25, sd = 0.5)
      }
      
      if (RDV >= barrier[time]){
        choice = "left"
      } else if (RDV <= -barrier[time]){
        choice = "right"
      }
      break
    } 
    
    if (elapsedNDT < nonDecIters){
      mu_mean = 0
      elapsedNDT = elapsedNDT + 1
    } else{
      if (time < stimDelayIters){
        # Integration after fractal prob presentation but before stim presentation happens ONLY for the probfractaldraw == 1 trials
        if (probFractalDraw == 1){
          mu_mean = qv_mu_mean
        } else {
          # No integration after NDT and before stim presentation for any other trial type
          mu_mean = 0
        }
      } else{
        # Time for EV computation. Should create lottery bias
        if (time < (stimDelayIters + evCompIters)){
          mu_mean = ev_mu_mean
        } else {
          # Competition?
          # Gathering evidence based on lotteries vs fractals
          mu_mean = weighted_mu_mean
        }
      }
    }
    
    # Sample the change in RDV from the distribution.
    mu = rnorm(1, mu_mean, epsilon)
    RDV = RDV + rnorm(1, mu, sigma)
    
    if (debug){
      debug_row = data.frame(time = time, mu_mean = mu_mean, mu = round(mu, 3), RDV = round(RDV, 3), barrier = round(barrier[time], 3))
      debug_df = rbind.all.columns(debug_df, debug_row)
      }
    
    # Increment sampling iteration
    time = time + 1
  }
  
  #If a choice hasn't been made by the time limit
  if(is.na(RT)){
    # Choose whatever you have most evidence for
    if (RDV >= 0){
      choice = "left"
    } else if (RDV <= 0){
      choice = "right"
    }
    if(debug){
      print("Max iterations reached.")
    }
    timeOut = 1
    RT=rlnorm(1, mean = 1.25, sd = 0.1)
  }
  
  #Organize output 
  out = data.frame(EVLeft = EVLeft, EVRight = EVRight, QVLeft = QVLeft, QVRight = QVRight, probFractalDraw = probFractalDraw, choice=choice, reactionTime = RT, timeOut = timeOut, decPreStim = decPreStim, leftFractalAdv = leftFractalAdv, leftLotteryAdv = leftLotteryAdv,  relPrefFractal = relPrefFractal, relPrefLottery = 1/(relPrefFractal+1e-6), d = d, sigma = sigma, barrierDecay = barrierDecay)
  
  if(debug){
    return(list(out=out, debug_df = debug_df[-1,]))
  } else {
    return(out)
  }
}
sim_trial_list[['model2']] = sim_trial
```

```{r}
sim_trial(d = .002, sigma = .05, barrierDecay = 0.005, EVLeft = 0.7, EVRight = .5, QVLeft = 0.3, QVRight = 0.3, probFractalDraw = 0, debug=TRUE)
```

```{r}
sim_data_m2_1 = sim_task(stimuli=sub_data, d = .004, sigma = .04, barrierDecay = 0.005)
```

```{r}
sim_sanity_checks(sim_data_m2_1)
```

## Checks

- RT
  - Bimodal RT distributions (should not be)
  - Yes slight inverse U
  - Yes fast pFrac == 1 trials (too fast)
- Choice
  - Logits too high for pfrac == 1
  - Yes lottery bias

What is going on with the trials that hit decision before stimuli are presented but are not pfrac = 1? There should be no integration for these before the stimuli are presented. Seems to go down quickly with reducing sigma so they're likely from noise integration but reducing sigma messes up other things as well

```{r}
sim_data_m2_1 %>% 
  filter(decPreStim == 1)
```
# Model 3: Same as model 2 except for relative preference weighting

- Same two early integration possibilities
- For other cases the weighting factor is computed differently to mitigate effect of very large numbers at 0 difference between attributes

```{r}
sim_trial = function(d, sigma, barrierDecay, barrier=1, nonDecisionTime=0, bias=0, timeStep=10, maxIter=400, epsilon = 0.0002, stimDelay = 2000, evCompTime = 300, debug=FALSE,...){
  
  # d : drift rate
  # sigma: sd of the normal distribution 
  # timeStep: in ms
  # nonDecisionTime: in ms
  # maxIter: num max samples. if a barrier isn't hit by this sampling of evidence no decision is made. If time step is 10ms and maxIter is 1000 this would be a 10sec timeout maximum
  
  if(debug){
    debug_df = data.frame()
  }
  
  RDV = bias
  time = 1
  elapsedNDT = 0
  choice = 0
  RT = NA
  
  decPreStim = 0
  timeOut = 0
  
  kwargs = list(...)
  EVLeft=kwargs$EVLeft
  EVRight=kwargs$EVRight
  QVLeft=kwargs$QVLeft
  QVRight=kwargs$QVRight
  probFractalDraw=kwargs$probFractalDraw
  # Stimulus screen comes on 2 secs after the presentation of probFractalDraw
  stimDelayIters = stimDelay / timeStep
  nonDecIters = nonDecisionTime / timeStep
  evCompIters = evCompTime / timeStep
  
  # Integration starts before stim presentation (though meaningful move from 0 happens only for pFrac = 1 trials) but decision can only be indicated after stim. Since total iterations depend on maxIter the addition of iterations before stim presentation controls for the desired max time out for the trial. In the arguments to the function it is specified as the maximum time out duration after stim presentation
  maxIter = maxIter + stimDelayIters
  
  initialBarrier = barrier
  barrier = rep(initialBarrier, maxIter)
  
  # The values of the barriers can change over time
  # Barrier decay starts after stim presentation. Not during any possible sampling before that
  for(t in seq(stimDelayIters, maxIter, 1)){
    barrier[t] = initialBarrier / (1 + barrierDecay * (t-stimDelayIters))
  }
  
  qv_mu_mean = d*(QVLeft - QVRight)
  ev_mu_mean = d * (1-probFractalDraw) * (EVLeft - EVRight)
  leftFractalAdv =  probFractalDraw* (QVLeft - QVRight)
  leftLotteryAdv = (1-probFractalDraw) * (EVLeft - EVRight)
  relPrefFractal = abs(leftFractalAdv)/(abs(leftLotteryAdv)+abs(leftFractalAdv)+1e-6)
  weighted_mu_mean = d * (relPrefFractal * leftFractalAdv + (1-relPrefFractal) * leftLotteryAdv)

  
  while (time<maxIter){
    
    # If the RDV hit one of the barriers, the trial is over.
    if (RDV >= barrier[time] | RDV <= -barrier[time]){
      
      # Convert ms back to secs
      RT = (time * timeStep)/1000 
      
      #subtract stimDelay
      RT = RT - (stimDelay/1000) 
      
      # If decision is reached before the stim screen sample rt from log normal distribution similar to choice RT 
      if (RT < 0){
        decPreStim = 1
        RT=rlnorm(1, mean = -.25, sd = 0.5)
      }
      
      if (RDV >= barrier[time]){
        choice = "left"
      } else if (RDV <= -barrier[time]){
        choice = "right"
      }
      break
    } 
    
    if (elapsedNDT < nonDecIters){
      mu_mean = 0
      elapsedNDT = elapsedNDT + 1
    } else{
      if (time < stimDelayIters){
        # Integration after fractal prob presentation but before stim presentation happens ONLY for the probfractaldraw == 1 trials
        if (probFractalDraw == 1){
          mu_mean = qv_mu_mean
        } else {
          # No integration after NDT and before stim presentation for any other trial type
          mu_mean = 0
        }
      } else{
        
        # Time for EV computation. Should create lottery bias
        if (time < (stimDelayIters + evCompIters)){
          mu_mean = ev_mu_mean
        } else {
          # Competition?
          # Gathering evidence based on lotteries vs fractals' relative strength of preference
          mu_mean = weighted_mu_mean
        }
      }
    }
    
    # Sample the change in RDV from the distribution.
    mu = rnorm(1, mu_mean, epsilon)
    RDV = RDV + rnorm(1, mu, sigma)
    
    if (debug){
      debug_row = data.frame(time = time, mu_mean = mu_mean, mu = round(mu, 3), RDV = round(RDV, 3), barrier = round(barrier[time], 3))
      debug_df = rbind.all.columns(debug_df, debug_row)
    }
    
    # Increment sampling iteration
    time = time + 1
  }
  
  #If a choice hasn't been made by the time limit
  if(is.na(RT)){
    # Choose whatever you have most evidence for
    if (RDV >= 0){
      choice = "left"
    } else if (RDV <= 0){
      choice = "right"
    }
    if(debug){
      print("Max iterations reached.")
    }
    timeOut = 1
    RT=rlnorm(1, mean = 1.25, sd = 0.1)
  }
  
  #Organize output 
  out = data.frame(EVLeft = EVLeft, EVRight = EVRight, QVLeft = QVLeft, QVRight = QVRight, probFractalDraw = probFractalDraw, choice=choice, reactionTime = RT, timeOut = timeOut, decPreStim = decPreStim, leftFractalAdv = leftFractalAdv, leftLotteryAdv = leftLotteryAdv,  relPrefFractal = relPrefFractal, d = d, sigma = sigma, barrierDecay = barrierDecay, barrier = barrier[time], RDV = RDV)
  
  if(debug){
    return(list(out=out, debug_df=debug_df))
  }else{
    return(out)
  }
  
}
sim_trial_list[['model3']] = sim_trial
```

```{r}
sim_trial(d = .008, sigma = .01, barrierDecay = 0, EVLeft = 0.7, EVRight = .1, QVLeft = 0.7, QVRight = 0.1, probFractalDraw = .6, debug=TRUE)
```

```{r}
sim_data_m3_1 = sim_task(stimuli=sub_data, d = .01, sigma = .01, barrierDecay = 0.005)
```

```{r}
sim_sanity_checks(sim_data_m3_1)
```

## Checks

- RT
  - Bimodal RT distributions (should not be)
  - Not really inverse U, more like an increase wihth increased pFrac
  - Yes fast pFrac == 1 trials
- Choice
  - Logits too high for pfrac == 1
  - No lottery bias

# Model 4: 3 integrators

- all biases are by moving the starting points
  - for all trials there is a general lottery bias
  - for pfrac == 1 trials there is a fractal bias the size of the QV difference
- Integration happens for EV and QV separately along with an arbitrator that determines the decision

```{r}
sim_trial = function(d, sigma, barrierDecay, barrier=1, nonDecisionTime=0, lotteryBias=0.1, fractalBias = 0, timeStep=10, maxIter=400, epsilon = 0.002, debug=FALSE,...){
  
  # d : drift rate
  # sigma: sd of the normal distribution 
  # timeStep: in ms
  # nonDecisionTime: in ms
  # maxIter: num max samples. if a barrier isn't hit by this sampling of evidence no decision is made. If time step is 10ms and maxIter is 1000 this would be a 10sec timeout maximum
  
  
  arbitratorRDV = 0
  time = 1
  elapsedNDT = 0
  choice = 0
  RT = NA
  
  timeOut = 0
  
  arbitrator_mu_mean = NA
  if(debug){
    debug_df = data.frame()
  }
  
  kwargs = list(...)
  EVLeft=kwargs$EVLeft
  EVRight=kwargs$EVRight
  if(EVLeft > EVRight){
    lotteryRDV = lotteryBias
  } else {
    lotteryRDV = -lotteryBias
  }
  
  QVLeft=kwargs$QVLeft
  QVRight=kwargs$QVRight
  if(EVLeft > EVRight){
    fractalRDV = fractalBias
  } else {
    fractalRDV = -fractalBias
  }
  
  probFractalDraw=kwargs$probFractalDraw
  if(probFractalDraw == 1){
    fractalRDV = QVLeft - QVRight
  }
  
  nonDecIters = nonDecisionTime / timeStep
  
  initialBarrier = barrier
  barrier = rep(initialBarrier, maxIter)
  
  # The values of the barriers can change over time
  for(t in seq(1, maxIter, 1)){
    barrier[t] = initialBarrier / (1 + barrierDecay * t)
  }
  
  lottery_mu_mean = d * (1-probFractalDraw) * (EVLeft - EVRight)
  fractal_mu_mean = d * probFractalDraw * (QVLeft - QVRight)
  
  while (time<maxIter){
    
    # If the arbitrator RDV hits one of the barriers make decision
    if (arbitratorRDV >= barrier[time] | arbitratorRDV <= -barrier[time]){
      
      # Convert ms back to secs
      RT = (time * timeStep)/1000 
      
      if (arbitratorRDV >= barrier[time]){
        arbitrator = "EV"
        choice = ifelse(lotteryRDV > 0, "left", "right")
      } else if (arbitratorRDV <= -barrier[time]){
        arbitrator = "QV"
        choice = ifelse(fractalRDV > 0, "left", "right")
      }
      break
    } 
    
    # Otherwise continue sampling evidence
    if (elapsedNDT < nonDecIters){
      mu_mean = 0
      elapsedNDT = elapsedNDT + 1
    } else{
      
      # Three integrators
      
      # Lottery integrator
      lottery_mu = rnorm(1, lottery_mu_mean, epsilon)
      lotteryRDV = lotteryRDV + rnorm(1, lottery_mu, sigma)
      
      # Fractal integrator
      fractal_mu = rnorm(1, fractal_mu_mean, epsilon)
      fractalRDV = fractalRDV + rnorm(1, fractal_mu, sigma)
      
      # Arbitrator 
      # If abs(lotteryRDV) > abs(fractalRDV) stronger relative preference for a side based on lotteries
      arbitrator_mu_mean = d * (abs(lotteryRDV) - abs(fractalRDV))
      arbitrator_mu = rnorm(1, arbitrator_mu_mean, epsilon)
      arbitratorRDV = arbitratorRDV + rnorm(1, arbitrator_mu, sigma)
    }
    
    if (debug){
      debug_row = data.frame(time = time, arbitrator_mu_mean = round(arbitrator_mu_mean, 3), arbitratorRDV = round(arbitratorRDV, 3), barrier = round(barrier[time], 3), lotteryRDV = round(lotteryRDV, 3), fractalRDV = round(fractalRDV, 3))
      debug_df = rbind(debug_df, debug_row)
    }
    
    # Increment sampling iteration
    time = time + 1
  }
  
  #If a choice hasn't been made by the time limit
  if(is.na(RT)){
    # Choose whatever you have most evidence for
    arbitrator = ifelse(arbitratorRDV >= 0 , "EV", "QV")
    if(arbitrator == "EV"){
      choice = ifelse(lotteryRDV > 0, "left", "right")
    } else if (arbitrator == "QV"){
      choice = ifelse(fractalRDV > 0, "left", "right")
    }
   
    timeOut = 1
    RT=rlnorm(1, mean = 1.25, sd = 0.1)
  }
  
  #Organize output 
  out = data.frame(EVLeft = EVLeft, EVRight = EVRight, QVLeft = QVLeft, QVRight = QVRight, probFractalDraw = probFractalDraw, choice=choice, reactionTime = RT, timeOut = timeOut, arbitrator = arbitrator)
  
  if(debug){
    out = list(out=out, debug_df=debug_df[-1,])
  }
  
  return(out)
}
sim_trial_list[['model4']] = sim_trial
```

Example visualization of integration

```{r echo=FALSE, eval=FALSE}
tmp = sim_trial(d = .033, sigma = .03, barrierDecay = 0.005, EVLeft = .7, EVRight = 0.5, QVLeft = 0.3, QVRight = 0.7, probFractalDraw = .8, debug=TRUE, nonDecisionTime = 0)

tmp$debug_df %>%
  select(-arbitrator_mu_mean) %>%
  gather(key, value, -time, -barrier) %>%
  ggplot()+
  geom_line(aes(time, value))+
  geom_line(aes(time, barrier), color="red")+
  geom_line(aes(time, -barrier), color="green")+
  geom_hline(aes(yintercept = 0), linetype="dashed")+
  facet_grid(key ~.)
```


```{r}
sim_data_m4_1 = sim_task(stimuli=sub_data, d = .033, sigma = .03, barrierDecay = 0.007)
```

```{r}
sim_sanity_checks(sim_data_m4_1)
```

## Checks

- RT
  - RT distributions largely overlapping with true distributions
  - Inverse U or continued increase?
  - Yes fast pFrac == 1 trials
- Choice
  - Logits too high for edge pfrac
  - Slight/no lottery bias
  
# Model 5: 3 integrators

- Same as model 4 but with attribute relevance affecting arbitrator and not the attribute integrators

```{r}
sim_trial = function(d, sigma, barrierDecay, barrier=1, nonDecisionTime=0, lotteryBias=0.1, fractalBias = 0, timeStep=10, maxIter=400, epsilon = 0.002, debug=FALSE,...){
  
  # d : drift rate
  # sigma: sd of the normal distribution 
  # timeStep: in ms
  # nonDecisionTime: in ms
  # maxIter: num max samples. if a barrier isn't hit by this sampling of evidence no decision is made. If time step is 10ms and maxIter is 1000 this would be a 10sec timeout maximum
  
  
  arbitratorRDV = 0
  time = 1
  elapsedNDT = 0
  choice = 0
  RT = NA
  
  timeOut = 0
  
  arbitrator_mu_mean = NA
  if(debug){
    debug_df = data.frame()
  }
  
  kwargs = list(...)
  EVLeft=kwargs$EVLeft
  EVRight=kwargs$EVRight
  if(EVLeft > EVRight){
    lotteryRDV = lotteryBias
  } else {
    lotteryRDV = -lotteryBias
  }
  
  QVLeft=kwargs$QVLeft
  QVRight=kwargs$QVRight
  if(EVLeft > EVRight){
    fractalRDV = fractalBias
  } else {
    fractalRDV = -fractalBias
  }
  
  probFractalDraw=kwargs$probFractalDraw
  if(probFractalDraw == 1){
    fractalRDV = QVLeft - QVRight
  }
  
  nonDecIters = nonDecisionTime / timeStep
  
  initialBarrier = barrier
  barrier = rep(initialBarrier, maxIter)
  
  # The values of the barriers can change over time
  for(t in seq(1, maxIter, 1)){
    barrier[t] = initialBarrier / (1 + barrierDecay * t)
  }
  
  lottery_mu_mean = d * (EVLeft - EVRight)
  fractal_mu_mean = d * (QVLeft - QVRight)
  
  while (time<maxIter){
    
    # If the arbitrator RDV hits one of the barriers make decision
    if (arbitratorRDV >= barrier[time] | arbitratorRDV <= -barrier[time]){
      
      # Convert ms back to secs
      RT = (time * timeStep)/1000 
      
      if (arbitratorRDV >= barrier[time]){
        arbitrator = "EV"
        choice = ifelse(lotteryRDV > 0, "left", "right")
      } else if (arbitratorRDV <= -barrier[time]){
        arbitrator = "QV"
        choice = ifelse(fractalRDV > 0, "left", "right")
      }
      break
    } 
    
    # Otherwise continue sampling evidence
    if (elapsedNDT < nonDecIters){
      mu_mean = 0
      elapsedNDT = elapsedNDT + 1
    } else{
      
      # Three integrators
      
      # Lottery integrator
      lottery_mu = rnorm(1, lottery_mu_mean, epsilon)
      lotteryRDV = lotteryRDV + rnorm(1, lottery_mu, sigma)
      
      # Fractal integrator
      fractal_mu = rnorm(1, fractal_mu_mean, epsilon)
      fractalRDV = fractalRDV + rnorm(1, fractal_mu, sigma)
      
      # Arbitrator 
      # If abs(lotteryRDV) > abs(fractalRDV) stronger relative preference for a side based on lotteries
      arbitrator_mu_mean = d * ((1-probFractalDraw) * abs(lotteryRDV) - (probFractalDraw) * abs(fractalRDV))
      arbitrator_mu = rnorm(1, arbitrator_mu_mean, epsilon)
      arbitratorRDV = arbitratorRDV + rnorm(1, arbitrator_mu, sigma)
    }
    
    if (debug){
      debug_row = data.frame(time = time, arbitrator_mu_mean = round(arbitrator_mu_mean, 3), arbitratorRDV = round(arbitratorRDV, 3), barrier = round(barrier[time], 3), lotteryRDV = round(lotteryRDV, 3), fractalRDV = round(fractalRDV, 3))
      debug_df = rbind(debug_df, debug_row)
    }
    
    # Increment sampling iteration
    time = time + 1
  }
  
  #If a choice hasn't been made by the time limit
  if(is.na(RT)){
    # Choose whatever you have most evidence for
    arbitrator = ifelse(arbitratorRDV >= 0 , "EV", "QV")
    if(arbitrator == "EV"){
      choice = ifelse(lotteryRDV > 0, "left", "right")
    } else if (arbitrator == "QV"){
      choice = ifelse(fractalRDV > 0, "left", "right")
    }
   
    timeOut = 1
    RT=rlnorm(1, mean = 1.25, sd = 0.1)
  }
  
  #Organize output 
  out = data.frame(EVLeft = EVLeft, EVRight = EVRight, QVLeft = QVLeft, QVRight = QVRight, probFractalDraw = probFractalDraw, choice=choice, reactionTime = RT, timeOut = timeOut, arbitrator = arbitrator)
  
  if(debug){
    out = list(out=out, debug_df=debug_df)
  }
  
  return(out)
}
sim_trial_list[['model5']] = sim_trial
```

Example visualization of integration

```{r echo=FALSE, eval=FALSE}
tmp = sim_trial(d = .033, sigma = .03, barrierDecay = 0.005, EVLeft = .7, EVRight = 0.5, QVLeft = 0.3, QVRight = 0.7, probFractalDraw = .8, debug=TRUE, nonDecisionTime = 0)

tmp$debug_df %>%
  select(-arbitrator_mu_mean) %>%
  gather(key, value, -time, -barrier) %>%
  ggplot()+
  geom_line(aes(time, value))+
  geom_line(aes(time, barrier), color="red")+
  geom_line(aes(time, -barrier), color="green")+
  geom_hline(aes(yintercept = 0), linetype="dashed")+
  facet_grid(key ~.)
```


```{r}
sim_data_m5_1 = sim_task(stimuli=sub_data, model_name = "model5", d = .033, sigma = .03, barrierDecay = 0.007)
```

```{r}
sim_data_m5_1
```

```{r}
sim_sanity_checks(sim_data_m5_1)
```

## Checks

- RT
  - RT distributions largely overlapping with true distributions
  - Inverse U but the apex pushed to where the attribute difference is maximal (by model design)
  - Yes fast pFrac == 1 trials
- Choice
  - Logits too high when value difference is not 
  - Lottery bias?

```{r}
get_rt_sumsq = function(sub_data, sim_data){
  
  out = sim_data %>%
    select(EVLeft, EVRight, QVLeft, QVRight, probFractalDraw, choice, reactionTime) %>%
    mutate(data_type = "sim") %>%
    rbind(sub_data %>%
            mutate(choice = ifelse(choiceLeft == 1, "left", "right"),
                   data_type = "true") %>%
            select(-subnum, -choiceLeft)) %>%
    drop_na()%>%
    mutate(probFractalDraw = as.factor(probFractalDraw), 
           log_rt = log(reactionTime)) %>%
    filter(is.finite(log_rt)) %>%
    group_by(probFractalDraw, data_type) %>%
    summarise(mean_log_rt = mean(log_rt),.groups="keep") %>%
    spread(data_type, mean_log_rt) %>%
    mutate(sqdev = (sim-true)^2)
  
  rt_sumsq = sum(out$sqdev)
  
  return(rt_sumsq)
}

get_choice_sumsq = function(sub_data, sim_data){
  out1 = sim_data %>%
    select(EVLeft, EVRight, QVLeft, QVRight, probFractalDraw, choice, reactionTime) %>%
    mutate(probFractalDraw = as.factor(probFractalDraw),
           choiceLeft = ifelse(choice == "left", 1, ifelse(choice=="right", 0, NA)),
           EVDiff = EVLeft - EVRight, 
           QVDiff = QVLeft - QVRight) %>%
    nest(data = -probFractalDraw) %>% 
    mutate(
      fit = map(data, ~ glm(choiceLeft ~ EVDiff + QVDiff, data = .x, family=binomial(link="logit"))),
      tidied = map(fit, tidy)
    ) %>% 
    unnest(tidied) %>%
    filter(term != "(Intercept)") %>%
    select(probFractalDraw, term, estimate) %>%
    mutate(term = paste0(term, "_sim"))
  
  out2 = sub_data %>%
    select(-subnum) %>%
    mutate(choice = ifelse(choiceLeft == 1, "left", "right")) %>%
    select(EVLeft, EVRight, QVLeft, QVRight, probFractalDraw, choice, reactionTime) %>%
    mutate(probFractalDraw = as.factor(probFractalDraw),
           choiceLeft = ifelse(choice == "left", 1, ifelse(choice=="right", 0, NA)),
           EVDiff = EVLeft - EVRight, 
           QVDiff = QVLeft - QVRight) %>%
    nest(data = -probFractalDraw) %>% 
    mutate(
      fit = map(data, ~ glm(choiceLeft ~ EVDiff + QVDiff, data = .x, family=binomial(link="logit"))),
      tidied = map(fit, tidy)
    ) %>% 
    unnest(tidied) %>%
    filter(term != "(Intercept)") %>%
    select(probFractalDraw, term, estimate) %>%
    mutate(term = paste0(term, "_true"))
  
  out = out1 %>%
    rbind(out2) %>%
    spread(term, estimate) %>%
    mutate(evsqdev = (EVDiff_sim - EVDiff_true)^2,
           qvsqdev = (QVDiff_sim - QVDiff_true)^2,
           sqdev = evsqdev + qvsqdev)
  
  choice_sumsq = sum(out$sqdev)
  
  return(choice_sumsq)
}


find_best_par_combo = function(sub_data, model_name, d_par_space = ..., sigma_par_space = seq(.01, .1, .01), barrier_par_space = c(1), heatmaps = FALSE, save_output=TRUE, out_path = here()){
  
  out = data.frame()
  
  for(cur_d in d_par_space){
    for(cur_sigma in sigma_par_space){
      for(cur_barrier in barrier_par_space){
        out_row = data.frame(d = cur_d, sigma = cur_sigma, barrier_decay = cur_barrier)
        sim_data = sim_task(stimuli=sub_data, d = cur_d, sigma = cur_sigma, barrierDecay = cur_sigma)
        out_row$rt_sumsq = get_rt_sumsq(sub_data, sim_data)
        out_row$choice_sumsq = get_choice_sumsq(sub_data, sim_data)
        out_row$avg_sumsq = with(out_row, (rt_sumsq + choice_sumsq)/2)
        
        out = rbind.all.columns(out, out_row)
      }
    }
  }
  
  if(save_output){
    write.csv(out, paste0(out_path, '/outputs/find_best_par_combo_', model_name, '.csv'), row.names = FALSE)
  }
  
  if(heatmaps){
    p1 = out %>%
      mutate(d = as.factor(d),
             sigma = as.factor(sigma)) %>%
      ggplot(aes(d, sigma, fill=rt_sumsq)) +
      geom_tile()+
      theme(legend.position = "bottom")
    
    p2 = out %>%
      mutate(d = as.factor(d),
             sigma = as.factor(sigma)) %>%
      ggplot(aes(d, sigma, fill=choice_sumsq)) +
      geom_tile()+
      theme(legend.position = "bottom")
    
    p3 = grid.arrange(p1, p2, ncol=2)
  }
  
  return(list(opt_rt_pars = out[out$rt_sumsq == min(out$rt_sumsq),],
              opt_choice_pars = out[out$choice_sumsq == min(out$choice_sumsq),],
              opt_avg_pars = out[out$avg_sumsq == min(out$avg_sumsq),]))
}
```

```{r}
find_best_par_combo(sub_data, model_name = "model5",d_par_space = c(.03, .003), sigma_par_space = c(.01, .04), heatmaps = TRUE)
```

# Next steps

- Quantitative check for inverse U?
- Simulations with best fitting parameter combinations?
  - What distributions would these parameters come from?
- Incorporating EV and QV computation instead of using them as input
