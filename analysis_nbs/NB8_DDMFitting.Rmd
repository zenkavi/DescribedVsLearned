---
title: "Experience vs. description based decision-making project: DDM fitting to subject data"
output: 
  html_document:
    toc: true
    toc_float: true
    code_folding: 'hide'
---

# Setup

Set up environment and load in data

```{r include=FALSE}
library(tidyverse)
library(here)
cbbPalette <- c("#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
theme_set(theme_classic())
sem <- function(x) {sd(x, na.rm=T) / sqrt(length(x))}
helpers_path = here('helpers/')

set.seed(38573)
```

Adding in parameters from the two systems model for all subjects (i.e. not choosing the best fitting one per subject)

```{r}
 # do this first not to mess with cluster setup
source(paste0(helpers_path,'ddmSims/fit_task.R'))
source(paste0(helpers_path,'ddmSims/sim_task.R'))

source(paste0(helpers_path,'ddmSims/sim_sanity_checks.R'))
source(paste0(helpers_path,'twoSystemsFitting/fit_twoValSystemsWithRL_hierarchical.R'))
source(paste0(helpers_path,'add_inferred_pars.R'))
clean_beh_data = add_inferred_pars(clean_beh_data, par_ests, model_name="original")

rm(fit, g_par_ests, par_ests, get_qvals, organize_stan_output, add_inferred_pars, extract_var_for_stan)
```

Create empty list that will store the trial simulators for the forthcoming models.

```{r}
sim_trial_list = list()
fit_trial_list = list()
```


# Testing parameter recovery

## Model 2b: Asymmetric prob distortion

- Distort probFractalDraw when integrating info about fractals but no distortion for lotteries
- Intended to capture the stepwise nature of the logit slopes for the QV difference but the linear nature for the EV difference

```{r}
source(paste0(helpers_path, 'ddmSims/ddm_model2b.R'))
sim_trial_list[['model2b']] = sim_trial
fit_trial_list[['model2b']] = fit_trial
```

## Test single trial

Make sure trial simulator works. Use the mean RT from trials simulated using this model (2b) as the input for fitting in the next step. 

```{r}
100 %>% 
  rerun() %>%
  map_df(~data.frame(sim_trial(d=.04, sigma=0.01, barrierDecay=0, delta=3, gamma=3, EVLeft = .7, EVRight = .2, QVLeft = .7, QVRight = .2, probFractalDraw = .4))) %>%
  summarise(meanRT = mean(reactionTime),
            numLeft = sum(choice == "left"))

```

Are likelihoods higher on average for a parameter combination that is far from the true parameters? No. Not sure why.

```{r}
tmp1 = 100 %>% 
  rerun() %>%
  map_df(~data.frame(fit_trial(d=.04, sigma=0.01, barrierDecay=0, delta=3, gamma=3, EVLeft = .7, EVRight = .2, QVLeft = .7, QVRight = .2, probFractalDraw = .4, choice = "left", reactionTime = .7))) %>%
  mutate(par_type = "true")
```

```{r}
tmp2 = 100 %>% 
  rerun() %>%
  map_df(~data.frame(fit_trial(d=.002, sigma=0.1, barrierDecay=0, delta=3, gamma=3, EVLeft = .7, EVRight = .2, QVLeft = .7, QVRight = .2, probFractalDraw = .4, choice = "left", reactionTime = .7))) %>%
  mutate(par_type = "false")
```

**Why is the likelihood for the false parameters consistently (for all 100 iterations) higher than the likelihood for the true parameters?**

```{r}
rbind(tmp1, tmp2) %>%
  ggplot(aes(par_type, log(likelihood))) +
  geom_boxplot()
```

```{r}
rm(tmp1, tmp2)
```

## Test all trials in a task

Can the likelihood function correctly identify the parameter combination that generated the data? Is the sum of likelihoods for all trials highest for the correct combination than any other combination?

Filter one subject's data.

```{r}
sub_data = clean_beh_data %>%
  filter(subnum  %in% c("19")) %>%
  select(leftQValue, rightQValue, leftLotteryEV, rightLotteryEV, probFractalDraw, reactionTime, choiceLeft, subnum) %>%
  rename(EVLeft = leftLotteryEV, EVRight = rightLotteryEV, QVLeft = leftQValue, QVRight = rightQValue)
```

Use the trials from that subject's data to simulate data (not fitting anything to real data yet to see if recovery with known true parameters is possible)

```{r}
true_dat = sim_task(sub_data, model_name = "model2b", d=0.02, sigma = 0.007, delta = 3, gamma = 3, barrierDecay = 0.004, epsilon = 0.03, nonDecisionTime = 0)
```

```{r}
pars = list(d=0.02, sigma = 0.007, delta = 3, gamma = 3, barrierDecay = 0.004, epsilon = 0.03, nonDecisionTime = 0)
fit1_data = fit_task(true_dat, model_name = "model2b", pars_ = pars)
```

```{r}
pars = list(d=0.05, sigma = 0.01, delta = 2, gamma = 2, barrierDecay = 0.001, epsilon = 0, nonDecisionTime = 0)
fit2_data = fit_task(true_dat, model_name = "model2b", pars_ = pars)
```

```{r}
pars = list(d=0.03, sigma = 0.01, delta = 3, gamma = 3, barrierDecay = 0, epsilon = 0.0004, nonDecisionTime = 0)
fit3_data = fit_task(true_dat, model_name = "model2b", pars_ = pars)
```

Are the sum of likelihoods higher using the true parameter combination compared to false combinations? Yes.

```{r}
sum(fit1_data$likelihood) > sum(fit2_data$likelihood)
```

```{r}
sum(fit1_data$likelihood) > sum(fit3_data$likelihood)
```

```{r}
fit1_data %>%
  mutate(par_type = "true") %>%
  rbind(fit2_data %>% mutate(par_type = "false_1")) %>%
  rbind(fit3_data %>% mutate(par_type = "false_2")) %>%
  group_by(par_type) %>%
  summarise(neg_log_lik = -sum(log(likelihood+1e-200))) %>%
  ggplot(aes(par_type, neg_log_lik))+
  geom_bar(stat="identity", width=.5)+
  geom_hline(aes(yintercept = min(neg_log_lik)), linetype="dashed")

```

# Parameter recovery

```{r}
true_dat = sim_task(sub_data, model_name = "model2b", d=0.02, sigma = 0.007, delta = 3, gamma = 3, barrierDecay = 0.004, epsilon = 0.03, nonDecisionTime = 0)
```

Is the task neg log likelihood **smaller** for the true parameters compared to wrong ones? **No! So identifiability is problematic?**

```{r}
get_task_nll(data=true_dat, par=c(.02, .007, 3, 3, .004, .03), par_names=c("d", "sigma", "delta", "gamma", "barrierDecay", "epsilon"), model_name="model2b")
```

```{r}
get_task_nll(data=true_dat, par=c(1, 1, .0004), par_names=c("d", "sigma", "epsilon"), model_name="model2b")
```

# Fit to data

## Built-in optimizer

This does work (checked with fewer iterations) but it takes forever. 

```{r eval=FALSE}
optim_out = optim(c(.01, .01), get_task_nll, data=true_dat, par_names = c("d", "sigma"), model_name="model2b", control = list(maxit=5))
```

```{r}
optim_out
```

## Grid search

Since fit to one subject when parallelized only takes a few seconds, what if you run a parallelized grid search?
